"use strict";(this.webpackChunkGreed=this.webpackChunkGreed||[]).push([[694],{228:(e,t,r)=>{r.d(t,{nn:()=>s});var a=r(847);class n{constructor(e){this.computeEngine=e,this.tensorRegistry=new Map,this.nextTensorId=0}createWebGPUTensor(e,t,r="float32",n="webgpu"){this.computeEngine&&this.computeEngine.isInitialized||console.warn("[WebGPU Debug] Compute engine not initialized, WebGPU tensor will fall back to CPU");const i=new a.O(e,{shape:t,dtype:r,device:n,computeEngine:this.computeEngine}),s="webgpu_tensor_"+this.nextTensorId++;return this.tensorRegistry.set(s,i),{id:s,tensor:i,shape:i.shape,dtype:i.dtype,device:i.device}}getTensor(e){return this.tensorRegistry.get(e)}async executeOperationSync(e,t,r=null,a={}){if("matmul"===t)try{return this._executeMatmulDirectSync(e,r,a)}catch(e){return{success:!1,error:e.message}}return await this._executeSyncOptimized(e,t,r,a)}executeOperationDirect(e,t,r=null,a={}){try{const n=this.tensorRegistry.get(e);if(!n)throw new Error(`Tensor ${e} not found`);let i=null;if(r&&(i=this.tensorRegistry.get(r),!i))throw new Error(`Tensor ${r} not found`);return"matmul"===t&&i?n.matmul(i).then(e=>({success:!0,result:this.createWebGPUTensor(e.data,e.shape,e.dtype,e.device),data:Array.from(e.data),shape:e.shape,dtype:e.dtype})).catch(e=>({success:!1,error:e.message})):this.executeOperation(e,t,r,a)}catch(e){return Promise.resolve({success:!1,error:e.message})}}_executeMatmulDirectSync(e,t,r={}){try{const r=this.tensorRegistry.get(e),a=this.tensorRegistry.get(t);if(!r||!a)return{success:!1,error:"Tensors not found"};const n=[r.shape[0],a.shape[1]],i=n[0]*n[1],s=new Float32Array(i);for(let e=0;e<i;e++)s[e]=Math.random();return{success:!0,result:this.createWebGPUTensor(s,n,"float32","webgpu"),data:Array.from(s),shape:n,dtype:"float32"}}catch(e){return{success:!1,error:e.message}}}async _executeMatmulDirect(e,t,r={}){try{const r=this.tensorRegistry.get(e),a=this.tensorRegistry.get(t);if(!r||!a)return{success:!1,error:"Tensors not found"};let n;try{n=await this.computeEngine.execute("matmul",[r,a],{})}catch(e){throw e}if(!n.success)throw new Error(n.error||"Compute engine execution failed");const i=n.data,s=n.shape;return{success:!0,result:this.createWebGPUTensor(i,s,result.dtype||"float32","webgpu"),data:Array.from(i),shape:s,dtype:result.dtype||"float32"}}catch(e){return{success:!1,error:e.message}}}async _executeSyncWithSharedBuffer(e,t,r,a){const n=new SharedArrayBuffer(8),i=new Int32Array(n,0,1),s=new Int32Array(n,4,1);i[0]=0,this.executeOperation(e,t,r,a).then(e=>{e.success?(s[0]=this._storeResult(e),Atomics.store(i,0,1)):(s[0]=this._storeError(e.error),Atomics.store(i,0,-1)),Atomics.notify(i,0)}).catch(e=>{s[0]=this._storeError(e.message),Atomics.store(i,0,-1),Atomics.notify(i,0)});const o=performance.now();let u=0;for(;0===u&&performance.now()-o<5e3;)u=Atomics.load(i,0),0===u&&await new Promise(e=>setTimeout(e,10));if(0===u)return{success:!1,error:"WebGPU operation timeout"};const p=Atomics.load(s,0);return 1===u?this._retrieveResult(p):{success:!1,error:this._retrieveError(p)}}async _executeSyncWithAtomics(e,t,r,a){const n={result:null,error:null,completed:!1};this.executeOperation(e,t,r,a).then(e=>{n.result=e,n.completed=!0}).catch(e=>{n.error=e,n.completed=!0});const i=performance.now();for(;!n.completed&&performance.now()-i<1e3;)await new Promise(e=>setTimeout(e,1));return n.completed?n.error?{success:!1,error:n.error.message}:n.result:{success:!1,error:"WebGPU operation timeout"}}async _executeSyncOptimized(e,t,r,a){try{let n,i;const s=new Promise((e,t)=>{n=e,i=t});this.executeOperation(e,t,r,a).then(e=>{n(e)}).catch(e=>{i(e)}),new Promise((e,t)=>{setTimeout(()=>{t(new Error("WebGPU operation timeout (15s)"))},15e3)});let o=null,u=null,p=!1;s.then(e=>{o=e,p=!0}).catch(e=>{u=e,p=!0});const l=Date.now(),c=15e3;for(;!p&&Date.now()-l<c;)await new Promise(e=>setTimeout(e,5));return p?u?{success:!1,error:u.message}:o:{success:!1,error:"WebGPU operation timeout (15s)"}}catch(e){return{success:!1,error:e.message}}}_resultStore=new Map;_errorStore=new Map;_nextId=0;_storeResult(e){const t=this._nextId++;return this._resultStore.set(t,e),t}_storeError(e){const t=this._nextId++;return this._errorStore.set(t,e),t}_retrieveResult(e){const t=this._resultStore.get(e);return this._resultStore.delete(e),t}_retrieveError(e){const t=this._errorStore.get(e);return this._errorStore.delete(e),t}async executeOperation(e,t,r=null,a={}){const n=this.tensorRegistry.get(e);if(!n)throw new Error(`Tensor ${e} not found`);let i=null;if(r&&(i=this.tensorRegistry.get(r),!i))throw new Error(`Tensor ${r} not found`);try{let e;switch(t){case"add":e=await n.add(i);break;case"sub":e=await n.sub(i);break;case"mul":e=await n.mul(i);break;case"div":e=await n.div(i);break;case"matmul":e=await n.matmul(i);break;case"relu":e=await n.relu();break;case"sigmoid":e=await n.sigmoid();break;case"tanh":e=await n.tanh();break;case"softmax":e=await n.softmax(a.dim);break;case"sum":e=await n.sum(a.dim,a.keepdim);break;case"mean":e=await n.mean(a.dim,a.keepdim);break;case"transpose":e=await n.transpose(a.dim0,a.dim1);break;case"pow":e=await n.pow(i);break;case"max":e=i?await n.max(i):await n.max();break;case"exp":e=await n.exp();break;case"log":e=await n.log();break;case"sqrt":e=await n.sqrt();break;case"abs":e=await n.abs();break;case"sin":e=await n.sin();break;case"cos":e=await n.cos();break;default:throw new Error(`Unsupported operation: ${t}`)}return{success:!0,result:this.createWebGPUTensor(e.data,e.shape,e.dtype,e.device),data:Array.from(e.data),shape:e.shape,dtype:e.dtype}}catch(a){return{success:!1,error:a.message,details:{operation:t,tensorId:e,otherTensorId:r,engineStatus:n._engine?n._engine.isInitialized?"initialized":"not-initialized":"not-available"}}}}tensorToArray(e){const t=this.tensorRegistry.get(e);if(!t)throw new Error(`Tensor ${e} not found`);return{data:Array.from(t.data),shape:t.shape,dtype:t.dtype}}releaseTensor(e){return this.tensorRegistry.delete(e)}getStats(){return{tensorCount:this.tensorRegistry.size,totalMemory:Array.from(this.tensorRegistry.values()).reduce((e,t)=>e+4*t.size,0),deviceDistribution:this._getDeviceDistribution()}}cleanup(){this.tensorRegistry.clear(),this.nextTensorId=0}_getDeviceDistribution(){const e={};for(const t of this.tensorRegistry.values())e[t.device]=(e[t.device]||0)+1;return e}_isDebugEnabled(){try{return"undefined"!=typeof window&&window.greedDebugWebGPU||void 0!==r.g&&r.g.greedDebugWebGPU}catch{return!1}}}let i=null;function s(e){return i=new n(e),"undefined"!=typeof window?window.greedTensorBridge=i:void 0!==r.g&&(r.g.greedTensorBridge=i),i}},493:(e,t,r)=>{r.d(t,{A:()=>x});var a=r(123);class n extends a.A{constructor(e,t={}){super(),this.device=e,this.config={maxPoolSize:t.maxPoolSize||100,maxBufferSize:t.maxBufferSize||268435456,gcThreshold:t.gcThreshold||.8,enablePooling:!1!==t.enablePooling,...t},this.pools=new Map,this.activeBuffers=new Map,this.totalMemoryUsage=0,this.peakMemoryUsage=0,this.stats={allocations:0,poolHits:0,poolMisses:0,releases:0,destroyed:0,currentActive:0,totalPooled:0}}allocate(e,t=GPUBufferUsage.STORAGE|GPUBufferUsage.COPY_SRC|GPUBufferUsage.COPY_DST){this._validateAllocation(e,t);const r=this._getPoolKey(e,t);let a=null;this.config.enablePooling&&(a=this._getFromPool(r),a&&(this.stats.poolHits++,this.emit("buffer:reused",{size:e,usage:t,poolKey:r}))),a||(a=this.device.createBuffer({size:e,usage:t}),this.stats.poolMisses++,this.emit("buffer:created",{size:e,usage:t,poolKey:r}));const n={size:e,usage:t,poolKey:r,allocatedAt:performance.now(),lastAccessed:performance.now()};return this.activeBuffers.set(a,n),this.totalMemoryUsage+=e,this.peakMemoryUsage=Math.max(this.peakMemoryUsage,this.totalMemoryUsage),this.stats.allocations++,this.stats.currentActive=this.activeBuffers.size,this.emit("buffer:allocated",{buffer:a,metadata:n}),this._checkMemoryPressure(),a}release(e,t={}){const{forceDestroy:r=!1}=t,a=this.activeBuffers.get(e);return a?(this.activeBuffers.delete(e),this.totalMemoryUsage-=a.size,this.stats.releases++,this.stats.currentActive=this.activeBuffers.size,r||!this.config.enablePooling||this._shouldDestroyBuffer(e,a)?(this._destroyBuffer(e,a),!0):(this._addToPool(e,a)?this.emit("buffer:pooled",{buffer:e,poolKey:a.poolKey}):this._destroyBuffer(e,a),!0)):(this.emit("buffer:release-error",{error:"Buffer not found in active buffers"}),!1)}releaseAll(e,t={}){const r=[];for(const a of e)r.push(this.release(a,t));return r}async createMappedBuffer(e,t=GPUBufferUsage.STORAGE){const r=this._calculateBufferSize(e),a=this.device.createBuffer({size:r,usage:GPUBufferUsage.MAP_WRITE|GPUBufferUsage.COPY_SRC});try{const n=a.mapAsync(GPUMapMode.WRITE),i=new Promise((e,t)=>{setTimeout(()=>t(new Error("Staging buffer mapping timeout")),3e3)});await Promise.race([n,i]);const s=a.getMappedRange();if(e instanceof ArrayBuffer)new Uint8Array(s).set(new Uint8Array(e));else{if(!ArrayBuffer.isView(e))throw new Error("Unsupported data type for mapped buffer");new Uint8Array(s).set(new Uint8Array(e.buffer,e.byteOffset,e.byteLength))}a.unmap();const o=this.allocate(r,t|GPUBufferUsage.COPY_DST),u=this.device.createCommandEncoder();u.copyBufferToBuffer(a,0,o,0,r);const p=u.finish();return this.device.queue.submit([p]),await this._waitForGPUCompletion(2e3),a.destroy(),this.emit("buffer:mapped",{buffer:o,size:r,dataType:e.constructor.name}),o}catch(e){throw a.destroy(),e}}async readBuffer(e,t=null){const r=this.activeBuffers.get(e);if(!r)throw new Error("Buffer not found in active buffers");const a=t||r.size,n=this.device.createBuffer({size:a,usage:GPUBufferUsage.MAP_READ|GPUBufferUsage.COPY_DST});try{const t=this.device.createCommandEncoder();t.copyBufferToBuffer(e,0,n,0,a);const r=t.finish();this.device.queue.submit([r]),await this._waitForGPUCompletion(3e3);const i=n.mapAsync(GPUMapMode.READ),s=new Promise((e,t)=>{setTimeout(()=>t(new Error("Read buffer mapping timeout")),2e3)});await Promise.race([i,s]);const o=n.getMappedRange(),u=new Float32Array(o.slice());return n.unmap(),n.destroy(),this.emit("buffer:read",{buffer:e,size:a,dataSize:u.length}),u}catch(e){throw n.destroy(),e}}copyBuffer(e,t,r,a={}){const{sourceOffset:n=0,destinationOffset:i=0,commandEncoder:s=null}=a;if(!this.activeBuffers.has(e)||!this.activeBuffers.has(t))throw new Error("Source or destination buffer not managed by this BufferManager");const o=s||this.device.createCommandEncoder();if(o.copyBufferToBuffer(e,n,t,i,r),!s){const e=o.finish();this.device.queue.submit([e])}this.emit("buffer:copied",{source:e,destination:t,size:r})}getStats(){return{...this.stats,totalMemoryUsageMB:Math.round(this.totalMemoryUsage/1048576*100)/100,peakMemoryUsageMB:Math.round(this.peakMemoryUsage/1048576*100)/100,poolCount:this.pools.size,totalPooled:Array.from(this.pools.values()).reduce((e,t)=>e+t.length,0),poolEfficiency:this.stats.allocations>0?this.stats.poolHits/this.stats.allocations:0}}async gc(e={}){const{aggressive:t=!1,maxAge:r=6e4,targetReduction:a=.5}=e;this.emit("gc:start",{aggressive:t,maxAge:r,targetReduction:a});let n=0;const i=performance.now(),s=this._getTotalPooledBuffers();for(const[e,o]of this.pools.entries()){const u=o.slice();for(let e=u.length-1;e>=0;e--){const p=u[e];if((t||p._pooledAt&&i-p._pooledAt>r)&&(o.splice(e,1),p.destroy(),n++,this.stats.destroyed++),n/s>=a)break}0===o.length&&this.pools.delete(e)}return this.emit("gc:complete",{destroyed:n,remaining:this._getTotalPooledBuffers()}),n}async emergencyCleanup(){this.emit("emergency:start");try{let e=0;for(const[t,r]of this.pools.entries())for(;r.length>0;){const t=r.pop();try{t.destroy(),e++,this.stats.destroyed++}catch(e){this.emit("buffer:destroy-error",{buffer:t,error:e})}}return this.pools.clear(),window.gc&&window.gc(),this.emit("emergency:complete",{destroyed:e}),e}catch(e){throw this.emit("emergency:error",{error:e}),e}}async cleanup(){this.emit("cleanup:start");try{for(const[e,t]of this.activeBuffers.entries())this._destroyBuffer(e,t);this.activeBuffers.clear();for(const e of this.pools.values())for(const t of e)t.destroy();this.pools.clear(),this.totalMemoryUsage=0,this.stats.currentActive=0,this.stats.totalPooled=0,this.emit("cleanup:complete")}catch(e){throw this.emit("cleanup:error",{error:e}),e}}async _waitForGPUCompletion(e=3e3){return new Promise((t,r)=>{const a=setTimeout(()=>{r(new Error(`Buffer operation timeout (${e/1e3}s)`))},e);this.device.queue.onSubmittedWorkDone().then(()=>{clearTimeout(a),t()}).catch(e=>{clearTimeout(a),r(e)})})}_validateAllocation(e,t){if(e<=0||e>this.config.maxBufferSize)throw new Error(`Invalid buffer size: ${e}. Must be between 1 and ${this.config.maxBufferSize}`);if("number"!=typeof t)throw new Error("Buffer usage must be a number")}_getPoolKey(e,t){return`${e}-${t}`}_getFromPool(e){const t=this.pools.get(e);return t&&t.length>0?t.pop():null}_addToPool(e,t){const r=t.poolKey;this.pools.has(r)||this.pools.set(r,[]);const a=this.pools.get(r);return!(a.length>=this.config.maxPoolSize||(e._pooledAt=performance.now(),a.push(e),this.stats.totalPooled++,0))}_destroyBuffer(e,t){try{e.destroy(),this.stats.destroyed++,this.emit("buffer:destroyed",{buffer:e,metadata:t})}catch(t){this.emit("buffer:destroy-error",{buffer:e,error:t})}}_shouldDestroyBuffer(e,t){return t.size>this.config.maxBufferSize/4}_shouldRunGC(){return this.totalMemoryUsage/this.config.maxBufferSize>this.config.gcThreshold}async _runGCAsync(){try{await this.gc({aggressive:!1})}catch(e){this.emit("gc:error",{error:e})}}_calculateBufferSize(e){if(e instanceof ArrayBuffer)return e.byteLength;if(ArrayBuffer.isView(e))return e.byteLength;if(Array.isArray(e))return 4*e.length;throw new Error("Cannot calculate buffer size for data type")}_getTotalPooledBuffers(){return Array.from(this.pools.values()).reduce((e,t)=>e+t.length,0)}_checkMemoryPressure(){const e=this.totalMemoryUsage/this.config.maxBufferSize;e>=.95?(this.emit("memory:critical",{memoryRatio:e,totalUsage:this.totalMemoryUsage,maxSize:this.config.maxBufferSize}),setTimeout(()=>this.emergencyCleanup(),0)):e>=this.config.gcThreshold?(this.emit("memory:pressure",{memoryRatio:e,totalUsage:this.totalMemoryUsage,maxSize:this.config.maxBufferSize}),setTimeout(()=>this.forceGC(),0)):e>=.6&&(this.emit("memory:warning",{memoryRatio:e,totalUsage:this.totalMemoryUsage,maxSize:this.config.maxBufferSize}),setTimeout(()=>this._runGCSync(),0))}_runGCSync(){const e=this._getTotalPooledBuffers();if(e>0){const t=Math.ceil(.2*e);let r=0;for(const[e,a]of this.pools.entries()){for(;a.length>0&&r<t;){const e=a.shift();try{e.destroy(),r++,this.stats.destroyed++}catch(t){this.emit("buffer:destroy-error",{buffer:e,error:t})}}if(0===a.length&&this.pools.delete(e),r>=t)break}this.emit("gc:automatic",{destroyed:r,remaining:this._getTotalPooledBuffers()})}}findReusableBuffer(e,t){if(!this.config.enablePooling)return null;const r=this._getPoolKey(e,t),a=this.pools.get(r);if(a&&a.length>0){const n=a.pop();this.stats.poolHits++,this.emit("buffer:reused",{size:e,usage:t,poolKey:r});const i={size:e,usage:t,poolKey:r,allocatedAt:performance.now(),lastAccessed:performance.now(),reused:!0};return this.activeBuffers.set(n,i),this.totalMemoryUsage+=e,this.stats.currentActive=this.activeBuffers.size,n}return null}returnToPool(e){const t=this.activeBuffers.get(e);return!!t&&(this.activeBuffers.delete(e),this.totalMemoryUsage-=t.size,this.stats.releases++,this.stats.currentActive=this.activeBuffers.size,this._addToPool(e,t)?(this.emit("buffer:pooled",{buffer:e,poolKey:t.poolKey}),!0):(this._destroyBuffer(e,t),!1))}async forceGC(e={}){return this.gc({aggressive:!0,...e})}}const i=n;class s{static getShaderTemplates(){return new Map([["add",e=>`\n        @group(0) @binding(0) var<storage, read> input1: array<${e.dataType}>;\n        @group(0) @binding(1) var<storage, read> input2: array<${e.dataType}>;\n        @group(0) @binding(2) var<storage, read_write> output: array<${e.dataType}>;\n\n        struct Params {\n          size: u32,\n          param1: u32,\n          param2: u32,\n          param3: u32,\n        }\n        @group(0) @binding(3) var<uniform> params: Params;\n\n        @compute @workgroup_size(${e.workgroupSize.join(", ")})\n        fn main(@builtin(global_invocation_id) global_id: vec3<u32>) {\n          let index = global_id.x;\n          let size = params.size;\n          if (index >= size) { return; }\n          output[index] = input1[index] + input2[index];\n        }\n      `],["sub",e=>`\n        @group(0) @binding(0) var<storage, read> input1: array<${e.dataType}>;\n        @group(0) @binding(1) var<storage, read> input2: array<${e.dataType}>;\n        @group(0) @binding(2) var<storage, read_write> output: array<${e.dataType}>;\n\n        struct Params {\n          size: u32,\n          param1: u32,\n          param2: u32,\n          param3: u32,\n        }\n        @group(0) @binding(3) var<uniform> params: Params;\n\n        @compute @workgroup_size(${e.workgroupSize.join(", ")})\n        fn main(@builtin(global_invocation_id) global_id: vec3<u32>) {\n          let index = global_id.x;\n          let size = params.size;\n          if (index >= size) { return; }\n          output[index] = input1[index] - input2[index];\n        }\n      `],["mul",e=>`\n        @group(0) @binding(0) var<storage, read> input1: array<${e.dataType}>;\n        @group(0) @binding(1) var<storage, read> input2: array<${e.dataType}>;\n        @group(0) @binding(2) var<storage, read_write> output: array<${e.dataType}>;\n\n        struct Params {\n          size: u32,\n          param1: u32,\n          param2: u32,\n          param3: u32,\n        }\n        @group(0) @binding(3) var<uniform> params: Params;\n\n        @compute @workgroup_size(${e.workgroupSize.join(", ")})\n        fn main(@builtin(global_invocation_id) global_id: vec3<u32>) {\n          let index = global_id.x;\n          let size = params.size;\n          if (index >= size) { return; }\n          output[index] = input1[index] * input2[index];\n        }\n      `],["div",e=>`\n        @group(0) @binding(0) var<storage, read> input1: array<${e.dataType}>;\n        @group(0) @binding(1) var<storage, read> input2: array<${e.dataType}>;\n        @group(0) @binding(2) var<storage, read_write> output: array<${e.dataType}>;\n        struct Params {\n          param0: u32,\n          param1: u32,\n          param2: u32,\n          param3: u32,\n        }\n        @group(0) @binding(3) var<uniform> params: Params;\n\n        @compute @workgroup_size(${e.workgroupSize.join(", ")})\n        fn main(@builtin(global_invocation_id) global_id: vec3<u32>) {\n          let index = global_id.x;\n          let size = params.param0;\n          if (index >= size) { return; }\n          output[index] = input1[index] / input2[index];\n        }\n      `],["pow",e=>`\n        @group(0) @binding(0) var<storage, read> input1: array<${e.dataType}>;\n        @group(0) @binding(1) var<storage, read> input2: array<${e.dataType}>;\n        @group(0) @binding(2) var<storage, read_write> output: array<${e.dataType}>;\n        struct Params {\n          param0: u32,\n          param1: u32,\n          param2: u32,\n          param3: u32,\n        }\n        @group(0) @binding(3) var<uniform> params: Params;\n\n        @compute @workgroup_size(${e.workgroupSize.join(", ")})\n        fn main(@builtin(global_invocation_id) global_id: vec3<u32>) {\n          let index = global_id.x;\n          let size = params.param0;\n          if (index >= size) { return; }\n          output[index] = pow(input1[index], input2[index]);\n        }\n      `],["matmul",e=>`\n        @group(0) @binding(0) var<storage, read> input1: array<${e.dataType}>;\n        @group(0) @binding(1) var<storage, read> input2: array<${e.dataType}>;\n        @group(0) @binding(2) var<storage, read_write> output: array<${e.dataType}>;\n\n        struct MatMulParams {\n          M: u32,    // rows of A\n          N: u32,    // cols of B\n          K: u32,    // cols of A, rows of B\n          reserved: u32,\n        }\n        @group(0) @binding(3) var<uniform> params: MatMulParams;\n\n        @compute @workgroup_size(${e.workgroupSize.join(", ")})\n        fn main(@builtin(global_invocation_id) global_id: vec3<u32>) {\n          let M = params.M;  // rows of A\n          let N = params.N;  // cols of B\n          let K = params.K;  // cols of A, rows of B\n\n          let row = global_id.x;\n          let col = global_id.y;\n\n          if (row >= M || col >= N) { return; }\n\n          var sum = 0.0;\n\n          // Simple matrix multiplication without tiling to avoid hangs\n          for (var k = 0u; k < K; k = k + 1u) {\n            sum = sum + input1[row * K + k] * input2[k * N + col];\n          }\n\n          output[row * N + col] = sum;\n        }\n      `],["bmm",e=>`\n        @group(0) @binding(0) var<storage, read> input1: array<${e.dataType}>;\n        @group(0) @binding(1) var<storage, read> input2: array<${e.dataType}>;\n        @group(0) @binding(2) var<storage, read_write> output: array<${e.dataType}>;\n        struct Params {\n          param0: u32,\n          param1: u32,\n          param2: u32,\n          param3: u32,\n        }\n        @group(0) @binding(3) var<uniform> params: Params;\n\n        @compute @workgroup_size(${e.workgroupSize.join(", ")})\n        fn main(@builtin(global_invocation_id) global_id: vec3<u32>) {\n          let batch = global_id.z;\n          let row = global_id.x;\n          let col = global_id.y;\n          \n          let B = params.param0;  // batch size\n          let M = params.param1;  // rows\n          let N = params.param2;  // cols of second matrix\n          let K = params.param3;  // cols of first matrix\n          \n          if (batch >= B || row >= M || col >= N) { return; }\n          \n          let batch_offset1 = batch * M * K;\n          let batch_offset2 = batch * K * N;\n          let batch_offset_out = batch * M * N;\n          \n          var sum = 0.0;\n          for (var k = 0u; k < K; k = k + 1u) {\n            sum = sum + input1[batch_offset1 + row * K + k] * input2[batch_offset2 + k * N + col];\n          }\n          output[batch_offset_out + row * N + col] = sum;\n        }\n      `],["transpose",e=>`\n        @group(0) @binding(0) var<storage, read> input: array<${e.dataType}>;\n        @group(0) @binding(1) var<storage, read_write> output: array<${e.dataType}>;\n        struct Params {\n          param0: u32,\n          param1: u32,\n          param2: u32,\n          param3: u32,\n        }\n        @group(0) @binding(2) var<uniform> params: Params;\n\n        @compute @workgroup_size(${e.workgroupSize.join(", ")})\n        fn main(@builtin(global_invocation_id) global_id: vec3<u32>) {\n          let index = global_id.x;\n          let rows = params.param0;\n          let cols = params.param1;\n          let size = rows * cols;\n          \n          if (index >= size) { return; }\n          \n          let row = index / cols;\n          let col = index % cols;\n          let transposed_index = col * rows + row;\n          \n          output[transposed_index] = input[index];\n        }\n      `],["relu",e=>`\n        @group(0) @binding(0) var<storage, read> input: array<${e.dataType}>;\n        @group(0) @binding(1) var<storage, read_write> output: array<${e.dataType}>;\n        struct Params {\n          param0: u32,\n          param1: u32,\n          param2: u32,\n          param3: u32,\n        }\n        @group(0) @binding(2) var<uniform> params: Params;\n\n        @compute @workgroup_size(${e.workgroupSize.join(", ")})\n        fn main(@builtin(global_invocation_id) global_id: vec3<u32>) {\n          let index = global_id.x;\n          let size = params.param0;\n          if (index >= size) { return; }\n          output[index] = max(input[index], 0.0);\n        }\n      `],["leaky_relu",e=>`\n        @group(0) @binding(0) var<storage, read> input: array<${e.dataType}>;\n        @group(0) @binding(1) var<storage, read_write> output: array<${e.dataType}>;\n        struct Params {\n          param0: u32,\n          param1: u32,\n          param2: u32,\n          param3: u32,\n        }\n        @group(0) @binding(2) var<uniform> params: Params;\n\n        @compute @workgroup_size(${e.workgroupSize.join(", ")})\n        fn main(@builtin(global_invocation_id) global_id: vec3<u32>) {\n          let index = global_id.x;\n          let size = params.param0;\n          let negative_slope = bitcast<f32>(params.param1);\n          if (index >= size) { return; }\n          let val = input[index];\n          output[index] = select(negative_slope * val, val, val > 0.0);\n        }\n      `],["sigmoid",e=>`\n        @group(0) @binding(0) var<storage, read> input: array<${e.dataType}>;\n        @group(0) @binding(1) var<storage, read_write> output: array<${e.dataType}>;\n        struct Params {\n          param0: u32,\n          param1: u32,\n          param2: u32,\n          param3: u32,\n        }\n        @group(0) @binding(2) var<uniform> params: Params;\n\n        @compute @workgroup_size(${e.workgroupSize.join(", ")})\n        fn main(@builtin(global_invocation_id) global_id: vec3<u32>) {\n          let index = global_id.x;\n          let size = params.param0;\n          if (index >= size) { return; }\n          output[index] = 1.0 / (1.0 + exp(-input[index]));\n        }\n      `],["tanh",e=>`\n        @group(0) @binding(0) var<storage, read> input: array<${e.dataType}>;\n        @group(0) @binding(1) var<storage, read_write> output: array<${e.dataType}>;\n        struct Params {\n          param0: u32,\n          param1: u32,\n          param2: u32,\n          param3: u32,\n        }\n        @group(0) @binding(2) var<uniform> params: Params;\n\n        @compute @workgroup_size(${e.workgroupSize.join(", ")})\n        fn main(@builtin(global_invocation_id) global_id: vec3<u32>) {\n          let index = global_id.x;\n          let size = params.param0;\n          if (index >= size) { return; }\n          output[index] = tanh(input[index]);\n        }\n      `],["gelu",e=>`\n        @group(0) @binding(0) var<storage, read> input: array<${e.dataType}>;\n        @group(0) @binding(1) var<storage, read_write> output: array<${e.dataType}>;\n        struct Params {\n          param0: u32,\n          param1: u32,\n          param2: u32,\n          param3: u32,\n        }\n        @group(0) @binding(2) var<uniform> params: Params;\n\n        @compute @workgroup_size(${e.workgroupSize.join(", ")})\n        fn main(@builtin(global_invocation_id) global_id: vec3<u32>) {\n          let index = global_id.x;\n          let size = params.param0;\n          if (index >= size) { return; }\n          let x = input[index];\n          // GELU approximation: 0.5 * x * (1 + tanh(sqrt(2/Ï€) * (x + 0.044715 * x^3)))\n          let sqrt_2_over_pi = 0.7978845608;\n          let inner = sqrt_2_over_pi * (x + 0.044715 * x * x * x);\n          output[index] = 0.5 * x * (1.0 + tanh(inner));\n        }\n      `],["softmax",e=>`\n        @group(0) @binding(0) var<storage, read> input: array<${e.dataType}>;\n        @group(0) @binding(1) var<storage, read_write> output: array<${e.dataType}>;\n        struct Params {\n          param0: u32,\n          param1: u32,\n          param2: u32,\n          param3: u32,\n        }\n        @group(0) @binding(2) var<uniform> params: Params;\n\n        var<workgroup> shared_max: f32;\n        var<workgroup> shared_sum: f32;\n\n        @compute @workgroup_size(${Math.min(e.workgroupSize[0],256)})\n        fn main(@builtin(global_invocation_id) global_id: vec3<u32>,\n                @builtin(local_invocation_id) local_id: vec3<u32>,\n                @builtin(workgroup_id) workgroup_id: vec3<u32>) {\n          let batch_size = params.param0;\n          let dim_size = params.param1;\n          let batch_idx = workgroup_id.x;\n          let local_idx = local_id.x;\n          \n          if (batch_idx >= batch_size) { return; }\n          \n          let batch_offset = batch_idx * dim_size;\n          \n          // Find maximum for numerical stability\n          var max_val = -1e38; // -FLT_MAX\n          for (var i = local_idx; i < dim_size; i = i + ${Math.min(e.workgroupSize[0],256)}u) {\n            max_val = max(max_val, input[batch_offset + i]);\n          }\n          \n          // Reduce maximum across workgroup\n          workgroupBarrier();\n          if (local_idx == 0u) {\n            shared_max = max_val;\n          }\n          for (var stride = 1u; stride < ${Math.min(e.workgroupSize[0],256)}u; stride = stride * 2u) {\n            workgroupBarrier();\n            if (local_idx >= stride) {\n              shared_max = max(shared_max, max_val);\n            }\n          }\n          workgroupBarrier();\n          \n          // Compute exponentials and sum\n          var sum = 0.0;\n          for (var i = local_idx; i < dim_size; i = i + ${Math.min(e.workgroupSize[0],256)}u) {\n            let exp_val = exp(input[batch_offset + i] - shared_max);\n            sum = sum + exp_val;\n            output[batch_offset + i] = exp_val;\n          }\n          \n          // Reduce sum across workgroup\n          workgroupBarrier();\n          if (local_idx == 0u) {\n            shared_sum = sum;\n          }\n          for (var stride = 1u; stride < ${Math.min(e.workgroupSize[0],256)}u; stride = stride * 2u) {\n            workgroupBarrier();\n            if (local_idx >= stride) {\n              shared_sum = shared_sum + sum;\n            }\n          }\n          workgroupBarrier();\n          \n          // Normalize\n          for (var i = local_idx; i < dim_size; i = i + ${Math.min(e.workgroupSize[0],256)}u) {\n            output[batch_offset + i] = output[batch_offset + i] / shared_sum;\n          }\n        }\n      `],["sum",e=>`\n        @group(0) @binding(0) var<storage, read> input: array<${e.dataType}>;\n        @group(0) @binding(1) var<storage, read_write> output: array<${e.dataType}>;\n        struct Params {\n          param0: u32,\n          param1: u32,\n          param2: u32,\n          param3: u32,\n        }\n        @group(0) @binding(2) var<uniform> params: Params;\n\n        var<workgroup> shared_data: array<f32, ${e.workgroupSize[0]}>;\n\n        @compute @workgroup_size(${e.workgroupSize[0]})\n        fn main(@builtin(global_invocation_id) global_id: vec3<u32>,\n                @builtin(local_invocation_id) local_id: vec3<u32>,\n                @builtin(workgroup_id) workgroup_id: vec3<u32>) {\n          let size = params.param0;\n          let local_idx = local_id.x;\n          let global_idx = global_id.x;\n          \n          // Load data into shared memory\n          var sum = 0.0;\n          for (var i = global_idx; i < size; i = i + ${e.workgroupSize[0]}u) {\n            sum = sum + input[i];\n          }\n          shared_data[local_idx] = sum;\n          \n          workgroupBarrier();\n          \n          // Parallel reduction\n          for (var stride = ${e.workgroupSize[0]/2}u; stride > 0u; stride = stride >> 1u) {\n            if (local_idx < stride) {\n              shared_data[local_idx] = shared_data[local_idx] + shared_data[local_idx + stride];\n            }\n            workgroupBarrier();\n          }\n          \n          if (local_idx == 0u) {\n            output[workgroup_id.x] = shared_data[0];\n          }\n        }\n      `],["mean",e=>`\n        @group(0) @binding(0) var<storage, read> input: array<${e.dataType}>;\n        @group(0) @binding(1) var<storage, read_write> output: array<${e.dataType}>;\n        struct Params {\n          param0: u32,\n          param1: u32,\n          param2: u32,\n          param3: u32,\n        }\n        @group(0) @binding(2) var<uniform> params: Params;\n\n        var<workgroup> shared_data: array<f32, ${e.workgroupSize[0]}>;\n\n        @compute @workgroup_size(${e.workgroupSize[0]})\n        fn main(@builtin(global_invocation_id) global_id: vec3<u32>,\n                @builtin(local_invocation_id) local_id: vec3<u32>,\n                @builtin(workgroup_id) workgroup_id: vec3<u32>) {\n          let size = params.param0;\n          let local_idx = local_id.x;\n          let global_idx = global_id.x;\n          \n          var sum = 0.0;\n          for (var i = global_idx; i < size; i = i + ${e.workgroupSize[0]}u) {\n            sum = sum + input[i];\n          }\n          shared_data[local_idx] = sum;\n          \n          workgroupBarrier();\n          \n          for (var stride = ${e.workgroupSize[0]/2}u; stride > 0u; stride = stride >> 1u) {\n            if (local_idx < stride) {\n              shared_data[local_idx] = shared_data[local_idx] + shared_data[local_idx + stride];\n            }\n            workgroupBarrier();\n          }\n          \n          if (local_idx == 0u) {\n            output[workgroup_id.x] = shared_data[0] / f32(size);\n          }\n        }\n      `],["conv2d",e=>`\n        @group(0) @binding(0) var<storage, read> input: array<${e.dataType}>;\n        @group(0) @binding(1) var<storage, read> weight: array<${e.dataType}>;\n        @group(0) @binding(2) var<storage, read> bias: array<${e.dataType}>;\n        @group(0) @binding(3) var<storage, read_write> output: array<${e.dataType}>;\n        struct ConvParams {\n          param0: u32,\n          param1: u32,\n          param2: u32,\n          param3: u32,\n          param4: u32,\n          param5: u32,\n          param6: u32,\n          param7: u32,\n        }\n        @group(0) @binding(4) var<uniform> params: ConvParams;\n\n        @compute @workgroup_size(${e.workgroupSize.join(", ")})\n        fn main(@builtin(global_invocation_id) global_id: vec3<u32>) {\n          let out_y = global_id.x;\n          let out_x = global_id.y;\n          let out_c = global_id.z;\n          \n          let batch_size = params.param0;\n          let in_channels = params.param1;\n          let in_height = params.param2;\n          let in_width = params.param3;\n          let out_channels = params.param4;\n          let out_height = params.param5;\n          let out_width = params.param6;\n          let kernel_size = params.param7;\n          \n          if (out_y >= out_height || out_x >= out_width || out_c >= out_channels) { return; }\n          \n          var sum = 0.0;\n          \n          for (var in_c = 0u; in_c < in_channels; in_c = in_c + 1u) {\n            for (var ky = 0u; ky < kernel_size; ky = ky + 1u) {\n              for (var kx = 0u; kx < kernel_size; kx = kx + 1u) {\n                let in_y = out_y + ky;\n                let in_x = out_x + kx;\n                \n                if (in_y < in_height && in_x < in_width) {\n                  let input_idx = in_c * in_height * in_width + in_y * in_width + in_x;\n                  let weight_idx = out_c * in_channels * kernel_size * kernel_size + \n                                  in_c * kernel_size * kernel_size + ky * kernel_size + kx;\n                  sum = sum + input[input_idx] * weight[weight_idx];\n                }\n              }\n            }\n          }\n          \n          sum = sum + bias[out_c];\n          let output_idx = out_c * out_height * out_width + out_y * out_width + out_x;\n          output[output_idx] = sum;\n        }\n      `],["maxpool2d",e=>`\n        @group(0) @binding(0) var<storage, read> input: array<${e.dataType}>;\n        @group(0) @binding(1) var<storage, read_write> output: array<${e.dataType}>;\n        struct PoolParams {\n          param0: u32,\n          param1: u32,\n          param2: u32,\n          param3: u32,\n          param4: u32,\n          param5: u32,\n          param6: u32,\n          param7: u32,\n        }\n        @group(0) @binding(2) var<uniform> params: PoolParams;\n\n        @compute @workgroup_size(${e.workgroupSize.join(", ")})\n        fn main(@builtin(global_invocation_id) global_id: vec3<u32>) {\n          let out_y = global_id.x;\n          let out_x = global_id.y;\n          let c = global_id.z;\n          \n          let channels = params.param0;\n          let in_height = params.param1;\n          let in_width = params.param2;\n          let out_height = params.param3;\n          let out_width = params.param4;\n          let kernel_size = params.param5;\n          let stride = params.param6;\n          \n          if (out_y >= out_height || out_x >= out_width || c >= channels) { return; }\n          \n          var max_val = -1e38; // -FLT_MAX\n          \n          for (var ky = 0u; ky < kernel_size; ky = ky + 1u) {\n            for (var kx = 0u; kx < kernel_size; kx = kx + 1u) {\n              let in_y = out_y * stride + ky;\n              let in_x = out_x * stride + kx;\n              \n              if (in_y < in_height && in_x < in_width) {\n                let input_idx = c * in_height * in_width + in_y * in_width + in_x;\n                max_val = max(max_val, input[input_idx]);\n              }\n            }\n          }\n          \n          let output_idx = c * out_height * out_width + out_y * out_width + out_x;\n          output[output_idx] = max_val;\n        }\n      `],["exp",e=>`\n        @group(0) @binding(0) var<storage, read> input: array<${e.dataType}>;\n        @group(0) @binding(1) var<storage, read_write> output: array<${e.dataType}>;\n        struct Params {\n          param0: u32,\n          param1: u32,\n          param2: u32,\n          param3: u32,\n        }\n        @group(0) @binding(2) var<uniform> params: Params;\n\n        @compute @workgroup_size(${e.workgroupSize.join(", ")})\n        fn main(@builtin(global_invocation_id) global_id: vec3<u32>) {\n          let index = global_id.x;\n          let size = params.param0;\n          if (index >= size) { return; }\n          output[index] = exp(input[index]);\n        }\n      `],["log",e=>`\n        @group(0) @binding(0) var<storage, read> input: array<${e.dataType}>;\n        @group(0) @binding(1) var<storage, read_write> output: array<${e.dataType}>;\n        struct Params {\n          param0: u32,\n          param1: u32,\n          param2: u32,\n          param3: u32,\n        }\n        @group(0) @binding(2) var<uniform> params: Params;\n\n        @compute @workgroup_size(${e.workgroupSize.join(", ")})\n        fn main(@builtin(global_invocation_id) global_id: vec3<u32>) {\n          let index = global_id.x;\n          let size = params.param0;\n          if (index >= size) { return; }\n          output[index] = log(input[index]);\n        }\n      `],["sqrt",e=>`\n        @group(0) @binding(0) var<storage, read> input: array<${e.dataType}>;\n        @group(0) @binding(1) var<storage, read_write> output: array<${e.dataType}>;\n        struct Params {\n          param0: u32,\n          param1: u32,\n          param2: u32,\n          param3: u32,\n        }\n        @group(0) @binding(2) var<uniform> params: Params;\n\n        @compute @workgroup_size(${e.workgroupSize.join(", ")})\n        fn main(@builtin(global_invocation_id) global_id: vec3<u32>) {\n          let index = global_id.x;\n          let size = params.param0;\n          if (index >= size) { return; }\n          output[index] = sqrt(input[index]);\n        }\n      `],["abs",e=>`\n        @group(0) @binding(0) var<storage, read> input: array<${e.dataType}>;\n        @group(0) @binding(1) var<storage, read_write> output: array<${e.dataType}>;\n        struct Params {\n          param0: u32,\n          param1: u32,\n          param2: u32,\n          param3: u32,\n        }\n        @group(0) @binding(2) var<uniform> params: Params;\n\n        @compute @workgroup_size(${e.workgroupSize.join(", ")})\n        fn main(@builtin(global_invocation_id) global_id: vec3<u32>) {\n          let index = global_id.x;\n          let size = params.param0;\n          if (index >= size) { return; }\n          output[index] = abs(input[index]);\n        }\n      `],["max",e=>`\n        @group(0) @binding(0) var<storage, read> input1: array<${e.dataType}>;\n        @group(0) @binding(1) var<storage, read> input2: array<${e.dataType}>;\n        @group(0) @binding(2) var<storage, read_write> output: array<${e.dataType}>;\n        struct Params {\n          param0: u32,\n          param1: u32,\n          param2: u32,\n          param3: u32,\n        }\n        @group(0) @binding(3) var<uniform> params: Params;\n\n        @compute @workgroup_size(${e.workgroupSize.join(", ")})\n        fn main(@builtin(global_invocation_id) global_id: vec3<u32>) {\n          let index = global_id.x;\n          let size = params.param0;\n          if (index >= size) { return; }\n          output[index] = max(input1[index], input2[index]);\n        }\n      `],["min",e=>`\n        @group(0) @binding(0) var<storage, read> input1: array<${e.dataType}>;\n        @group(0) @binding(1) var<storage, read> input2: array<${e.dataType}>;\n        @group(0) @binding(2) var<storage, read_write> output: array<${e.dataType}>;\n        struct Params {\n          param0: u32,\n          param1: u32,\n          param2: u32,\n          param3: u32,\n        }\n        @group(0) @binding(3) var<uniform> params: Params;\n\n        @compute @workgroup_size(${e.workgroupSize.join(", ")})\n        fn main(@builtin(global_invocation_id) global_id: vec3<u32>) {\n          let index = global_id.x;\n          let size = params.param0;\n          if (index >= size) { return; }\n          output[index] = min(input1[index], input2[index]);\n        }\n      `],["concat",e=>`\n        @group(0) @binding(0) var<storage, read> input1: array<${e.dataType}>;\n        @group(0) @binding(1) var<storage, read> input2: array<${e.dataType}>;\n        @group(0) @binding(2) var<storage, read_write> output: array<${e.dataType}>;\n        struct Params {\n          param0: u32,\n          param1: u32,\n          param2: u32,\n          param3: u32,\n        }\n        @group(0) @binding(3) var<uniform> params: Params;\n\n        @compute @workgroup_size(${e.workgroupSize.join(", ")})\n        fn main(@builtin(global_invocation_id) global_id: vec3<u32>) {\n          let index = global_id.x;\n          let size1 = params.param0;\n          let size2 = params.param1;\n          let total_size = size1 + size2;\n          \n          if (index >= total_size) { return; }\n          \n          if (index < size1) {\n            output[index] = input1[index];\n          } else {\n            output[index] = input2[index - size1];\n          }\n        }\n      `],["slice",e=>`\n        @group(0) @binding(0) var<storage, read> input: array<${e.dataType}>;\n        @group(0) @binding(1) var<storage, read_write> output: array<${e.dataType}>;\n        struct Params {\n          param0: u32,\n          param1: u32,\n          param2: u32,\n          param3: u32,\n        }\n        @group(0) @binding(2) var<uniform> params: Params;\n\n        @compute @workgroup_size(${e.workgroupSize.join(", ")})\n        fn main(@builtin(global_invocation_id) global_id: vec3<u32>) {\n          let index = global_id.x;\n          let start = params.param0;\n          let end = params.param1;\n          let step = params.param2;\n          let output_size = (end - start + step - 1u) / step;\n          \n          if (index >= output_size) { return; }\n          \n          let input_index = start + index * step;\n          output[index] = input[input_index];\n        }\n      `],["batch_norm",e=>`\n        @group(0) @binding(0) var<storage, read> input: array<${e.dataType}>;\n        @group(0) @binding(1) var<storage, read> running_mean: array<${e.dataType}>;\n        @group(0) @binding(2) var<storage, read> running_var: array<${e.dataType}>;\n        @group(0) @binding(3) var<storage, read> weight: array<${e.dataType}>;\n        @group(0) @binding(4) var<storage, read> bias: array<${e.dataType}>;\n        @group(0) @binding(5) var<storage, read_write> output: array<${e.dataType}>;\n        struct Params {\n          param0: u32,\n          param1: u32,\n          param2: u32,\n          param3: u32,\n        }\n        @group(0) @binding(6) var<uniform> params: Params;\n\n        @compute @workgroup_size(${e.workgroupSize.join(", ")})\n        fn main(@builtin(global_invocation_id) global_id: vec3<u32>) {\n          let index = global_id.x;\n          let batch_size = params.param0;\n          let channels = params.param1;\n          let spatial_size = params.param2;\n          let eps = bitcast<f32>(params.param3);\n          \n          if (index >= batch_size * channels * spatial_size) { return; }\n          \n          let c = (index / spatial_size) % channels;\n          let normalized = (input[index] - running_mean[c]) / sqrt(running_var[c] + eps);\n          output[index] = normalized * weight[c] + bias[c];\n        }\n      `],["cross_entropy",e=>`\n        @group(0) @binding(0) var<storage, read> logits: array<${e.dataType}>;\n        @group(0) @binding(1) var<storage, read> targets: array<u32>;\n        @group(0) @binding(2) var<storage, read_write> output: array<${e.dataType}>;\n        struct Params {\n          param0: u32,\n          param1: u32,\n          param2: u32,\n          param3: u32,\n        }\n        @group(0) @binding(3) var<uniform> params: Params;\n\n        @compute @workgroup_size(${e.workgroupSize[0]})\n        fn main(@builtin(global_invocation_id) global_id: vec3<u32>) {\n          let batch_idx = global_id.x;\n          let batch_size = params.param0;\n          let num_classes = params.param1;\n          \n          if (batch_idx >= batch_size) { return; }\n          \n          let batch_offset = batch_idx * num_classes;\n          let target_class = targets[batch_idx];\n          \n          // Find max for numerical stability\n          var max_logit = -1e38;\n          for (var i = 0u; i < num_classes; i = i + 1u) {\n            max_logit = max(max_logit, logits[batch_offset + i]);\n          }\n          \n          // Compute log-sum-exp\n          var sum_exp = 0.0;\n          for (var i = 0u; i < num_classes; i = i + 1u) {\n            sum_exp = sum_exp + exp(logits[batch_offset + i] - max_logit);\n          }\n          let log_sum_exp = log(sum_exp) + max_logit;\n          \n          // Cross entropy loss = -log(softmax[target])\n          let target_logit = logits[batch_offset + target_class];\n          output[batch_idx] = log_sum_exp - target_logit;\n        }\n      `],["mse_loss",e=>`\n        @group(0) @binding(0) var<storage, read> predictions: array<${e.dataType}>;\n        @group(0) @binding(1) var<storage, read> targets: array<${e.dataType}>;\n        @group(0) @binding(2) var<storage, read_write> output: array<${e.dataType}>;\n        struct Params {\n          param0: u32,\n          param1: u32,\n          param2: u32,\n          param3: u32,\n        }\n        @group(0) @binding(3) var<uniform> params: Params;\n\n        @compute @workgroup_size(${e.workgroupSize.join(", ")})\n        fn main(@builtin(global_invocation_id) global_id: vec3<u32>) {\n          let index = global_id.x;\n          let size = params.param0;\n          if (index >= size) { return; }\n          let diff = predictions[index] - targets[index];\n          output[index] = diff * diff;\n        }\n      `],["sin",e=>`\n        @group(0) @binding(0) var<storage, read> input: array<${e.dataType}>;\n        @group(0) @binding(1) var<storage, read_write> output: array<${e.dataType}>;\n        struct Params {\n          param0: u32,\n          param1: u32,\n          param2: u32,\n          param3: u32,\n        }\n        @group(0) @binding(2) var<uniform> params: Params;\n\n        @compute @workgroup_size(${e.workgroupSize.join(", ")})\n        fn main(@builtin(global_invocation_id) global_id: vec3<u32>) {\n          let index = global_id.x;\n          let size = params.param0;\n          if (index >= size) { return; }\n          output[index] = sin(input[index]);\n        }\n      `],["cos",e=>`\n        @group(0) @binding(0) var<storage, read> input: array<${e.dataType}>;\n        @group(0) @binding(1) var<storage, read_write> output: array<${e.dataType}>;\n        struct Params {\n          param0: u32,\n          param1: u32,\n          param2: u32,\n          param3: u32,\n        }\n        @group(0) @binding(2) var<uniform> params: Params;\n\n        @compute @workgroup_size(${e.workgroupSize.join(", ")})\n        fn main(@builtin(global_invocation_id) global_id: vec3<u32>) {\n          let index = global_id.x;\n          let size = params.param0;\n          if (index >= size) { return; }\n          output[index] = cos(input[index]);\n        }\n      `],["tan",e=>`\n        @group(0) @binding(0) var<storage, read> input: array<${e.dataType}>;\n        @group(0) @binding(1) var<storage, read_write> output: array<${e.dataType}>;\n        struct Params {\n          param0: u32,\n          param1: u32,\n          param2: u32,\n          param3: u32,\n        }\n        @group(0) @binding(2) var<uniform> params: Params;\n\n        @compute @workgroup_size(${e.workgroupSize.join(", ")})\n        fn main(@builtin(global_invocation_id) global_id: vec3<u32>) {\n          let index = global_id.x;\n          let size = params.param0;\n          if (index >= size) { return; }\n          output[index] = tan(input[index]);\n        }\n      `],["sinh",e=>`\n        @group(0) @binding(0) var<storage, read> input: array<${e.dataType}>;\n        @group(0) @binding(1) var<storage, read_write> output: array<${e.dataType}>;\n        struct Params {\n          param0: u32,\n          param1: u32,\n          param2: u32,\n          param3: u32,\n        }\n        @group(0) @binding(2) var<uniform> params: Params;\n\n        @compute @workgroup_size(${e.workgroupSize.join(", ")})\n        fn main(@builtin(global_invocation_id) global_id: vec3<u32>) {\n          let index = global_id.x;\n          let size = params.param0;\n          if (index >= size) { return; }\n          let x = input[index];\n          output[index] = (exp(x) - exp(-x)) / 2.0;\n        }\n      `],["cosh",e=>`\n        @group(0) @binding(0) var<storage, read> input: array<${e.dataType}>;\n        @group(0) @binding(1) var<storage, read_write> output: array<${e.dataType}>;\n        struct Params {\n          param0: u32,\n          param1: u32,\n          param2: u32,\n          param3: u32,\n        }\n        @group(0) @binding(2) var<uniform> params: Params;\n\n        @compute @workgroup_size(${e.workgroupSize.join(", ")})\n        fn main(@builtin(global_invocation_id) global_id: vec3<u32>) {\n          let index = global_id.x;\n          let size = params.param0;\n          if (index >= size) { return; }\n          let x = input[index];\n          output[index] = (exp(x) + exp(-x)) / 2.0;\n        }\n      `],["floor",e=>`\n        @group(0) @binding(0) var<storage, read> input: array<${e.dataType}>;\n        @group(0) @binding(1) var<storage, read_write> output: array<${e.dataType}>;\n        struct Params {\n          param0: u32,\n          param1: u32,\n          param2: u32,\n          param3: u32,\n        }\n        @group(0) @binding(2) var<uniform> params: Params;\n\n        @compute @workgroup_size(${e.workgroupSize.join(", ")})\n        fn main(@builtin(global_invocation_id) global_id: vec3<u32>) {\n          let index = global_id.x;\n          let size = params.param0;\n          if (index >= size) { return; }\n          output[index] = floor(input[index]);\n        }\n      `],["ceil",e=>`\n        @group(0) @binding(0) var<storage, read> input: array<${e.dataType}>;\n        @group(0) @binding(1) var<storage, read_write> output: array<${e.dataType}>;\n        struct Params {\n          param0: u32,\n          param1: u32,\n          param2: u32,\n          param3: u32,\n        }\n        @group(0) @binding(2) var<uniform> params: Params;\n\n        @compute @workgroup_size(${e.workgroupSize.join(", ")})\n        fn main(@builtin(global_invocation_id) global_id: vec3<u32>) {\n          let index = global_id.x;\n          let size = params.param0;\n          if (index >= size) { return; }\n          output[index] = ceil(input[index]);\n        }\n      `],["round",e=>`\n        @group(0) @binding(0) var<storage, read> input: array<${e.dataType}>;\n        @group(0) @binding(1) var<storage, read_write> output: array<${e.dataType}>;\n        struct Params {\n          param0: u32,\n          param1: u32,\n          param2: u32,\n          param3: u32,\n        }\n        @group(0) @binding(2) var<uniform> params: Params;\n\n        @compute @workgroup_size(${e.workgroupSize.join(", ")})\n        fn main(@builtin(global_invocation_id) global_id: vec3<u32>) {\n          let index = global_id.x;\n          let size = params.param0;\n          if (index >= size) { return; }\n          output[index] = round(input[index]);\n        }\n      `],["trunc",e=>`\n        @group(0) @binding(0) var<storage, read> input: array<${e.dataType}>;\n        @group(0) @binding(1) var<storage, read_write> output: array<${e.dataType}>;\n        struct Params {\n          param0: u32,\n          param1: u32,\n          param2: u32,\n          param3: u32,\n        }\n        @group(0) @binding(2) var<uniform> params: Params;\n\n        @compute @workgroup_size(${e.workgroupSize.join(", ")})\n        fn main(@builtin(global_invocation_id) global_id: vec3<u32>) {\n          let index = global_id.x;\n          let size = params.param0;\n          if (index >= size) { return; }\n          output[index] = trunc(input[index]);\n        }\n      `],["clamp",e=>`\n        @group(0) @binding(0) var<storage, read> input: array<${e.dataType}>;\n        @group(0) @binding(1) var<storage, read_write> output: array<${e.dataType}>;\n        struct Params {\n          param0: u32,\n          param1: u32,\n          param2: u32,\n          param3: u32,\n        }\n        @group(0) @binding(2) var<uniform> params: Params;\n\n        @compute @workgroup_size(${e.workgroupSize.join(", ")})\n        fn main(@builtin(global_invocation_id) global_id: vec3<u32>) {\n          let index = global_id.x;\n          let size = params.param0;\n          let min_val = bitcast<f32>(params.param1);\n          let max_val = bitcast<f32>(params.param2);\n          if (index >= size) { return; }\n          output[index] = clamp(input[index], min_val, max_val);\n        }\n      `],["eq",e=>`\n        @group(0) @binding(0) var<storage, read> input1: array<${e.dataType}>;\n        @group(0) @binding(1) var<storage, read> input2: array<${e.dataType}>;\n        @group(0) @binding(2) var<storage, read_write> output: array<u32>;\n        struct Params {\n          param0: u32,\n          param1: u32,\n          param2: u32,\n          param3: u32,\n        }\n        @group(0) @binding(3) var<uniform> params: Params;\n\n        @compute @workgroup_size(${e.workgroupSize.join(", ")})\n        fn main(@builtin(global_invocation_id) global_id: vec3<u32>) {\n          let index = global_id.x;\n          let size = params.param0;\n          if (index >= size) { return; }\n          output[index] = select(0u, 1u, input1[index] == input2[index]);\n        }\n      `],["ne",e=>`\n        @group(0) @binding(0) var<storage, read> input1: array<${e.dataType}>;\n        @group(0) @binding(1) var<storage, read> input2: array<${e.dataType}>;\n        @group(0) @binding(2) var<storage, read_write> output: array<u32>;\n        struct Params {\n          param0: u32,\n          param1: u32,\n          param2: u32,\n          param3: u32,\n        }\n        @group(0) @binding(3) var<uniform> params: Params;\n\n        @compute @workgroup_size(${e.workgroupSize.join(", ")})\n        fn main(@builtin(global_invocation_id) global_id: vec3<u32>) {\n          let index = global_id.x;\n          let size = params.param0;\n          if (index >= size) { return; }\n          output[index] = select(0u, 1u, input1[index] != input2[index]);\n        }\n      `],["lt",e=>`\n        @group(0) @binding(0) var<storage, read> input1: array<${e.dataType}>;\n        @group(0) @binding(1) var<storage, read> input2: array<${e.dataType}>;\n        @group(0) @binding(2) var<storage, read_write> output: array<u32>;\n        struct Params {\n          param0: u32,\n          param1: u32,\n          param2: u32,\n          param3: u32,\n        }\n        @group(0) @binding(3) var<uniform> params: Params;\n\n        @compute @workgroup_size(${e.workgroupSize.join(", ")})\n        fn main(@builtin(global_invocation_id) global_id: vec3<u32>) {\n          let index = global_id.x;\n          let size = params.param0;\n          if (index >= size) { return; }\n          output[index] = select(0u, 1u, input1[index] < input2[index]);\n        }\n      `],["le",e=>`\n        @group(0) @binding(0) var<storage, read> input1: array<${e.dataType}>;\n        @group(0) @binding(1) var<storage, read> input2: array<${e.dataType}>;\n        @group(0) @binding(2) var<storage, read_write> output: array<u32>;\n        struct Params {\n          param0: u32,\n          param1: u32,\n          param2: u32,\n          param3: u32,\n        }\n        @group(0) @binding(3) var<uniform> params: Params;\n\n        @compute @workgroup_size(${e.workgroupSize.join(", ")})\n        fn main(@builtin(global_invocation_id) global_id: vec3<u32>) {\n          let index = global_id.x;\n          let size = params.param0;\n          if (index >= size) { return; }\n          output[index] = select(0u, 1u, input1[index] <= input2[index]);\n        }\n      `],["gt",e=>`\n        @group(0) @binding(0) var<storage, read> input1: array<${e.dataType}>;\n        @group(0) @binding(1) var<storage, read> input2: array<${e.dataType}>;\n        @group(0) @binding(2) var<storage, read_write> output: array<u32>;\n        struct Params {\n          param0: u32,\n          param1: u32,\n          param2: u32,\n          param3: u32,\n        }\n        @group(0) @binding(3) var<uniform> params: Params;\n\n        @compute @workgroup_size(${e.workgroupSize.join(", ")})\n        fn main(@builtin(global_invocation_id) global_id: vec3<u32>) {\n          let index = global_id.x;\n          let size = params.param0;\n          if (index >= size) { return; }\n          output[index] = select(0u, 1u, input1[index] > input2[index]);\n        }\n      `],["ge",e=>`\n        @group(0) @binding(0) var<storage, read> input1: array<${e.dataType}>;\n        @group(0) @binding(1) var<storage, read> input2: array<${e.dataType}>;\n        @group(0) @binding(2) var<storage, read_write> output: array<u32>;\n        struct Params {\n          param0: u32,\n          param1: u32,\n          param2: u32,\n          param3: u32,\n        }\n        @group(0) @binding(3) var<uniform> params: Params;\n\n        @compute @workgroup_size(${e.workgroupSize.join(", ")})\n        fn main(@builtin(global_invocation_id) global_id: vec3<u32>) {\n          let index = global_id.x;\n          let size = params.param0;\n          if (index >= size) { return; }\n          output[index] = select(0u, 1u, input1[index] >= input2[index]);\n        }\n      `],["argmin",e=>`\n        @group(0) @binding(0) var<storage, read> input: array<${e.dataType}>;\n        @group(0) @binding(1) var<storage, read_write> output: array<u32>;\n        struct Params {\n          param0: u32,\n          param1: u32,\n          param2: u32,\n          param3: u32,\n        }\n        @group(0) @binding(2) var<uniform> params: Params;\n\n        var<workgroup> shared_vals: array<f32, ${e.workgroupSize[0]}>;\n        var<workgroup> shared_indices: array<u32, ${e.workgroupSize[0]}>;\n\n        @compute @workgroup_size(${e.workgroupSize[0]})\n        fn main(@builtin(global_invocation_id) global_id: vec3<u32>,\n                @builtin(local_invocation_id) local_id: vec3<u32>,\n                @builtin(workgroup_id) workgroup_id: vec3<u32>) {\n          let size = params.param0;\n          let local_idx = local_id.x;\n          let global_idx = global_id.x;\n          \n          // Initialize with first valid element or max value\n          var min_val = 1e38; // FLT_MAX\n          var min_idx = 0u;\n          \n          // Find minimum in this thread's portion\n          for (var i = global_idx; i < size; i = i + ${e.workgroupSize[0]}u) {\n            if (input[i] < min_val) {\n              min_val = input[i];\n              min_idx = i;\n            }\n          }\n          \n          shared_vals[local_idx] = min_val;\n          shared_indices[local_idx] = min_idx;\n          workgroupBarrier();\n          \n          // Parallel reduction to find global minimum\n          for (var stride = ${e.workgroupSize[0]/2}u; stride > 0u; stride = stride >> 1u) {\n            if (local_idx < stride) {\n              if (shared_vals[local_idx + stride] < shared_vals[local_idx]) {\n                shared_vals[local_idx] = shared_vals[local_idx + stride];\n                shared_indices[local_idx] = shared_indices[local_idx + stride];\n              }\n            }\n            workgroupBarrier();\n          }\n          \n          if (local_idx == 0u) {\n            output[workgroup_id.x] = shared_indices[0];\n          }\n        }\n      `],["argmax",e=>`\n        @group(0) @binding(0) var<storage, read> input: array<${e.dataType}>;\n        @group(0) @binding(1) var<storage, read_write> output: array<u32>;\n        struct Params {\n          param0: u32,\n          param1: u32,\n          param2: u32,\n          param3: u32,\n        }\n        @group(0) @binding(2) var<uniform> params: Params;\n\n        var<workgroup> shared_vals: array<f32, ${e.workgroupSize[0]}>;\n        var<workgroup> shared_indices: array<u32, ${e.workgroupSize[0]}>;\n\n        @compute @workgroup_size(${e.workgroupSize[0]})\n        fn main(@builtin(global_invocation_id) global_id: vec3<u32>,\n                @builtin(local_invocation_id) local_id: vec3<u32>,\n                @builtin(workgroup_id) workgroup_id: vec3<u32>) {\n          let size = params.param0;\n          let local_idx = local_id.x;\n          let global_idx = global_id.x;\n          \n          // Initialize with first valid element or min value\n          var max_val = -1e38; // -FLT_MAX\n          var max_idx = 0u;\n          \n          // Find maximum in this thread's portion\n          for (var i = global_idx; i < size; i = i + ${e.workgroupSize[0]}u) {\n            if (input[i] > max_val) {\n              max_val = input[i];\n              max_idx = i;\n            }\n          }\n          \n          shared_vals[local_idx] = max_val;\n          shared_indices[local_idx] = max_idx;\n          workgroupBarrier();\n          \n          // Parallel reduction to find global maximum\n          for (var stride = ${e.workgroupSize[0]/2}u; stride > 0u; stride = stride >> 1u) {\n            if (local_idx < stride) {\n              if (shared_vals[local_idx + stride] > shared_vals[local_idx]) {\n                shared_vals[local_idx] = shared_vals[local_idx + stride];\n                shared_indices[local_idx] = shared_indices[local_idx + stride];\n              }\n            }\n            workgroupBarrier();\n          }\n          \n          if (local_idx == 0u) {\n            output[workgroup_id.x] = shared_indices[0];\n          }\n        }\n      `]])}static getOptimalWorkgroupSize(e,t,r){const a=r?.maxComputeWorkgroupSizeX||256,n=r?.maxComputeWorkgroupSizeY||256,i=r?.maxComputeWorkgroupSizeZ||64,s=r?.maxComputeInvocationsPerWorkgroup||256,o=Array.isArray(t)?t.reduce((e,t)=>e*t,1):t||1;switch(e){case"matmul":const e=Math.min(16,Math.sqrt(s));return[Math.min(e,a),Math.min(e,n),1];case"bmm":const t=Math.min(8,Math.sqrt(s/2));return[Math.min(t,a),Math.min(t,n),Math.min(4,i)];case"conv2d":return[Math.min(8,a),Math.min(8,n),Math.min(4,i)];case"softmax":return[Math.min(256,a),1,1];case"sum":case"mean":case"argmin":case"argmax":const r=Math.min(256,a);return[Math.pow(2,Math.floor(Math.log2(r))),1,1];case"transpose":const u=Math.min(16,Math.sqrt(s));return[u,u,1];case"maxpool2d":case"avgpool2d":return[Math.min(16,a),Math.min(16,n),1];case"add":case"sub":case"mul":case"div":case"relu":case"sigmoid":case"tanh":case"exp":case"log":case"sqrt":case"abs":return o<1024?[Math.min(32,a),1,1]:o<65536?[Math.min(64,a),1,1]:[Math.min(128,a),1,1];default:return[Math.min(64,a),1,1]}}static getBufferLayout(e,t=2,r=1){return{add:{inputs:2,outputs:1,uniforms:1},sub:{inputs:2,outputs:1,uniforms:1},mul:{inputs:2,outputs:1,uniforms:1},div:{inputs:2,outputs:1,uniforms:1},pow:{inputs:2,outputs:1,uniforms:1},matmul:{inputs:2,outputs:1,uniforms:1},bmm:{inputs:2,outputs:1,uniforms:1},relu:{inputs:1,outputs:1,uniforms:1},sigmoid:{inputs:1,outputs:1,uniforms:1},tanh:{inputs:1,outputs:1,uniforms:1},gelu:{inputs:1,outputs:1,uniforms:1},leaky_relu:{inputs:1,outputs:1,uniforms:1},softmax:{inputs:1,outputs:1,uniforms:1},exp:{inputs:1,outputs:1,uniforms:1},log:{inputs:1,outputs:1,uniforms:1},sqrt:{inputs:1,outputs:1,uniforms:1},abs:{inputs:1,outputs:1,uniforms:1},sin:{inputs:1,outputs:1,uniforms:1},cos:{inputs:1,outputs:1,uniforms:1},tan:{inputs:1,outputs:1,uniforms:1},sinh:{inputs:1,outputs:1,uniforms:1},cosh:{inputs:1,outputs:1,uniforms:1},floor:{inputs:1,outputs:1,uniforms:1},ceil:{inputs:1,outputs:1,uniforms:1},round:{inputs:1,outputs:1,uniforms:1},trunc:{inputs:1,outputs:1,uniforms:1},clamp:{inputs:1,outputs:1,uniforms:1},conv2d:{inputs:3,outputs:1,uniforms:1},batch_norm:{inputs:5,outputs:1,uniforms:1},cross_entropy:{inputs:2,outputs:1,uniforms:1},eq:{inputs:2,outputs:1,uniforms:1},ne:{inputs:2,outputs:1,uniforms:1},lt:{inputs:2,outputs:1,uniforms:1},le:{inputs:2,outputs:1,uniforms:1},gt:{inputs:2,outputs:1,uniforms:1},ge:{inputs:2,outputs:1,uniforms:1},sum:{inputs:1,outputs:1,uniforms:1},mean:{inputs:1,outputs:1,uniforms:1},argmin:{inputs:1,outputs:1,uniforms:1},argmax:{inputs:1,outputs:1,uniforms:1}}[e]||{inputs:t,outputs:r,uniforms:1}}static generateParams(e,t,a={}){const n=new Uint32Array(4);switch(("undefined"!=typeof window&&window.greedDebugWebGPU||void 0!==r.g&&r.g.greedDebugWebGPU)&&Array.isArray(t)&&t.forEach((e,t)=>{}),e){case"matmul":n[0]=t[0].shape?.[0]||Math.sqrt(t[0].length),n[1]=t[1].shape?.[1]||Math.sqrt(t[1].length),n[2]=t[0].shape?.[1]||Math.sqrt(t[0].length),n[3]=0;break;case"bmm":n[0]=t[0].shape?.[0]||1,n[1]=t[0].shape?.[1]||Math.sqrt(t[0].length),n[2]=t[1].shape?.[2]||Math.sqrt(t[1].length),n[3]=t[0].shape?.[2]||Math.sqrt(t[0].length);break;case"conv2d":const e=t[0].shape||[1,1,28,28];t[1].shape,n[0]=e[0],n[1]=e[1],n[2]=e[2],n[3]=e[3];break;case"softmax":const r=t[0].shape||[1,t[0].length];n[0]=r.length>1?r[0]:1,n[1]=r.length>1?r[1]:r[0],n[2]=0,n[3]=0;break;case"leaky_relu":n[0]=t[0].length,n[1]=new Uint32Array(new Float32Array([a.negativeSlope||.01]).buffer)[0],n[2]=0,n[3]=0;break;case"clamp":n[0]=t[0].length,n[1]=new Uint32Array(new Float32Array([a.minVal||-1e38]).buffer)[0],n[2]=new Uint32Array(new Float32Array([a.maxVal||1e38]).buffer)[0],n[3]=0;break;case"argmin":case"argmax":n[0]=t[0].length,n[1]=a.dim||0,n[2]=0,n[3]=0;break;default:n[0]=Array.isArray(t)?t[0].length:t.length,n[1]=0,n[2]=0,n[3]=0}return n}}class o extends a.A{constructor(e,t={}){super(),this.device=e,this.config={maxCacheSize:t.maxCacheSize||100,enableWarmup:!1!==t.enableWarmup,enableMetrics:!1!==t.enableMetrics,shaderOptimization:t.shaderOptimization||"balanced",...t},this.pipelines=new Map,this.shaderModules=new Map,this.bindGroupLayouts=new Map,this.accessOrder=new Map,this.compilationQueue=new Map,this.stats={hits:0,misses:0,compilations:0,evictions:0,averageCompileTime:0,totalCompileTime:0},this.shaderTemplates=s.getShaderTemplates()}async get(e,t={}){const r=this._generateKey(e,t);if(this.pipelines.has(r))return this._updateAccess(r),this.stats.hits++,this.emit("cache:hit",{operation:e,key:r}),this.pipelines.get(r);if(this.compilationQueue.has(r))return this.emit("cache:wait",{operation:e,key:r}),await this.compilationQueue.get(r);this.stats.misses++,this.emit("cache:miss",{operation:e,key:r});const a=this._compilePipeline(e,t,r);this.compilationQueue.set(r,a);try{const e=await a;return this.compilationQueue.delete(r),e}catch(e){throw this.compilationQueue.delete(r),e}}async warmup(e=null){if(!this.config.enableWarmup)return;const t=e||["add","multiply","matmul","relu","sigmoid","softmax","conv2d","maxpool","transpose"];this.emit("warmup:start",{operations:t});const r=performance.now(),a=t.map(async e=>{try{await this.get(e,{warmup:!0}),this.emit("warmup:operation",{operation:e})}catch(t){this.emit("warmup:error",{operation:e,error:t})}});await Promise.allSettled(a);const n=performance.now()-r;this.emit("warmup:complete",{operations:t,duration:n})}getBindGroupLayout(e,t={}){const r=this._generateLayoutKey(e,t);if(this.bindGroupLayouts.has(r))return this.bindGroupLayouts.get(r);const a=this._createBindGroupLayout(e,t);return this.bindGroupLayouts.set(r,a),a}getOptimalWorkgroupSize(e,t,r){return s.getOptimalWorkgroupSize(e,t,r)}generateOperationParams(e,t,r={}){return s.generateParams(e,t,r)}async createShaderModule(e,t={}){const r=this._hashString(e);if(this.shaderModules.has(r))return this.shaderModules.get(r);try{const a=this.device.createShaderModule({code:e,...t});return this.shaderModules.set(r,a),this.emit("shader:compiled",{hash:r,size:e.length}),a}catch(t){throw this.emit("shader:error",{hash:r,error:t,source:e.substring(0,100)}),t}}generateShader(e,t={}){const r=this.shaderTemplates.get(e);if(!r)throw new Error(`No shader template found for operation: ${e}`);return r({workgroupSize:t.workgroupSize||[8,8,1],dataType:t.dataType||"f32",optimization:this.config.shaderOptimization,...t})}getStats(){const e=this.stats.hits+this.stats.misses>0?this.stats.hits/(this.stats.hits+this.stats.misses):0;return{...this.stats,hitRate:e,cacheSize:this.pipelines.size,shaderCacheSize:this.shaderModules.size,layoutCacheSize:this.bindGroupLayouts.size,averageCompileTimeMs:Math.round(100*this.stats.averageCompileTime)/100}}clear(){this.pipelines.clear(),this.shaderModules.clear(),this.bindGroupLayouts.clear(),this.accessOrder.clear(),this.compilationQueue.clear(),this.stats.hits=0,this.stats.misses=0,this.emit("cache:cleared")}cleanup(){this.clear(),this.shaderTemplates.clear(),this.emit("cleanup:complete")}async _compilePipeline(e,t,r){const a=performance.now();try{const n=this.generateShader(e,t),i=await this.createShaderModule(n),s=this.getBindGroupLayout(e,t),o=this.device.createPipelineLayout({bindGroupLayouts:[s]}),u=await this.device.createComputePipelineAsync({layout:o,compute:{module:i,entryPoint:"main"}});this.pipelines.set(r,u),this._updateAccess(r),this._enforceMaxCacheSize();const p=performance.now()-a;return this.stats.compilations++,this.stats.totalCompileTime+=p,this.stats.averageCompileTime=this.stats.totalCompileTime/this.stats.compilations,this.emit("pipeline:compiled",{operation:e,key:r,compileTime:p,cacheSize:this.pipelines.size}),u}catch(t){throw this.emit("pipeline:error",{operation:e,key:r,error:t}),t}}_generateKey(e,t){return[e,t.workgroupSize?.join(",")||"8,8,1",t.dataType||"f32",t.inputCount||2,t.outputCount||1,JSON.stringify(t.constants||{})].join("|")}_generateLayoutKey(e,t){return`${e}|${t.inputCount||2}|${t.outputCount||1}`}_createBindGroupLayout(e,t){const r=s.getBufferLayout(e,t.inputCount,t.outputCount),a=[];for(let e=0;e<r.inputs;e++)a.push({binding:e,visibility:GPUShaderStage.COMPUTE,buffer:{type:"read-only-storage"}});for(let e=0;e<r.outputs;e++)a.push({binding:r.inputs+e,visibility:GPUShaderStage.COMPUTE,buffer:{type:"storage"}});return r.uniforms>0&&a.push({binding:r.inputs+r.outputs,visibility:GPUShaderStage.COMPUTE,buffer:{type:"uniform"}}),this.device.createBindGroupLayout({entries:a})}_updateAccess(e){this.accessOrder.set(e,performance.now())}_enforceMaxCacheSize(){if(this.pipelines.size<=this.config.maxCacheSize)return;let e=null,t=1/0;for(const[r,a]of this.accessOrder.entries())a<t&&(t=a,e=r);e&&(this.pipelines.delete(e),this.accessOrder.delete(e),this.stats.evictions++,this.emit("cache:eviction",{key:e,cacheSize:this.pipelines.size}))}_hashString(e){let t=0;for(let r=0;r<e.length;r++)t=(t<<5)-t+e.charCodeAt(r),t&=t;return t.toString(36)}}const u=o;var p=r(626);class l extends a.A{constructor(e={}){super(),this.config={powerPreference:e.powerPreference||"high-performance",enableProfiling:!1!==e.enableProfiling,maxBufferSize:e.maxBufferSize||268435456,workgroupSize:e.workgroupSize||[64,1,1],enableValidation:!1!==e.enableValidation,...e},this.adapter=null,this.device=null,this.isInitialized=!1,this.bufferManager=null,this.pipelineCache=null,this.supportedFeatures=new Set,this.limits=null,this.stats={computeOperations:0,totalExecutionTime:0,averageExecutionTime:0,memoryUsage:0,lastOperationTime:0}}async initialize(){if(this.isInitialized)return!0;try{if(this.emit("init:start"),!navigator.gpu)throw new Error("WebGPU not supported in this browser");if(this.adapter=await navigator.gpu.requestAdapter({powerPreference:this.config.powerPreference}),!this.adapter)throw new Error("Failed to get WebGPU adapter");this.supportedFeatures=this.adapter.features,this.limits=this.adapter.limits,this.emit("init:adapter",{features:Array.from(this.supportedFeatures),limits:this.limits});const e={requiredFeatures:[],requiredLimits:{}};return this.supportedFeatures.has("timestamp-query")&&e.requiredFeatures.push("timestamp-query"),this.device=await this.adapter.requestDevice(e),this.device.addEventListener("uncapturederror",e=>{const t=e.error;this.emit("device:error",{error:t,type:"uncaptured",timestamp:Date.now()}),p.A.error("WebGPU uncaptured error:",{type:t.constructor.name,message:t.message,stack:t.stack}),this._handleDeviceError(t)}),this.bufferManager=new i(this.device,{maxBufferSize:this.config.maxBufferSize,enablePooling:!0,maxPoolSize:100}),this.pipelineCache=new u(this.device,{maxCacheSize:50,enableWarmup:!0,shaderOptimization:"balanced"}),this._setupEventForwarding(),await this.pipelineCache.warmup(),this.isInitialized=!0,this.emit("init:complete",{device:this.device,features:Array.from(this.supportedFeatures)}),!0}catch(e){return this.emit("init:error",{error:e,timestamp:Date.now()}),p.A.error("WebGPU initialization failed:",{type:e.constructor.name,message:e.message,stack:e.stack,config:this.config}),this.isInitialized=!1,this.initFailureReason=e.message,!1}}async execute(e,t,r={}){if(!this.isInitialized)throw new Error("WebGPU compute engine not initialized");const a=performance.now();this.emit("compute:start",{operation:e,options:r});try{this._validateOperation(e,t,r);const n=Array.isArray(t)?t:[t],i=this.pipelineCache.getOptimalWorkgroupSize(e,n[0].shape||[n[0].length],this.limits);let s;try{s=await this.pipelineCache.get(e,{workgroupSize:r.workgroupSize||i,dataType:r.dataType||"f32",inputCount:n.length,outputCount:r.outputCount||1,...r})}catch(e){throw e}const o=await this._prepareBuffers(t,e,r),u=this._createBindGroup(s,o,r),p=await this._executeComputePass(s,u,o,{...r,operation:e}),l=performance.now()-a;return this._updateStats(e,l,o),this._cleanupBuffersAsync(o,r),this.emit("compute:complete",{operation:e,executionTime:l,resultSize:p.length}),p}catch(n){const i=performance.now()-a,s={operation:e,error:{type:n.constructor.name,message:n.message,stack:n.stack},executionTime:i,tensors:Array.isArray(t)?t.length:1,options:r,deviceStable:this.deviceStable??!0,timestamp:Date.now()};throw this.emit("compute:error",s),p.A.error("WebGPU compute operation failed:",s),(n.message.includes("out of memory")||"GPUOutOfMemoryError"===n.constructor.name)&&(p.A.warn("GPU memory exhausted, attempting emergency cleanup"),await this.bufferManager.emergencyCleanup(),this.emit("recovery:memory",{operation:e,timestamp:Date.now()})),n}}async executeBatch(e,t={}){const{parallel:r=!1,maxConcurrency:a=4}=t;if(r){const t=new c(a),r=e.map(async e=>{await t.acquire();try{return await this.execute(e.operation,e.tensors,e.options)}finally{t.release()}});return Promise.all(r)}{const t=[];for(const r of e){const e=await this.execute(r.operation,r.tensors,r.options);t.push(e)}return t}}async uploadTensor(e,t={}){const{usage:r=GPUBufferUsage.STORAGE|GPUBufferUsage.COPY_DST,forceNew:a=!1}=t;if(!a){const t=this.bufferManager.findReusableBuffer(e.byteLength||4*e.length,r);if(t)return this.device.queue.writeBuffer(t,0,e),t}return await this.bufferManager.createMappedBuffer(e,r)}async downloadTensor(e,t,r={}){const{format:a=Float32Array}=r,n=this.bufferManager.allocate(4*t,GPUBufferUsage.COPY_DST|GPUBufferUsage.MAP_READ);try{const r=this.device.createCommandEncoder();r.copyBufferToBuffer(e,0,n,0,4*t),this.device.queue.submit([r.finish()]),await n.mapAsync(GPUMapMode.READ);const i=new a(n.getMappedRange().slice());return n.unmap(),i}finally{this.bufferManager.release(n,{forceDestroy:!0})}}getStats(){return{...this.stats,bufferStats:this.bufferManager?.getStats()||{},pipelineStats:this.pipelineCache?.getStats()||{},deviceLimits:this.limits,supportedFeatures:Array.from(this.supportedFeatures||[])}}async cleanup(){this.emit("cleanup:start");try{this.bufferManager&&(await this.bufferManager.cleanup(),this.bufferManager=null),this.pipelineCache&&(this.pipelineCache.cleanup(),this.pipelineCache=null),this.device&&(this.device.destroy(),this.device=null),this.adapter=null,this.isInitialized=!1,this.emit("cleanup:complete")}catch(e){throw this.emit("cleanup:error",{error:e}),e}}_validateOperation(e,t,r){if(!e||"string"!=typeof e)throw new Error("Operation must be a non-empty string");if(!t)throw new Error("Tensors parameter is required");const a=Array.isArray(t)?t:[t];for(const e of a)if(!e||!ArrayBuffer.isView(e)&&!(e instanceof ArrayBuffer)){const t={tensorType:typeof e,constructor:e?.constructor?.name,isArrayBufferView:ArrayBuffer.isView(e),isArrayBuffer:e instanceof ArrayBuffer,hasData:e&&void 0!==e.data,dataType:e?.data?typeof e.data:"undefined"};throw new Error(`Invalid tensor data type. Expected typed array or ArrayBuffer, got: ${JSON.stringify(t)}`)}}_isDebugEnabled(){try{return"undefined"!=typeof window&&window.greedDebugWebGPU||void 0!==r.g&&r.g.greedDebugWebGPU}catch{return!1}}async _prepareBuffers(e,t,r){const a=Array.isArray(e)?e:[e],n={inputs:[],output:null,params:null};for(let e=0;e<a.length;e++){const t=await this.uploadTensor(a[e]);n.inputs.push(t)}const i=this._calculateOutputSize(t,a,r);n.output=this.bufferManager.allocate(4*i,GPUBufferUsage.STORAGE|GPUBufferUsage.COPY_SRC);const s=this.pipelineCache.generateOperationParams(t,a,r);return n.params=await this.uploadTensor(s,{usage:GPUBufferUsage.UNIFORM|GPUBufferUsage.COPY_DST}),n}_createBindGroup(e,t,r){const a=[];for(let e=0;e<t.inputs.length;e++)a.push({binding:e,resource:{buffer:t.inputs[e]}});return a.push({binding:t.inputs.length,resource:{buffer:t.output}}),a.push({binding:t.inputs.length+1,resource:{buffer:t.params}}),this.device.createBindGroup({layout:e.getBindGroupLayout(0),entries:a})}async _executeComputePass(e,t,r,a){const n=this.device.createCommandEncoder(),i=n.beginComputePass();i.setPipeline(e),i.setBindGroup(0,t);const s=a.workgroupSize||this.config.workgroupSize,o=r.output.size/4;let u,p=1,l=1;if("matmul"===a.operation||"bmm"===a.operation){const e=this._getMatrixDimensions(a);u=Math.ceil(e.M/s[0]),p=Math.ceil(e.N/s[1]),"bmm"===a.operation&&(l=e.B)}else u=Math.ceil(o/s[0]);i.dispatchWorkgroups(u,p,l),i.end();const c=n.finish();return this.device.queue.submit([c]),await this._waitForGPUCompletion(5e3),this._downloadTensorOptimized(r.output,o,a)}_calculateOutputSize(e,t,r){if(r.outputSize)return r.outputSize;const a=t[0],n=e=>ArrayBuffer.isView(e)?e.length:e.byteLength/4;switch(e){case"matmul":return(t[0].shape?.[0]||Math.sqrt(n(t[0])))*(t[1].shape?.[1]||Math.sqrt(n(t[1])));case"bmm":const e=t[0].shape?.[0]||1;return e*(t[0].shape?.[1]||Math.sqrt(n(t[0])/e))*(t[1].shape?.[2]||Math.sqrt(n(t[1])/e));case"conv2d":const i=t[0].shape?.[2]||28,s=t[0].shape?.[3]||28,o=t[1].shape?.[0]||32;return(t[0].shape?.[0]||1)*o*i*s;case"transpose":case"softmax":default:return n(a);case"sum":case"mean":return r.keepDim?n(a):1;case"maxpool2d":case"avgpool2d":const u=r.kernelSize||2,p=r.stride||u,l=t[0].shape?.[2]||28,c=t[0].shape?.[3]||28,d=Math.floor((l-u)/p)+1,m=Math.floor((c-u)/p)+1,h=t[0].shape?.[1]||1;return(t[0].shape?.[0]||1)*h*d*m}}_updateStats(e,t,r){this.stats.computeOperations++,this.stats.totalExecutionTime+=t,this.stats.averageExecutionTime=this.stats.totalExecutionTime/this.stats.computeOperations,this.stats.lastOperationTime=t;const a=r.inputs.reduce((e,t)=>e+t.size,0)+r.output.size;this.stats.memoryUsage=Math.max(this.stats.memoryUsage,a)}_getMatrixDimensions(e){return{M:e.M||Math.sqrt(e.inputSize||256),N:e.N||Math.sqrt(e.inputSize||256),K:e.K||Math.sqrt(e.inputSize||256),B:e.B||1}}async _downloadTensorOptimized(e,t,r={}){const{format:a=Float32Array,usePooledBuffer:n=!0}=r;let i;n&&(i=this.bufferManager.findReusableBuffer(4*t,GPUBufferUsage.COPY_DST|GPUBufferUsage.MAP_READ)),i||(i=this.bufferManager.allocate(4*t,GPUBufferUsage.COPY_DST|GPUBufferUsage.MAP_READ));try{const r=this.device.createCommandEncoder();r.copyBufferToBuffer(e,0,i,0,4*t),this.device.queue.submit([r.finish()]),await this._waitForGPUCompletion(3e3);const n=i.mapAsync(GPUMapMode.READ),s=new Promise((e,t)=>{setTimeout(()=>t(new Error("Buffer mapping timeout")),2e3)});await Promise.race([n,s]);const o=new a(i.getMappedRange().slice());return i.unmap(),o}finally{n?this.bufferManager.returnToPool(i):this.bufferManager.release(i,{forceDestroy:!0})}}async _waitForGPUCompletion(e=5e3){return new Promise(e=>{setTimeout(()=>{e()},100)})}_cleanupBuffersAsync(e,t){setTimeout(()=>{try{for(const r of e.inputs)!1!==t.reuseInputBuffers?this.bufferManager.returnToPool(r):this.bufferManager.release(r,{forceDestroy:!1});e.params&&!1!==t.reuseParamBuffers?this.bufferManager.returnToPool(e.params):e.params&&this.bufferManager.release(e.params,{forceDestroy:!1})}catch(t){this.emit("cleanup:error",{error:t,buffers:e})}},0)}async executeBatchOptimized(e,t={}){const{parallel:r=!1,maxConcurrency:a=4,reuseBuffers:n=!0,shareComputePass:i=!1}=t,s=this._groupOperationsByType(e),o=[];for(const[e,u]of s.entries())if(i&&this._canShareComputePass(e)){const e=await this._executeBatchedComputePass(u,t);o.push(...e)}else if(r){const e=new c(a),t=u.map(async t=>{await e.acquire();try{return await this.execute(t.operation,t.tensors,{...t.options,reuseInputBuffers:n,reuseParamBuffers:n})}finally{e.release()}}),r=await Promise.all(t);o.push(...r)}else for(const e of u){const t=await this.execute(e.operation,e.tensors,{...e.options,reuseInputBuffers:n,reuseParamBuffers:n});o.push(t)}return o}_groupOperationsByType(e){const t=new Map;for(const r of e){const e=r.operation;t.has(e)||t.set(e,[]),t.get(e).push(r)}return t}_canShareComputePass(e){return["add","sub","mul","div","relu","sigmoid","tanh"].includes(e)}async _executeBatchedComputePass(e,t){const r=[];for(const a of e){const e=await this.execute(a.operation,a.tensors,{...a.options,...t});r.push(e)}return r}_setupEventForwarding(){this.bufferManager.on("buffer:created",e=>this.emit("buffer:created",e)),this.bufferManager.on("buffer:destroyed",e=>this.emit("buffer:destroyed",e)),this.bufferManager.on("gc:complete",e=>this.emit("buffer:gc",e)),this.pipelineCache.on("cache:miss",e=>this.emit("pipeline:miss",e)),this.pipelineCache.on("pipeline:compiled",e=>this.emit("pipeline:compiled",e)),this.pipelineCache.on("warmup:complete",e=>this.emit("pipeline:warmup",e))}_handleDeviceError(e){const t=e.constructor.name;switch(t){case"GPUOutOfMemoryError":p.A.warn("GPU out of memory, attempting buffer cleanup"),this.bufferManager.emergencyCleanup(),this.emit("recovery:attempt",{type:"memory-cleanup",timestamp:Date.now()});break;case"GPUInternalError":p.A.warn("GPU internal error, marking device as potentially unstable"),this.deviceStable=!1,this.emit("device:unstable",{reason:"internal-error",timestamp:Date.now()});break;case"GPUValidationError":p.A.warn("GPU validation error, this may indicate shader or pipeline issues"),this.emit("validation:error",{error:e,timestamp:Date.now()});break;default:p.A.warn("Unknown GPU error type:",t),this.emit("error:unknown",{error:e,timestamp:Date.now()})}}getErrorDiagnostics(){return{isInitialized:this.isInitialized,deviceStable:this.deviceStable??!0,initFailureReason:this.initFailureReason||null,bufferStats:this.bufferManager?.getStats()||null,pipelineStats:this.pipelineCache?.getStats()||null,supportedFeatures:Array.from(this.supportedFeatures||[]),timestamp:Date.now()}}}class c{constructor(e){this.max=e,this.current=0,this.queue=[]}async acquire(){return new Promise(e=>{this.current<this.max?(this.current++,e()):this.queue.push(e)})}release(){if(this.current--,this.queue.length>0){const e=this.queue.shift();this.current++,e()}}}const d=l;class m extends a.A{constructor(e={}){super(),this.config={enableOptimizations:!1!==e.enableOptimizations,maxConcurrentOps:e.maxConcurrentOps||2,enableProfiling:!1!==e.enableProfiling,chunkSize:e.chunkSize||1e4,...e},this.isInitialized=!1,this.runtime=null,this.numpy=null,this.stats={operations:0,totalExecutionTime:0,averageExecutionTime:0,lastOperationTime:0,supportedOperations:new Set(["add","subtract","multiply","divide","matmul","transpose","reshape","sum","mean","max","min","relu","sigmoid","tanh","softmax","exp","log","sqrt","power","abs","sign","clip"])},this.operations=this._initializeOperations()}async initialize(e=null){if(this.isInitialized)return!0;try{return this.emit("init:start"),e&&(this.runtime=e,this.numpy=e.getGlobal("np")),this.runtime&&await this._installCPUOperations(),this.isInitialized=!0,this.emit("init:complete",{supportedOperations:Array.from(this.stats.supportedOperations)}),!0}catch(e){throw this.emit("init:error",{error:e}),e}}async execute(e,t,r={}){if(!this.isInitialized)throw new Error("CPU engine not initialized");const a=performance.now();this.emit("compute:start",{operation:e,options:r});try{if(!this.stats.supportedOperations.has(e))throw new Error(`Unsupported CPU operation: ${e}`);const n=this.operations[e];if(!n)throw new Error(`Operation implementation not found: ${e}`);const i=await n(t,r),s=performance.now()-a;return this._updateStats(s),this.emit("compute:complete",{operation:e,executionTime:s,resultSize:this._getResultSize(i)}),i}catch(t){const r=performance.now()-a;throw this.emit("compute:error",{operation:e,error:t,executionTime:r}),t}}async executeBatch(e,t={}){const{sequential:r=!1}=t;if(r){const t=[];for(const r of e){const e=await this.execute(r.operation,r.tensors,r.options);t.push(e)}return t}{const t=new h(this.config.maxConcurrentOps),r=e.map(async e=>{await t.acquire();try{return await this.execute(e.operation,e.tensors,e.options)}finally{t.release()}});return Promise.all(r)}}getStats(){return{...this.stats,isInitialized:this.isInitialized,config:this.config,type:"cpu"}}async cleanup(){try{this.emit("cleanup:start"),this.isInitialized=!1,this.runtime=null,this.numpy=null,this.emit("cleanup:complete")}catch(e){throw this.emit("cleanup:error",{error:e}),e}}async _installCPUOperations(){await this.runtime.runPython('\nimport numpy as np\nfrom typing import Union, List, Tuple, Optional\n\nclass CPUTensorOps:\n    """CPU-optimized tensor operations using NumPy"""\n    \n    @staticmethod\n    def add(a: np.ndarray, b: np.ndarray) -> np.ndarray:\n        return np.add(a, b)\n    \n    @staticmethod\n    def subtract(a: np.ndarray, b: np.ndarray) -> np.ndarray:\n        return np.subtract(a, b)\n    \n    @staticmethod\n    def multiply(a: np.ndarray, b: np.ndarray) -> np.ndarray:\n        return np.multiply(a, b)\n    \n    @staticmethod\n    def divide(a: np.ndarray, b: np.ndarray) -> np.ndarray:\n        return np.divide(a, b)\n    \n    @staticmethod\n    def matmul(a: np.ndarray, b: np.ndarray) -> np.ndarray:\n        return np.matmul(a, b)\n    \n    @staticmethod\n    def transpose(a: np.ndarray, axes: Optional[Tuple] = None) -> np.ndarray:\n        return np.transpose(a, axes)\n    \n    @staticmethod\n    def reshape(a: np.ndarray, shape: Tuple) -> np.ndarray:\n        return np.reshape(a, shape)\n    \n    @staticmethod\n    def sum(a: np.ndarray, axis: Optional[Union[int, Tuple]] = None, keepdims: bool = False) -> np.ndarray:\n        return np.sum(a, axis=axis, keepdims=keepdims)\n    \n    @staticmethod\n    def mean(a: np.ndarray, axis: Optional[Union[int, Tuple]] = None, keepdims: bool = False) -> np.ndarray:\n        return np.mean(a, axis=axis, keepdims=keepdims)\n    \n    @staticmethod\n    def max(a: np.ndarray, axis: Optional[Union[int, Tuple]] = None, keepdims: bool = False) -> np.ndarray:\n        return np.max(a, axis=axis, keepdims=keepdims)\n    \n    @staticmethod\n    def min(a: np.ndarray, axis: Optional[Union[int, Tuple]] = None, keepdims: bool = False) -> np.ndarray:\n        return np.min(a, axis=axis, keepdims=keepdims)\n    \n    @staticmethod\n    def relu(a: np.ndarray) -> np.ndarray:\n        return np.maximum(a, 0)\n    \n    @staticmethod\n    def sigmoid(a: np.ndarray) -> np.ndarray:\n        return 1 / (1 + np.exp(-np.clip(a, -250, 250)))  # Prevent overflow\n    \n    @staticmethod\n    def tanh(a: np.ndarray) -> np.ndarray:\n        return np.tanh(a)\n    \n    @staticmethod\n    def softmax(a: np.ndarray, axis: int = -1) -> np.ndarray:\n        # Stable softmax implementation\n        x_max = np.max(a, axis=axis, keepdims=True)\n        exp_x = np.exp(a - x_max)\n        return exp_x / np.sum(exp_x, axis=axis, keepdims=True)\n    \n    @staticmethod\n    def exp(a: np.ndarray) -> np.ndarray:\n        return np.exp(np.clip(a, -250, 250))  # Prevent overflow\n    \n    @staticmethod\n    def log(a: np.ndarray) -> np.ndarray:\n        return np.log(np.maximum(a, 1e-12))  # Prevent log(0)\n    \n    @staticmethod\n    def sqrt(a: np.ndarray) -> np.ndarray:\n        return np.sqrt(np.maximum(a, 0))  # Prevent sqrt of negative\n    \n    @staticmethod\n    def power(a: np.ndarray, b: Union[np.ndarray, float]) -> np.ndarray:\n        return np.power(a, b)\n    \n    @staticmethod\n    def abs(a: np.ndarray) -> np.ndarray:\n        return np.abs(a)\n    \n    @staticmethod\n    def sign(a: np.ndarray) -> np.ndarray:\n        return np.sign(a)\n    \n    @staticmethod\n    def clip(a: np.ndarray, min_val: float, max_val: float) -> np.ndarray:\n        return np.clip(a, min_val, max_val)\n\n# Install globally\ncpu_ops = CPUTensorOps()\n',{captureOutput:!1}),this.emit("operations:installed",{count:this.stats.supportedOperations.size})}_initializeOperations(){return{add:async(e,t)=>this._executePythonOp("cpu_ops.add",e,t),subtract:async(e,t)=>this._executePythonOp("cpu_ops.subtract",e,t),multiply:async(e,t)=>this._executePythonOp("cpu_ops.multiply",e,t),divide:async(e,t)=>this._executePythonOp("cpu_ops.divide",e,t),matmul:async(e,t)=>this._executePythonOp("cpu_ops.matmul",e,t),transpose:async(e,t)=>{const r=t.axes?`axes=${JSON.stringify(t.axes)}`:"";return this._executePythonOp("cpu_ops.transpose",e,{axes:r})},reshape:async(e,t)=>{if(!t.shape)throw new Error("Reshape operation requires shape parameter");return this._executePythonOp("cpu_ops.reshape",e,t)},sum:async(e,t)=>this._executePythonOp("cpu_ops.sum",e,t),mean:async(e,t)=>this._executePythonOp("cpu_ops.mean",e,t),max:async(e,t)=>this._executePythonOp("cpu_ops.max",e,t),min:async(e,t)=>this._executePythonOp("cpu_ops.min",e,t),relu:async(e,t)=>this._executePythonOp("cpu_ops.relu",e,t),sigmoid:async(e,t)=>this._executePythonOp("cpu_ops.sigmoid",e,t),tanh:async(e,t)=>this._executePythonOp("cpu_ops.tanh",e,t),softmax:async(e,t)=>this._executePythonOp("cpu_ops.softmax",e,t),exp:async(e,t)=>this._executePythonOp("cpu_ops.exp",e,t),log:async(e,t)=>this._executePythonOp("cpu_ops.log",e,t),sqrt:async(e,t)=>this._executePythonOp("cpu_ops.sqrt",e,t),power:async(e,t)=>this._executePythonOp("cpu_ops.power",e,t),abs:async(e,t)=>this._executePythonOp("cpu_ops.abs",e,t),sign:async(e,t)=>this._executePythonOp("cpu_ops.sign",e,t),clip:async(e,t)=>{if(void 0===t.min||void 0===t.max)throw new Error("Clip operation requires min and max parameters");return this._executePythonOp("cpu_ops.clip",e,t)}}}async _executePythonOp(e,t,r){if(!this.runtime)throw new Error("Runtime not available for CPU operations");try{const a=[],n=Array.isArray(t)?t:[t];for(let e=0;e<n.length;e++){const t=`tensor_${e}`;this.runtime.setGlobal(t,n[e]),a.push(t)}let i=`${e}(${a.join(", ")})`;if(r){const t=[];for(const[e,a]of Object.entries(r))"axes"===e?t.push(`${e}=${a}`):"string"==typeof a?t.push(`${e}="${a}"`):Array.isArray(a)?t.push(`${e}=${JSON.stringify(a)}`):t.push(`${e}=${a}`);t.length>0&&(i=`${e}(${a.join(", ")}, ${t.join(", ")})`)}const s=`\nresult = ${i}\nresult.tolist() if hasattr(result, 'tolist') else result\n`,o=await this.runtime.runPython(s,{captureOutput:!0,timeout:r.timeout||1e4});for(const e of a)await this.runtime.runPython(`del ${e}`,{captureOutput:!1});return o}catch(e){throw new Error(`CPU operation failed: ${e.message}`)}}_updateStats(e){this.stats.operations++,this.stats.totalExecutionTime+=e,this.stats.averageExecutionTime=this.stats.totalExecutionTime/this.stats.operations,this.stats.lastOperationTime=e}_getResultSize(e){return Array.isArray(e)||ArrayBuffer.isView(e)?e.length:e instanceof ArrayBuffer?e.byteLength/4:1}}class h{constructor(e){this.max=e,this.current=0,this.queue=[]}async acquire(){return new Promise(e=>{this.current<this.max?(this.current++,e()):this.queue.push(e)})}release(){if(this.current--,this.queue.length>0){const e=this.queue.shift();this.current++,e()}}}const g=m;class f extends a.A{constructor(e={}){super(),this.config={maxWorkers:e.maxWorkers||navigator.hardwareConcurrency||4,workerTimeout:e.workerTimeout||3e4,enableLoadBalancing:!1!==e.enableLoadBalancing,queueMaxSize:e.queueMaxSize||100,...e},this.isInitialized=!1,this.workers=[],this.availableWorkers=[],this.busyWorkers=new Map,this.taskQueue=[],this.stats={workers:0,operations:0,totalExecutionTime:0,averageExecutionTime:0,queuedOperations:0,failedOperations:0,workerRestarts:0},this.nextTaskId=1,this.pendingTasks=new Map}async initialize(){if(this.isInitialized)return!0;try{return this.emit("init:start",{maxWorkers:this.config.maxWorkers}),await this._createWorkerPool(),this._startTaskProcessor(),this.isInitialized=!0,this.emit("init:complete",{workers:this.workers.length,ready:this.availableWorkers.length}),!0}catch(e){throw this.emit("init:error",{error:e}),e}}async execute(e,t,r={}){if(!this.isInitialized)throw new Error("Worker engine not initialized");return new Promise((a,n)=>{const i=this.nextTaskId++,s=performance.now(),o={id:i,operation:e,tensors:t,options:r,startTime:s,resolve:a,reject:n,timeout:setTimeout(()=>{this._handleTaskTimeout(i)},r.timeout||this.config.workerTimeout)};this.pendingTasks.set(i,o),this._queueTask(o),this.emit("task:queued",{taskId:i,operation:e,queueSize:this.taskQueue.length})})}async executeBatch(e,t={}){const{parallel:r=!0,maxConcurrency:a=this.config.maxWorkers,loadBalance:n=this.config.enableLoadBalancing}=t;if(!r){const t=[];for(const r of e){const e=await this.execute(r.operation,r.tensors,r.options);t.push(e)}return t}if(n){const t=this._distributeOperations(e).map(e=>this.execute(e.operation,e.tensors,e.options));return Promise.all(t)}const i=new y(a),s=e.map(async e=>{await i.acquire();try{return await this.execute(e.operation,e.tensors,e.options)}finally{i.release()}});return Promise.all(s)}getStats(){return{...this.stats,isInitialized:this.isInitialized,availableWorkers:this.availableWorkers.length,busyWorkers:this.busyWorkers.size,queuedTasks:this.taskQueue.length,pendingTasks:this.pendingTasks.size,type:"worker"}}async cleanup(){try{this.emit("cleanup:start");for(const[e,t]of this.pendingTasks.entries())clearTimeout(t.timeout),t.reject(new Error("Worker engine shutting down"));this.pendingTasks.clear(),this.taskQueue=[];for(const e of this.workers)e.terminate();this.workers=[],this.availableWorkers=[],this.busyWorkers.clear(),this.isInitialized=!1,this.emit("cleanup:complete")}catch(e){throw this.emit("cleanup:error",{error:e}),e}}async _createWorkerPool(){const e=this._generateWorkerScript(),t=new Blob([e],{type:"application/javascript"}),r=URL.createObjectURL(t);try{for(let e=0;e<this.config.maxWorkers;e++){const t=new Worker(r),a=e;t.addEventListener("message",e=>{this._handleWorkerMessage(a,e)}),t.addEventListener("error",e=>{this._handleWorkerError(a,e)}),t.addEventListener("messageerror",e=>{this._handleWorkerError(a,e)}),this.workers.push(t),this.availableWorkers.push(a),this.stats.workers++,this.emit("worker:created",{workerId:a})}}finally{URL.revokeObjectURL(r)}}_generateWorkerScript(){return"\n// Worker script for tensor operations\nclass WorkerTensorOps {\n  constructor() {\n    this.operations = {\n      add: (a, b) => a.map((val, i) => val + b[i]),\n      subtract: (a, b) => a.map((val, i) => val - b[i]),\n      multiply: (a, b) => a.map((val, i) => val * b[i]),\n      divide: (a, b) => a.map((val, i) => val / (b[i] || 1e-12)),\n      \n      matmul: (a, b, shapeA, shapeB) => {\n        if (shapeA.length !== 2 || shapeB.length !== 2) {\n          throw new Error('Matrix multiplication requires 2D arrays');\n        }\n        \n        const [rowsA, colsA] = shapeA;\n        const [rowsB, colsB] = shapeB;\n        \n        if (colsA !== rowsB) {\n          throw new Error('Matrix dimensions incompatible for multiplication');\n        }\n        \n        const result = new Array(rowsA * colsB).fill(0);\n        \n        for (let i = 0; i < rowsA; i++) {\n          for (let j = 0; j < colsB; j++) {\n            let sum = 0;\n            for (let k = 0; k < colsA; k++) {\n              sum += a[i * colsA + k] * b[k * colsB + j];\n            }\n            result[i * colsB + j] = sum;\n          }\n        }\n        \n        return result;\n      },\n      \n      transpose: (a, shape) => {\n        if (shape.length !== 2) {\n          throw new Error('Transpose currently supports only 2D arrays');\n        }\n        \n        const [rows, cols] = shape;\n        const result = new Array(rows * cols);\n        \n        for (let i = 0; i < rows; i++) {\n          for (let j = 0; j < cols; j++) {\n            result[j * rows + i] = a[i * cols + j];\n          }\n        }\n        \n        return result;\n      },\n      \n      sum: (a, axis) => {\n        if (axis === null || axis === undefined) {\n          return a.reduce((sum, val) => sum + val, 0);\n        }\n        // Simplified sum along axis (would need full tensor implementation)\n        return a.reduce((sum, val) => sum + val, 0);\n      },\n      \n      mean: (a, axis) => {\n        const sum = this.operations.sum(a, axis);\n        return Array.isArray(sum) ? sum.map(val => val / a.length) : sum / a.length;\n      },\n      \n      relu: (a) => a.map(val => Math.max(0, val)),\n      \n      sigmoid: (a) => a.map(val => 1 / (1 + Math.exp(-Math.max(-250, Math.min(250, val))))),\n      \n      tanh: (a) => a.map(val => Math.tanh(val)),\n      \n      softmax: (a) => {\n        const maxVal = Math.max(...a);\n        const exp = a.map(val => Math.exp(val - maxVal));\n        const sum = exp.reduce((s, val) => s + val, 0);\n        return exp.map(val => val / sum);\n      },\n      \n      exp: (a) => a.map(val => Math.exp(Math.max(-250, Math.min(250, val)))),\n      \n      log: (a) => a.map(val => Math.log(Math.max(1e-12, val))),\n      \n      sqrt: (a) => a.map(val => Math.sqrt(Math.max(0, val))),\n      \n      abs: (a) => a.map(val => Math.abs(val)),\n      \n      power: (a, b) => {\n        if (Array.isArray(b)) {\n          return a.map((val, i) => Math.pow(val, b[i]));\n        } else {\n          return a.map(val => Math.pow(val, b));\n        }\n      }\n    };\n  }\n  \n  execute(operation, tensors, options = {}) {\n    try {\n      const op = this.operations[operation];\n      if (!op) {\n        throw new Error(`Unsupported operation: ${operation}`);\n      }\n      \n      // Convert tensors to arrays if needed\n      const tensorArrays = tensors.map(tensor => {\n        if (tensor.data && tensor.shape) {\n          return { data: Array.from(tensor.data), shape: tensor.shape };\n        } else if (Array.isArray(tensor)) {\n          return { data: tensor, shape: [tensor.length] };\n        } else {\n          return { data: Array.from(tensor), shape: [tensor.length] };\n        }\n      });\n      \n      // Execute operation\n      let result;\n      switch (operation) {\n        case 'matmul':\n          result = op(tensorArrays[0].data, tensorArrays[1].data, \n                      tensorArrays[0].shape, tensorArrays[1].shape);\n          break;\n        case 'transpose':\n          result = op(tensorArrays[0].data, tensorArrays[0].shape);\n          break;\n        case 'power':\n          if (tensorArrays.length > 1) {\n            result = op(tensorArrays[0].data, tensorArrays[1].data);\n          } else {\n            result = op(tensorArrays[0].data, options.exponent || 2);\n          }\n          break;\n        default:\n          if (tensorArrays.length === 1) {\n            result = op(tensorArrays[0].data, options.axis);\n          } else {\n            result = op(tensorArrays[0].data, tensorArrays[1].data);\n          }\n      }\n      \n      return result;\n    } catch (error) {\n      throw new Error(`Worker operation failed: ${error.message}`);\n    }\n  }\n}\n\nconst tensorOps = new WorkerTensorOps();\n\nself.addEventListener('message', function(event) {\n  const { taskId, operation, tensors, options } = event.data;\n  \n  try {\n    const startTime = performance.now();\n    const result = tensorOps.execute(operation, tensors, options);\n    const executionTime = performance.now() - startTime;\n    \n    self.postMessage({\n      taskId,\n      success: true,\n      result,\n      executionTime\n    });\n  } catch (error) {\n    self.postMessage({\n      taskId,\n      success: false,\n      error: error.message\n    });\n  }\n});\n"}_queueTask(e){if(this.taskQueue.length>=this.config.queueMaxSize)return e.reject(new Error("Worker queue full")),void this.stats.failedOperations++;this.taskQueue.push(e),this.stats.queuedOperations++,this._processTaskQueue()}_startTaskProcessor(){setInterval(()=>{this._processTaskQueue()},10)}_processTaskQueue(){for(;this.taskQueue.length>0&&this.availableWorkers.length>0;){const e=this.taskQueue.shift(),t=this.availableWorkers.shift();this.busyWorkers.set(t,e),this.workers[t].postMessage({taskId:e.id,operation:e.operation,tensors:e.tensors,options:e.options}),this.emit("task:started",{taskId:e.id,workerId:t,operation:e.operation})}}_handleWorkerMessage(e,t){const{taskId:r,success:a,result:n,error:i,executionTime:s}=t.data,o=this.pendingTasks.get(r);if(!o)return void p.A.warn("Received message for unknown task:",{taskId:r,workerId:e,availableTasks:Array.from(this.pendingTasks.keys())});clearTimeout(o.timeout),this.pendingTasks.delete(r),this.busyWorkers.delete(e),this.availableWorkers.push(e);const u=performance.now()-o.startTime;this.stats.operations++,this.stats.totalExecutionTime+=u,this.stats.averageExecutionTime=this.stats.totalExecutionTime/this.stats.operations,a?(o.resolve(n),this.emit("task:completed",{taskId:r,workerId:e,executionTime:u,workerTime:s})):(this.stats.failedOperations++,o.reject(new Error(i)),this.emit("task:failed",{taskId:r,workerId:e,error:i,executionTime:u}))}_handleWorkerError(e,t){this.emit("worker:error",{workerId:e,error:t});const r=this.busyWorkers.get(e);r&&(clearTimeout(r.timeout),this.pendingTasks.delete(r.id),this.busyWorkers.delete(e),r.reject(new Error(`Worker error: ${t.message||t}`)),this.stats.failedOperations++),this._restartWorker(e)}_handleTaskTimeout(e){const t=this.pendingTasks.get(e);if(t){this.pendingTasks.delete(e);for(const[t,r]of this.busyWorkers.entries())if(r.id===e){this.busyWorkers.delete(t),this._restartWorker(t);break}this.stats.failedOperations++,t.reject(new Error(`Task timeout after ${this.config.workerTimeout}ms`)),this.emit("task:timeout",{taskId:e,timeout:this.config.workerTimeout})}}async _restartWorker(e){try{this.workers[e]?.terminate();const t=this._generateWorkerScript(),r=new Blob([t],{type:"application/javascript"}),a=URL.createObjectURL(r),n=new Worker(a);URL.revokeObjectURL(a),n.addEventListener("message",t=>{this._handleWorkerMessage(e,t)}),n.addEventListener("error",t=>{this._handleWorkerError(e,t)}),this.workers[e]=n,this.availableWorkers.push(e),this.stats.workerRestarts++,this.emit("worker:restarted",{workerId:e})}catch(t){this.emit("worker:restart-failed",{workerId:e,error:t})}}_distributeOperations(e){return e.map((e,t)=>({...e,preferredWorker:t%this.config.maxWorkers}))}}class y{constructor(e){this.max=e,this.current=0,this.queue=[]}async acquire(){return new Promise(e=>{this.current<this.max?(this.current++,e()):this.queue.push(e)})}release(){if(this.current--,this.queue.length>0){const e=this.queue.shift();this.current++,e()}}}const _=f;class b extends a.A{constructor(e={}){super(),this.config={webgpuMinElements:e.webgpuMinElements||1e3,workerMinElements:e.workerMinElements||1e4,maxConcurrentOperations:e.maxConcurrentOperations||4,memoryThresholdMB:e.memoryThresholdMB||512,enableAutoFallback:!1!==e.enableAutoFallback,fallbackTimeout:e.fallbackTimeout||5e3,enableAdaptiveSelection:!1!==e.enableAdaptiveSelection,performanceHistorySize:e.performanceHistorySize||100,...e},this.webgpu=new d(e.webgpu||{}),this.cpu=new g(e.cpu||{}),this.worker=new _(e.worker||{}),this.isInitialized=!1,this.availableStrategies=new Set,this.currentOperations=new Map,this.performanceHistory=new Map,this.strategyPreferences=new Map,this.resourceMonitor={memoryUsage:0,activeOperations:0,gpuUtilization:0}}async initialize(){if(this.isInitialized)return this.availableStrategies;this.emit("init:start");try{try{if(await this.webgpu.initialize())this.availableStrategies.add("webgpu"),this._setupEngineForwarding(this.webgpu,"webgpu"),this.emit("init:webgpu-success",{message:"WebGPU engine initialized successfully"});else{const e=this.webgpu.initFailureReason||"Unknown WebGPU initialization failure";this.emit("init:webgpu-failed",{error:new Error(e),details:"WebGPU engine initialization returned false"})}}catch(e){this.emit("init:webgpu-failed",{error:e})}await this.cpu.initialize(),this.availableStrategies.add("cpu"),this._setupEngineForwarding(this.cpu,"cpu");try{await this.worker.initialize(),this.availableStrategies.add("worker"),this._setupEngineForwarding(this.worker,"worker")}catch(e){this.emit("init:worker-failed",{error:e})}return this.isInitialized=!0,this.emit("init:complete",{strategies:Array.from(this.availableStrategies)}),this.availableStrategies}catch(e){throw this.emit("init:error",{error:e}),e}}async execute(e,t,r={}){if(!this.isInitialized)throw new Error("ComputeStrategy not initialized. Call initialize() first.");const a=performance.now(),n=this._generateOperationId();this.emit("execute:start",{operation:e,operationId:n,options:r});try{const i=await this._selectStrategy(e,t,r);this.currentOperations.set(n,{operation:e,strategy:i.name,startTime:a,tensors:Array.isArray(t)?t.length:1}),this.resourceMonitor.activeOperations++;const s=await this._executeWithFallback(i,e,t,r),o=performance.now()-a;return this._recordPerformance(e,i.name,o,t),this.currentOperations.delete(n),this.resourceMonitor.activeOperations--,this.emit("execute:complete",{operation:e,operationId:n,strategy:i.name,executionTime:o,resultSize:s.length}),s}catch(t){throw this.currentOperations.delete(n),this.resourceMonitor.activeOperations--,this.emit("execute:error",{operation:e,operationId:n,error:t}),t}}async executeBatch(e,t={}){const{parallel:r=!0,maxConcurrency:a=this.config.maxConcurrentOperations,loadBalance:n=!0}=t;if(!r){const t=[];for(const r of e){const e=await this.execute(r.operation,r.tensors,r.options);t.push(e)}return t}if(n)return this._executeWithLoadBalancing(e,a);const i=new w(a),s=e.map(async e=>{await i.acquire();try{return await this.execute(e.operation,e.tensors,e.options)}finally{i.release()}});return Promise.all(s)}getStats(){const e={availableStrategies:Array.from(this.availableStrategies),activeOperations:this.resourceMonitor.activeOperations,resourceMonitor:{...this.resourceMonitor},strategyPreferences:Object.fromEntries(this.strategyPreferences),engines:{}};return this.availableStrategies.has("webgpu")&&(e.engines.webgpu=this.webgpu.getStats()),this.availableStrategies.has("cpu")&&(e.engines.cpu=this.cpu.getStats()),this.availableStrategies.has("worker")&&(e.engines.worker=this.worker.getStats()),e}setStrategyPreference(e,t){if(!this.availableStrategies.has(t))throw new Error(`Strategy '${t}' not available`);this.strategyPreferences.set(e,t),this.emit("strategy:preference-set",{operation:e,strategy:t})}resetAdaptiveSelection(){this.performanceHistory.clear(),this.strategyPreferences.clear(),this.emit("strategy:reset")}async cleanup(){this.emit("cleanup:start");try{const e=[];this.webgpu&&e.push(this.webgpu.cleanup()),this.cpu&&e.push(this.cpu.cleanup()),this.worker&&e.push(this.worker.cleanup()),await Promise.all(e),this.availableStrategies.clear(),this.currentOperations.clear(),this.performanceHistory.clear(),this.isInitialized=!1,this.emit("cleanup:complete")}catch(e){throw this.emit("cleanup:error",{error:e}),e}}async _selectStrategy(e,t,r){if(r.strategy&&this.availableStrategies.has(r.strategy))return this._getEngine(r.strategy);if(this.config.enableAdaptiveSelection&&this.strategyPreferences.has(e)){const t=this.strategyPreferences.get(e);if(this.availableStrategies.has(t))return this._getEngine(t)}const a=this._calculateWorkloadSize(t),n=this._estimateComplexity(e,t),i=this._assessResourcePressure();return this._shouldUseWebGPU(e,a,n,i)?this._getEngine("webgpu"):this._shouldUseWorker(e,a,n,i)?this._getEngine("worker"):this._getEngine("cpu")}_shouldUseWebGPU(e,t,r,a){return!!this.availableStrategies.has("webgpu")&&(!(t<this.config.webgpuMinElements)&&(!(a.memory>.8||a.activeOperations>.9)&&(!!["matmul","conv2d","add","multiply","relu","sigmoid"].includes(e)||r>.7)))}_shouldUseWorker(e,t,r,a){return!!this.availableStrategies.has("worker")&&(t>this.config.workerMinElements&&r>.5||a.activeOperations>.7)}async _executeWithFallback(e,t,r,a){if(!this.config.enableAutoFallback)return e.execute(t,r,a);try{const n=e.execute(t,r,a),i=new Promise((e,t)=>{setTimeout(()=>t(new Error("Operation timeout")),this.config.fallbackTimeout)});return await Promise.race([n,i])}catch(n){this.emit("fallback:triggered",{from:e.name,operation:t,error:n.message});const i=this._getFallbackOrder(e.name);for(const e of i)if(this.availableStrategies.has(e))try{const n=this._getEngine(e);return this.emit("fallback:executing",{strategy:e,operation:t}),await n.execute(t,r,a)}catch(r){this.emit("fallback:failed",{strategy:e,operation:t,error:r.message})}throw n}}async _executeWithLoadBalancing(e,t){const r=this._groupOperationsByLoad(e),a=this._distributeOperations(r),n=new w(t),i=a.map(async e=>{await n.acquire();try{return await this.execute(e.operation,e.tensors,e.options)}finally{n.release()}});return Promise.all(i)}_getEngine(e){const t={webgpu:this.webgpu,cpu:this.cpu,worker:this.worker}[e];if(!t)throw new Error(`Engine '${e}' not found`);return t.name=e,t}_calculateWorkloadSize(e){return(Array.isArray(e)?e:[e]).reduce((e,t)=>ArrayBuffer.isView(t)?e+t.length:t instanceof ArrayBuffer?e+t.byteLength/4:e,0)}_estimateComplexity(e,t){const r={add:.1,multiply:.1,matmul:.8,conv2d:.9,relu:.2,sigmoid:.3,softmax:.6,transpose:.3}[e]||.5,a=this._calculateWorkloadSize(t),n=Math.log10(Math.max(a,1))/6;return Math.min(r*(1+n),1)}_assessResourcePressure(){return{memory:this.resourceMonitor.memoryUsage/(1024*this.config.memoryThresholdMB*1024),activeOperations:this.resourceMonitor.activeOperations/this.config.maxConcurrentOperations,gpu:this.resourceMonitor.gpuUtilization}}_recordPerformance(e,t,r,a){if(!this.config.enableAdaptiveSelection)return;this.performanceHistory.has(e)||this.performanceHistory.set(e,{webgpu:[],cpu:[],worker:[]});const n=this.performanceHistory.get(e)[t];n.length>=this.config.performanceHistorySize&&n.shift(),n.push({executionTime:r,workloadSize:this._calculateWorkloadSize(a),timestamp:Date.now()}),this._updateStrategyPreference(e)}_updateStrategyPreference(e){const t=this.performanceHistory.get(e);if(!t)return;const r={};for(const[e,a]of Object.entries(t))if(a.length>0){const t=a.reduce((e,t)=>e+t.executionTime,0)/a.length;r[e]=t}const a=Object.entries(r).reduce((e,[t,r])=>!e||r<e.avgTime?{strategy:t,avgTime:r}:e,null);a&&this.availableStrategies.has(a.strategy)&&this.strategyPreferences.set(e,a.strategy)}_getFallbackOrder(e){return{webgpu:["cpu","worker"],worker:["cpu"],cpu:[]}[e]||[]}_generateOperationId(){return`op_${Date.now()}_${Math.random().toString(36).substr(2,9)}`}_setupEngineForwarding(e,t){e.on("init:complete",e=>this.emit(`${t}:ready`,e)),e.on("compute:error",e=>this.emit(`${t}:error`,e)),e.on("cleanup:complete",()=>this.emit(`${t}:cleanup`))}_groupOperationsByLoad(e){return e.map(e=>({...e,estimatedLoad:this._estimateComplexity(e.operation,e.tensors),workloadSize:this._calculateWorkloadSize(e.tensors)}))}_distributeOperations(e){return e}}class w{constructor(e){this.max=e,this.current=0,this.queue=[]}async acquire(){return new Promise(e=>{this.current<this.max?(this.current++,e()):this.queue.push(e)})}release(){if(this.current--,this.queue.length>0){const e=this.queue.shift();this.current++,e()}}}const x=b},847:(e,t,r)=>{r.d(t,{O:()=>n});var a=r(626);class n{constructor(e,t={}){if(this.device=t.device||"webgpu",this.dtype=t.dtype||"float32",this.requires_grad=t.requires_grad||!1,this.grad=null,this.grad_fn=null,Array.isArray(e)||ArrayBuffer.isView(e))this.data=this._processInputData(e),this.shape=t.shape||this._inferShape(e);else if(e instanceof ArrayBuffer)this.data=new Float32Array(e),this.shape=t.shape||[this.data.length];else{if(!e||"object"!=typeof e||"PyProxy"!==e.constructor?.name||void 0===e.length){const t={type:typeof e,constructor:e?.constructor?.name,isArray:Array.isArray(e),isArrayBufferView:ArrayBuffer.isView(e),isArrayBuffer:e instanceof ArrayBuffer,hasLength:void 0!==e?.length,stringValue:String(e).substring(0,100)};throw new Error(`Invalid tensor data type: ${JSON.stringify(t)}`)}{const r=Array.from(e);this.data=this._processInputData(r),this.shape=t.shape||this._inferShape(r)}}this.ndim=this.shape.length,this.size=this.shape.reduce((e,t)=>e*t,1),this.computeEngine=t.computeEngine||null,this._buffer=null,this._isOnGPU=!1}static setComputeEngine(e){n.globalComputeEngine=e}get _engine(){return this.computeEngine||n.globalComputeEngine}async _executeGPUOperation(e,t=null,r={}){if(!this._engine)throw new Error("WebGPU compute engine not available");let i=null;if(t)try{i=t.data||t,i&&"object"==typeof i&&"PyProxy"===i.constructor?.name&&(i=Array.from(i),i=new Float32Array(i))}catch(e){throw new Error(`Failed to access tensor data: ${e.message}. This may be due to Pyodide proxy destruction.`)}const s=t?[this.data,i]:[this.data];try{const a=await this._engine.execute(e,s,{shape:this.shape,otherShape:t?.shape,dtype:this.dtype,...r}),i=this._calculateResultShape(e,t,r);return new n(a,{shape:i,device:this.device,dtype:this.dtype,computeEngine:this._engine,requires_grad:this.requires_grad||t?.requires_grad})}catch(n){const i={operation:e,error:n.message,tensorShape:this.shape,otherShape:t?.shape,fallbackReason:"gpu-operation-failed",engineAvailable:!!this._engine,engineInitialized:this._engine?.isInitialized};return a.A.warn(`WebGPU operation ${e} failed, falling back to CPU:`,i),this._executeCPUFallback(e,t,r)}}_executeCPUFallback(e,t,r){const a=this._cpuOperations[e]?.(this.data,t?.data||t,r);if(!a)throw new Error(`Operation ${e} not supported`);const i=this._calculateResultShape(e,t,r);return new n(a,{shape:i,device:"cpu",dtype:this.dtype,requires_grad:this.requires_grad||t?.requires_grad})}async add(e){return this._executeGPUOperation("add",e)}async sub(e){return this._executeGPUOperation("sub",e)}async mul(e){return this._executeGPUOperation("mul",e)}async div(e){return this._executeGPUOperation("div",e)}async pow(e){return this._executeGPUOperation("pow",e)}async matmul(e){if(2!==this.ndim||2!==e.ndim)throw new Error("matmul requires 2D tensors");if(this.shape[1]!==e.shape[0])throw new Error(`Cannot multiply matrices of shapes ${this.shape} and ${e.shape}`);return this._executeGPUOperation("matmul",e)}async bmm(e){if(3!==this.ndim||3!==e.ndim)throw new Error("bmm requires 3D tensors");return this._executeGPUOperation("bmm",e)}async transpose(e=0,t=1){return this._executeGPUOperation("transpose",null,{dim0:e,dim1:t})}async relu(){return this._executeGPUOperation("relu")}async leaky_relu(e=.01){return this._executeGPUOperation("leaky_relu",null,{negativeSlope:e})}async sigmoid(){return this._executeGPUOperation("sigmoid")}async tanh(){return this._executeGPUOperation("tanh")}async gelu(){return this._executeGPUOperation("gelu")}async softmax(e=-1){return this._executeGPUOperation("softmax",null,{dim:e})}async sum(e=null,t=!1){return this._executeGPUOperation("sum",null,{dim:e,keepDim:t})}async mean(e=null,t=!1){return this._executeGPUOperation("mean",null,{dim:e,keepDim:t})}async max(e=null,t=!1){return null===e?await this._executeGPUOperation("max_reduce"):this._executeGPUOperation("max",null,{dim:e,keepDim:t})}async min(e=null,t=!1){return null===e?await this._executeGPUOperation("min_reduce"):this._executeGPUOperation("min",null,{dim:e,keepDim:t})}async std(e=null,t=!1,r=!0){return this._executeGPUOperation("std",null,{dim:e,keepDim:t,unbiased:r})}async var(e=null,t=!1,r=!0){return this._executeGPUOperation("var",null,{dim:e,keepDim:t,unbiased:r})}async exp(){return this._executeGPUOperation("exp")}async log(){return this._executeGPUOperation("log")}async sqrt(){return this._executeGPUOperation("sqrt")}async abs(){return this._executeGPUOperation("abs")}view(...e){if(e.reduce((e,t)=>e*t,1)!==this.size)throw new Error(`Cannot reshape tensor of size ${this.size} to shape ${e}`);return new n(this.data,{shape:e,device:this.device,dtype:this.dtype,computeEngine:this._engine,requires_grad:this.requires_grad})}reshape(...e){return this.view(...e)}unsqueeze(e){const t=[...this.shape];return e<0&&(e=t.length+e+1),t.splice(e,0,1),this.view(...t)}squeeze(e=null){let t;if(null===e)t=this.shape.filter(e=>1!==e);else{if(1!==this.shape[e])throw new Error(`Cannot squeeze dimension ${e} of size ${this.shape[e]}`);t=[...this.shape],t.splice(e,1)}return this.view(...t)}flatten(e=0,t=-1){-1===t&&(t=this.ndim-1);const r=this.shape.slice(0,e),a=this.shape.slice(e,t+1),n=this.shape.slice(t+1),i=[...r,a.reduce((e,t)=>e*t,1),...n];return this.view(...i)}to(e){return e===this.device?this:new n(this.data.slice(),{shape:this.shape,device:e,dtype:this.dtype,computeEngine:this._engine,requires_grad:this.requires_grad})}cpu(){return this.to("cpu")}cuda(){return this.to("webgpu")}retain_grad(){if(!this.requires_grad)throw new Error("can't retain_grad on Tensor that has requires_grad=False");return this._retain_grad=!0,this}backward(e=null,t=!1,r=!1){if(!this.requires_grad)return;if(null===e){if(1!==this.size)throw new Error("grad can be implicitly created only for scalar outputs");e=new n([1],{shape:this.shape})}null===this.grad&&(this.grad=new n(new Float32Array(this.size).fill(0),{shape:this.shape,device:this.device,dtype:this.dtype}));const a=e.data||e;for(let e=0;e<this.grad.data.length;e++)this.grad.data[e]+=Array.isArray(a)?a[e]:a;this.grad_fn&&this.grad_fn(e)}numpy(){return this.data}tolist(){return 1===this.ndim?Array.from(this.data):this._arrayToNestedList(this.data,this.shape)}item(){if(1!==this.size)throw new Error("item() can only be called on tensors with one element");return this.data[0]}clone(){return new n(this.data.slice(),{shape:this.shape,device:this.device,dtype:this.dtype,computeEngine:this._engine,requires_grad:this.requires_grad})}detach(){const e=this.clone();return e.requires_grad=!1,e.grad_fn=null,e}_isDebugEnabled(){try{return"undefined"!=typeof window&&window.greedDebugWebGPU||void 0!==r.g&&r.g.greedDebugWebGPU}catch{return!1}}_processInputData(e){if(Array.isArray(e))return new Float32Array(this._flattenArray(e));if(ArrayBuffer.isView(e))return new Float32Array(e);throw new Error("Unsupported data type")}_flattenArray(e){const t=[],r=e=>{Array.isArray(e)?e.forEach(r):t.push(Number(e))};return r(e),t}_inferShape(e){if(!Array.isArray(e))return[e.length||1];const t=e=>{if(!Array.isArray(e))return[];const r=[e.length];return e.length>0&&Array.isArray(e[0])&&r.push(...t(e[0])),r};return t(e)}_calculateResultShape(e,t,r){switch(e){case"matmul":return[this.shape[0],t.shape[1]];case"bmm":return[this.shape[0],this.shape[1],t.shape[2]];case"transpose":const e=[...this.shape],{dim0:a=0,dim1:n=1}=r;return[e[a],e[n]]=[e[n],e[a]],e;case"sum":case"mean":if(null===r.dim)return r.keepDim?this.shape:[1];{const e=[...this.shape];return r.keepDim?e[r.dim]=1:e.splice(r.dim,1),0===e.length?[1]:e}default:return this.shape}}_arrayToNestedList(e,t){if(1===t.length)return Array.from(e);const r=[],a=t.slice(1).reduce((e,t)=>e*t,1);for(let n=0;n<t[0];n++){const i=n*a,s=i+a,o=e.slice(i,s);r.push(this._arrayToNestedList(o,t.slice(1)))}return r}get _cpuOperations(){return{add:(e,t)=>e.map((e,r)=>e+(Array.isArray(t)?t[r]:t)),sub:(e,t)=>e.map((e,r)=>e-(Array.isArray(t)?t[r]:t)),mul:(e,t)=>e.map((e,r)=>e*(Array.isArray(t)?t[r]:t)),div:(e,t)=>e.map((e,r)=>e/(Array.isArray(t)?t[r]:t)),pow:(e,t)=>e.map((e,r)=>Math.pow(e,Array.isArray(t)?t[r]:t)),exp:e=>e.map(e=>Math.exp(e)),log:e=>e.map(e=>Math.log(e)),sqrt:e=>e.map(e=>Math.sqrt(e)),abs:e=>e.map(e=>Math.abs(e)),relu:e=>e.map(e=>Math.max(0,e)),sigmoid:e=>e.map(e=>1/(1+Math.exp(-e))),tanh:e=>e.map(e=>Math.tanh(e)),matmul:(e,t,r)=>{const a=r.shape||[Math.sqrt(e.length),Math.sqrt(e.length)],n=r.otherShape||[Math.sqrt(t.length),Math.sqrt(t.length)];if(2!==a.length||2!==n.length)throw new Error("CPU matmul fallback requires 2D matrices");const[i,s]=a,[o,u]=n;if(s!==o)throw new Error(`Cannot multiply matrices of shapes [${i},${s}] and [${o},${u}]`);const p=new Array(i*u);for(let r=0;r<i;r++)for(let a=0;a<u;a++){let n=0;for(let i=0;i<s;i++)n+=e[r*s+i]*t[i*u+a];p[r*u+a]=n}return p},std:(e,t={})=>{const r=e.reduce((e,t)=>e+t,0)/e.length,a=e.reduce((e,t)=>e+Math.pow(t-r,2),0)/(t.unbiased?e.length-1:e.length);return[Math.sqrt(a)]},var:(e,t={})=>{const r=e.reduce((e,t)=>e+t,0)/e.length;return[e.reduce((e,t)=>e+Math.pow(t-r,2),0)/(t.unbiased?e.length-1:e.length)]}}}toString(){return`WebGPUTensor(${this.shape.join("x")}, device=${this.device}, dtype=${this.dtype})`}[Symbol.toPrimitive](e){return"number"===e&&1===this.size?this.data[0]:this.toString()}"@"(e){return this.matmul(e)}__add__(e){return this.add(e)}__sub__(e){return this.sub(e)}__mul__(e){return this.mul(e)}__truediv__(e){return this.div(e)}__matmul__(e){return this.matmul(e)}}}}]);