!function(e,n){"object"==typeof exports&&"object"==typeof module?module.exports=n():"function"==typeof define&&define.amd?define("Greed",[],n):"object"==typeof exports?exports.Greed=n():e.Greed=n()}(globalThis,()=>(()=>{"use strict";var e={d:(n,t)=>{for(var a in t)e.o(t,a)&&!e.o(n,a)&&Object.defineProperty(n,a,{enumerable:!0,get:t[a]})}};e.g=function(){if("object"==typeof globalThis)return globalThis;try{return this||new Function("return this")()}catch(e){if("object"==typeof window)return window}}(),e.o=(e,n)=>Object.prototype.hasOwnProperty.call(e,n);var n={};e.d(n,{default:()=>z});const t=class{constructor(){this._events=new Map,this._maxListeners=10}on(e,n){if("function"!=typeof n)throw new TypeError("Listener must be a function");this._events.has(e)||this._events.set(e,[]);const t=this._events.get(e);return t.push(n),t.length>this._maxListeners&&this.emit("maxListenersExceeded",{event:e,count:t.length,limit:this._maxListeners}),this}once(e,n){const t=(...a)=>{n.apply(this,a),this.off(e,t)};return this.on(e,t)}off(e,n){if(!this._events.has(e))return this;const t=this._events.get(e),a=t.indexOf(n);return-1!==a&&t.splice(a,1),0===t.length&&this._events.delete(e),this}emit(e,...n){if(!this._events.has(e))return!1;const t=this._events.get(e).slice();for(const a of t)try{a.apply(this,n)}catch(n){this.emit("error",n,e)}return!0}removeAllListeners(e){return e?this._events.delete(e):this._events.clear(),this}listenerCount(e){return this._events.has(e)?this._events.get(e).length:0}setMaxListeners(e){if("number"!=typeof e||e<0||isNaN(e))throw new TypeError("n must be a non-negative number");return this._maxListeners=e,this}eventNames(){return Array.from(this._events.keys())}async emitAsync(e,...n){if(!this._events.has(e))return[];const t=this._events.get(e).slice().map(async t=>{try{return await t.apply(this,n)}catch(n){throw this.emit("error",n,e),n}});return Promise.allSettled(t)}};class a{constructor(e={}){this.config={level:e.level||"warn",enableConsole:!1!==e.enableConsole,prefix:e.prefix||"Greed",timestamp:!1!==e.timestamp,...e},this.levels={error:0,warn:1,info:2,debug:3},this.currentLevelPriority=this.levels[this.config.level]||1}_shouldLog(e){return this.levels[e]<=this.currentLevelPriority}_formatMessage(e,n,...t){return{formatted:`${[this.config.timestamp?(new Date).toISOString():"",this.config.prefix?`[${this.config.prefix}]`:"",`[${e.toUpperCase()}]`].filter(Boolean).join(" ")} ${n}`,args:t}}error(e,...n){if(this._shouldLog("error")&&this.config.enableConsole){const{formatted:t,args:a}=this._formatMessage("error",e,...n);console.error(t,...a)}}warn(e,...n){if(this._shouldLog("warn")&&this.config.enableConsole){const{formatted:t,args:a}=this._formatMessage("warn",e,...n);console.warn(t,...a)}}info(e,...n){if(this._shouldLog("info")&&this.config.enableConsole){const{formatted:t,args:a}=this._formatMessage("info",e,...n);console.log(t,...a)}}debug(e,...n){if(this._shouldLog("debug")&&this.config.enableConsole){const{formatted:t,args:a}=this._formatMessage("debug",e,...n);console.log(t,...a)}}setLevel(e){e in this.levels&&(this.config.level=e,this.currentLevelPriority=this.levels[e])}child(e){return new a({...this.config,prefix:`${this.config.prefix}:${e}`})}}const r=new a,s=class extends t{constructor(e={}){super(),this.config={workerURL:e.workerURL||null,pyodideIndexURL:e.pyodideIndexURL||"https://cdn.jsdelivr.net/pyodide/v0.24.1/full/",pyodideURL:e.pyodideURL||"https://cdn.jsdelivr.net/pyodide/v0.24.1/full/pyodide.js",preloadPackages:e.preloadPackages||["numpy"],timeout:e.timeout||3e4,maxRetries:e.maxRetries||3,...e},this.worker=null,this.isInitialized=!1,this.isReady=!1,this.installedPackages=new Set,this.messageId=0,this.pendingMessages=new Map,this.executionTasks=new Map,this.stats={messagesProcessed:0,executionsCompleted:0,averageExecutionTime:0,totalExecutionTime:0}}async initialize(){if(this.isInitialized)return!0;try{this.emit("init:start",{stage:"worker"});const e=new Promise((e,n)=>{this._workerReadyResolve=e,this._workerReadyReject=n,this._workerReadyTimeout=setTimeout(()=>{r.error("Worker ready timeout - no response after",this.config.timeout,"ms"),n(new Error("Worker ready timeout"))},this.config.timeout)});return await this._createWorker(),await e,this._workerReadyTimeout&&clearTimeout(this._workerReadyTimeout),await this._initializePyodide(),this.isInitialized=!0,this.isReady=!0,this.emit("init:complete",{installedPackages:Array.from(this.installedPackages)}),!0}catch(e){throw this.emit("init:error",{error:e}),e}}async _createWorker(){return new Promise((e,n)=>{try{const t=this.config.workerURL||this._getWorkerURL();r.info("Creating worker from URL:",t),this.worker=new Worker(t),this.worker.onmessage=this._handleMessage.bind(this),this.worker.onerror=e=>{const t=new Error(`Worker error: ${e.message||"Unknown error"} at ${e.filename}:${e.lineno}:${e.colno}`);r.error("Worker error event:",{message:e.message,filename:e.filename,lineno:e.lineno,colno:e.colno}),this.emit("worker:error",{error:t}),this._workerReadyReject&&(this._workerReadyReject(t),this._workerReadyReject=null,this._workerReadyResolve=null),n(t)},r.info("Worker created successfully"),e()}catch(e){r.error("Failed to create worker:",e),n(e)}})}_getWorkerURL(){try{if("undefined"!=typeof document){let e;const n=document.getElementsByTagName("script");let t=null;for(let e=n.length-1;e>=0;e--)if(n[e].src&&n[e].src.includes("greed")){t=n[e];break}return t&&t.src?(e=t.src.replace(/[^/]*$/,""),r.info("Worker path from greed.js script tag:",e+"pyodide-worker.js")):document.currentScript&&document.currentScript.src?(e=document.currentScript.src.replace(/[^/]*$/,""),r.info("Worker path from currentScript:",e+"pyodide-worker.js")):(e=window.location.origin+"/dist/",r.info("Worker path from fallback:",e+"pyodide-worker.js")),e+"pyodide-worker.js"}return r.info("Worker path (no document):","dist/pyodide-worker.js"),"dist/pyodide-worker.js"}catch(e){return r.warn("Could not determine worker path, using fallback:",e),"dist/pyodide-worker.js"}}_createInlineWorker(){const e=new Blob([`importScripts('${this.config.pyodideURL}');\n       postMessage({ type: 'worker:ready' });`],{type:"application/javascript"});return URL.createObjectURL(e)}async _initializePyodide(){return this._sendMessage("init",{config:{indexURL:this.config.pyodideIndexURL,pyodideURL:this.config.pyodideURL,preloadPackages:this.config.preloadPackages}})}_handleMessage(e){const n=e.data;switch(this.stats.messagesProcessed++,n.type){case"worker:ready":r.info("Worker ready message received"),this._workerReadyResolve&&(this._workerReadyResolve(),this._workerReadyResolve=null,this._workerReadyReject=null);break;case"init:progress":case"init:complete":case"init:error":case"packages:loading":case"packages:loaded":case"packages:error":case"execution:warning":case"execution:interrupted":case"interrupt:error":case"reset:complete":case"reset:error":this.emit(n.type,n);break;case"execution:stdout":this.emit("execution:stdout",{type:"execution:stdout",taskId:n.taskId,output:n.output,timestamp:n.timestamp});break;case"execution:complete":this._handleExecutionComplete(n);break;case"execution:error":this._handleExecutionError(n);break;case"execution:cleanup":this.emit("execution:cleanup",n);break;case"init:ack":case"loadPackages:ack":case"execute:ack":case"getGlobal:result":case"setGlobal:result":case"deleteGlobal:result":case"interrupt:ack":case"reset:ack":case"pong":this._resolvePendingMessage(n.id,n);break;case"error":this._rejectPendingMessage(n.id,new Error(n.error.message));break;default:r.warn("Unknown message type from worker:",n.type)}}_handleExecutionComplete(e){const n=this.executionTasks.get(e.taskId);if(n){const t=performance.now()-n.startTime;this.stats.executionsCompleted++,this.stats.totalExecutionTime+=t,this.stats.averageExecutionTime=this.stats.totalExecutionTime/this.stats.executionsCompleted,n.resolve(e.result),this.executionTasks.delete(e.taskId),this.emit("execution:complete",{taskId:e.taskId,executionTime:t,result:e.result})}}_handleExecutionError(e){const n=this.executionTasks.get(e.taskId);if(n){const t=new Error(e.error.message);t.stack=e.error.stack,t.pythonType=e.error.type,n.reject(t),this.executionTasks.delete(e.taskId),this.emit("execution:error",{taskId:e.taskId,error:t})}}async _sendMessage(e,n={}){return new Promise((t,a)=>{const r=this.messageId++,s=setTimeout(()=>{this.pendingMessages.delete(r),a(new Error(`Message timeout: ${e}`))},this.config.timeout);this.pendingMessages.set(r,{resolve:t,reject:a,timeout:s}),this.worker.postMessage({type:e,id:r,...n})})}_resolvePendingMessage(e,n){const t=this.pendingMessages.get(e);t&&(clearTimeout(t.timeout),t.resolve(n),this.pendingMessages.delete(e))}_rejectPendingMessage(e,n){const t=this.pendingMessages.get(e);t&&(clearTimeout(t.timeout),t.reject(n),this.pendingMessages.delete(e))}async loadPackages(e){if(!this.isReady)throw new Error("Worker not initialized");const n=await this._sendMessage("loadPackages",{packages:e});return n.packages&&n.packages.forEach(e=>this.installedPackages.add(e)),Array.from(this.installedPackages)}async executePython(e,n={}){if(!this.isReady)throw new Error("Worker not initialized");return new Promise((t,a)=>{const r=n.taskId||`task_${Date.now()}_${Math.random().toString(36).substr(2,9)}`,s=performance.now();this.executionTasks.set(r,{taskId:r,startTime:s,resolve:t,reject:a}),this.worker.postMessage({type:"execute",id:this.messageId++,taskId:r,code:e,options:n}),n.timeout&&setTimeout(()=>{this.executionTasks.has(r)&&(this.executionTasks.delete(r),a(new Error("Execution timeout")))},n.timeout)})}async getGlobal(e){if(!this.isReady)throw new Error("Worker not initialized");return(await this._sendMessage("getGlobal",{name:e})).value}async setGlobal(e,n){if(!this.isReady)throw new Error("Worker not initialized");return(await this._sendMessage("setGlobal",{name:e,value:n})).success}async deleteGlobal(e){if(!this.isReady)throw new Error("Worker not initialized");return(await this._sendMessage("deleteGlobal",{name:e})).success}async interrupt(){this.isReady&&await this._sendMessage("interrupt")}async reset(){this.isReady&&await this._sendMessage("reset")}async ping(){if(!this.isReady)return!1;try{return await this._sendMessage("ping"),!0}catch(e){return!1}}getStats(){return{...this.stats}}async terminate(){if(this.worker){for(const[e,n]of this.pendingMessages)clearTimeout(n.timeout),n.reject(new Error("Worker terminated"));this.pendingMessages.clear();for(const[e,n]of this.executionTasks)n.reject(new Error("Worker terminated"));this.executionTasks.clear(),this.worker.terminate(),this.worker=null,this.isInitialized=!1,this.isReady=!1,this.emit("worker:terminated")}}};class i extends Error{constructor(e){super(e),this.name="SecurityError"}}const o=class extends t{constructor(e={}){super(),this.config={pyodideIndexURL:e.pyodideIndexURL||"https://cdn.jsdelivr.net/pyodide/v0.24.1/full/",preloadPackages:e.preloadPackages||["numpy"],availablePackages:e.availablePackages||["numpy","scipy","matplotlib","pandas","scikit-learn","plotly","seaborn","statsmodels","sympy","networkx"],timeout:e.initTimeout||3e4,enableWorkers:!1!==e.enableWorkers,...e},this.mode=this.config.enableWorkers?"worker":"main",this.pyodide=null,this.workerManager=null,this.isReady=!1,this.installedPackages=new Set,this.initPromise=null}async initialize(){return this.initPromise||(this.initPromise=this._initializeInternal()),this.initPromise}async _initializeInternal(){return"worker"===this.mode?this._initializeWorkerMode():this._initializeMainThreadMode()}async _initializeWorkerMode(){try{return this.emit("init:start",{stage:"worker",mode:"worker"}),this.workerManager=new s({pyodideIndexURL:this.config.pyodideIndexURL,preloadPackages:this.config.preloadPackages,timeout:this.config.timeout}),this.workerManager.on("init:progress",e=>this.emit("init:progress",e)),this.workerManager.on("init:complete",e=>{this.installedPackages=new Set(e.installedPackages),this.emit("init:complete",e)}),this.workerManager.on("init:error",e=>this.emit("init:error",e)),this.workerManager.on("packages:loading",e=>this.emit("packages:loading",e)),this.workerManager.on("packages:loaded",e=>this.emit("packages:loaded",e)),this.workerManager.on("execution:complete",e=>this.emit("execution:complete",e)),this.workerManager.on("execution:error",e=>this.emit("execution:error",e)),this.workerManager.on("execution:stdout",e=>this.emit("execution:stdout",e)),await this.workerManager.initialize(),this.isReady=!0,!0}catch(e){throw this.emit("init:error",{error:e,stage:"worker-initialization"}),e}}async _initializeMainThreadMode(){try{if(this.emit("init:start",{stage:"pyodide",mode:"main"}),"undefined"==typeof loadPyodide)throw new Error("Pyodide not loaded. Please include pyodide.js in your HTML.");const e=loadPyodide({indexURL:this.config.pyodideIndexURL,args:["-Xalloc-env=PYODIDE_WASM_MEMORY=4294967296"]});return this.pyodide=await Promise.race([e,this._createTimeoutPromise(this.config.timeout,"Pyodide initialization timeout")]),this.emit("init:progress",{stage:"pyodide",status:"loaded"}),this.config.preloadPackages.length>0&&(this.emit("init:progress",{stage:"packages",packages:this.config.preloadPackages}),await this._loadPackages(this.config.preloadPackages)),this.isReady=!0,this.emit("init:complete",{installedPackages:Array.from(this.installedPackages)}),!0}catch(e){throw this.emit("init:error",{error:e,stage:"initialization"}),e}}async loadPackages(e){if(!this.isReady)throw new Error("Runtime not initialized. Call initialize() first.");if("worker"===this.mode){const n=await this.workerManager.loadPackages(e);return n.forEach(e=>this.installedPackages.add(e)),n}return this._loadPackages(e)}async _loadPackages(e){const n=e.filter(e=>!this.installedPackages.has(e));if(0===n.length)return Array.from(this.installedPackages);try{return this.emit("packages:loading",{packages:n}),await this.pyodide.loadPackage(n),n.forEach(e=>this.installedPackages.add(e)),this.emit("packages:loaded",{loaded:n,total:Array.from(this.installedPackages)}),Array.from(this.installedPackages)}catch(e){return this.emit("packages:error",{error:e,packages:n}),n.forEach(e=>this.installedPackages.add(e)),Array.from(this.installedPackages)}}async runPython(e,n={}){if(!this.isReady)throw new Error("Runtime not initialized. Call initialize() first.");const{validateInput:t=!0}=n;if(t&&this._containsDangerousPatterns(e))throw new i("Potentially dangerous code patterns detected");const a=[{check:this._needsMatplotlib.bind(this),loader:this._ensureMatplotlibLoaded.bind(this)},{check:this._needsPandas.bind(this),loader:this._ensurePandasLoaded.bind(this)},{check:this._needsScipy.bind(this),loader:this._ensureScipyLoaded.bind(this)},{check:this._needsPlotly.bind(this),loader:this._ensurePlotlyLoaded.bind(this)},{check:this._needsSklearn.bind(this),loader:this._ensureSklearnLoaded.bind(this)}];for(const{check:n,loader:t}of a)n(e)&&await t();return"worker"===this.mode?this._runPythonWorker(e,n):this._runPythonMain(e,n)}async _runPythonWorker(e,n){try{return await this.workerManager.executePython(e,n)}catch(n){throw this.emit("execution:error",{error:n,code:e.substring(0,100)}),n}}async _runPythonMain(e,n){const{captureOutput:t,timeout:a,globals:r={},taskId:s,streamOutput:i}=n;try{for(const[e,n]of Object.entries(r))try{this.pyodide.globals.set(e,n)}catch(n){this.emit("global:error",{key:e,error:n.message})}let n;if(t){const t=!1!==i&&Boolean(s);t&&this.pyodide.globals.set("__greed_emit_stdout__",(e,n)=>{this.emit("execution:stdout",{type:"execution:stdout",taskId:e,output:n,timestamp:Date.now()})});const r=`\nimport sys\nfrom io import StringIO\nimport time\n\nclass StreamingBuffer:\n    def __init__(self, task_id, emit_callback, should_stream):\n        self.buffer = StringIO()\n        self.task_id = task_id\n        self.emit_callback = emit_callback\n        self.should_stream = should_stream\n        self.pending_output = ""\n\n    def write(self, text):\n        self.buffer.write(text)\n        # Emit immediately for real-time streaming\n        if self.should_stream and self.emit_callback and text:\n            # Emit immediately - don't wait for time intervals\n            # This ensures output appears in real-time, even during sleep() calls\n            self.emit_callback(self.task_id, text)\n\n    def flush(self):\n        self.buffer.flush()\n        # Emit any remaining output (usually not needed with immediate emission)\n        if self.should_stream and self.emit_callback and self.pending_output:\n            self.emit_callback(self.task_id, self.pending_output)\n            self.pending_output = ""\n\n    def getvalue(self):\n        return self.buffer.getvalue()\n\n_output_buffer = StreamingBuffer('${s||""}', ${t?"__greed_emit_stdout__":"None"}, ${t?"True":"False"})\n_original_stdout = sys.stdout\nsys.stdout = _output_buffer\n\ntry:\n${e.split("\n").map(e=>"    "+e).join("\n")}\nfinally:\n    sys.stdout.flush()\n    sys.stdout = _original_stdout\n    _captured_output = _output_buffer.getvalue()\n`;let o;a&&a>0&&(o=setTimeout(()=>{this.emit("execution:timeout",{timeout:a,stage:"capture_output"})},a));try{await this.pyodide.runPythonAsync(r)}finally{o&&clearTimeout(o)}let d="";try{d=this.pyodide.globals.get("_captured_output")||""}catch(e){this.emit("output:error",{error:e.message}),d="Output capture failed"}n={output:d};try{this.pyodide.globals.delete("_captured_output"),this.pyodide.globals.delete("_output_buffer"),this.pyodide.globals.delete("_original_stdout"),t&&this.pyodide.globals.delete("__greed_emit_stdout__")}catch(e){this.emit("cleanup:warning",{error:e.message})}}else{let t;a&&a>0&&(t=setTimeout(()=>{this.emit("execution:timeout",{timeout:a,stage:"no_capture"})},a));try{n=await this.pyodide.runPythonAsync(e)}finally{t&&clearTimeout(t)}}return n}catch(n){throw this.emit("execution:error",{error:n,code:e.substring(0,100)}),n}}async getGlobal(e){if(!this.isReady)throw new Error("Runtime not initialized");if("worker"===this.mode)return await this.workerManager.getGlobal(e);try{return this.pyodide.globals.get(e)}catch(n){return void this.emit("global:get:error",{name:e,error:n.message})}}async setGlobal(e,n){if(!this.isReady)throw new Error("Runtime not initialized");if("worker"===this.mode)return await this.workerManager.setGlobal(e,n);try{this.pyodide.globals.set(e,n)}catch(n){throw this.emit("global:set:error",{name:e,error:n.message}),n}}hasPackage(e){return this.installedPackages.has(e)}getStatus(){return{isReady:this.isReady,installedPackages:Array.from(this.installedPackages),pyodideVersion:this.pyodide?.version||null,config:this.config}}async clearExecutionState(){if(this.isReady)try{await this.pyodide.runPythonAsync("\nimport gc\nimport sys\nimport builtins\n\n# List of globals to preserve (built-ins and essential modules)\npreserved_globals = {\n    'torch', 'np', 'numpy', 'sys', 'builtins', '__builtins__',\n    'gc', '__name__', '__doc__', '__package__', '__loader__',\n    '__spec__', '__annotations__', '__cached__', '__file__'\n}\n\n# Get current globals\ncurrent_globals = list(globals().keys())\n\n# Remove user-defined variables\nfor var_name in current_globals:\n    if (var_name not in preserved_globals and\n        not var_name.startswith('_') and\n        not callable(globals().get(var_name, None)) or\n        var_name.startswith('_greed_')):\n        try:\n            del globals()[var_name]\n        except:\n            pass\n\n# Force garbage collection\ngc.collect()\n")}catch(e){this.emit("state:clear:error",{error:e.message})}}async cleanup(){try{if("worker"===this.mode&&this.workerManager)await this.workerManager.terminate(),this.workerManager=null;else if(this.pyodide){try{await this.pyodide.runPythonAsync("\nimport gc\nimport sys\n\n# Clear user globals\nuser_globals = [k for k in list(globals().keys())\n               if not k.startswith('__') and k not in sys.modules]\nfor k in user_globals:\n    try:\n        del globals()[k]\n    except:\n        pass\n\ngc.collect()\n")}catch(e){}this.pyodide.globals.clear(),this.pyodide=null}this.isReady=!1,this.installedPackages.clear(),this.initPromise=null,this.emit("cleanup:complete")}catch(e){this.emit("cleanup:error",{error:e})}}_createTimeoutPromise(e,n){return new Promise((t,a)=>{setTimeout(()=>a(new Error(n)),e)})}_needsMatplotlib(e){return[/import\s+matplotlib/,/from\s+matplotlib/,/import\s+matplotlib\.pyplot/,/from\s+matplotlib\.pyplot/,/plt\./].some(n=>n.test(e))}async _ensureMatplotlibLoaded(){try{this.installedPackages.has("matplotlib")||(this.emit("package:loading",{package:"matplotlib"}),await this.pyodide.loadPackage("matplotlib"),this.installedPackages.add("matplotlib"),this.emit("package:loaded",{package:"matplotlib"}))}catch(e){this.emit("package:error",{package:"matplotlib",error:e})}}_needsPandas(e){return[/import\s+pandas/,/from\s+pandas/,/import\s+pandas\s+as\s+pd/,/pd\./].some(n=>n.test(e))}async _ensurePandasLoaded(){try{this.installedPackages.has("pandas")||(this.emit("package:loading",{package:"pandas"}),await this.pyodide.loadPackage("pandas"),this.installedPackages.add("pandas"),this.emit("package:loaded",{package:"pandas"}))}catch(e){this.emit("package:error",{package:"pandas",error:e})}}_needsScipy(e){return[/import\s+scipy/,/from\s+scipy/,/scipy\./].some(n=>n.test(e))}async _ensureScipyLoaded(){try{this.installedPackages.has("scipy")||(this.emit("package:loading",{package:"scipy"}),await this.pyodide.loadPackage("scipy"),this.installedPackages.add("scipy"),this.emit("package:loaded",{package:"scipy"}))}catch(e){this.emit("package:error",{package:"scipy",error:e})}}_needsPlotly(e){return[/import\s+plotly/,/from\s+plotly/,/plotly\./,/import\s+plotly\.graph_objects/,/import\s+plotly\.express/].some(n=>n.test(e))}async _ensurePlotlyLoaded(){try{this.installedPackages.has("plotly")||(this.emit("package:loading",{package:"plotly"}),await this.pyodide.loadPackage("plotly"),this.installedPackages.add("plotly"),this.emit("package:loaded",{package:"plotly"}))}catch(e){this.emit("package:error",{package:"plotly",error:e})}}_needsSklearn(e){return[/import\s+sklearn/,/from\s+sklearn/,/sklearn\./,/from\s+sklearn\.\w+/].some(n=>n.test(e))}async _ensureSklearnLoaded(){try{this.installedPackages.has("scikit-learn")||(this.emit("package:loading",{package:"scikit-learn"}),await this.pyodide.loadPackage("scikit-learn"),this.installedPackages.add("scikit-learn"),this.emit("package:loaded",{package:"scikit-learn"}))}catch(e){this.emit("package:error",{package:"scikit-learn",error:e})}}_containsDangerousPatterns(e){return[/\beval\s*\(/,/\bexec\s*\(/,/\b__import__\s*\(/,/\bsubprocess\./,/\bos\.system\s*\(/,/\bopen\s*\(/,/\bfile\s*\(/].some(n=>n.test(e))}},d=class extends t{constructor(e,n={}){super(),this.device=e,this.config={maxPoolSize:n.maxPoolSize||100,maxBufferSize:n.maxBufferSize||268435456,gcThreshold:n.gcThreshold||.8,enablePooling:!1!==n.enablePooling,...n},this.pools=new Map,this.activeBuffers=new Map,this.totalMemoryUsage=0,this.peakMemoryUsage=0,this.stats={allocations:0,poolHits:0,poolMisses:0,releases:0,destroyed:0,currentActive:0,totalPooled:0}}allocate(e,n=GPUBufferUsage.STORAGE|GPUBufferUsage.COPY_SRC|GPUBufferUsage.COPY_DST){this._validateAllocation(e,n);const t=this._getPoolKey(e,n);let a=null;this.config.enablePooling&&(a=this._getFromPool(t),a&&(this.stats.poolHits++,this.emit("buffer:reused",{size:e,usage:n,poolKey:t}))),a||(a=this.device.createBuffer({size:e,usage:n}),this.stats.poolMisses++,this.emit("buffer:created",{size:e,usage:n,poolKey:t}));const r={size:e,usage:n,poolKey:t,allocatedAt:performance.now(),lastAccessed:performance.now()};return this.activeBuffers.set(a,r),this.totalMemoryUsage+=e,this.peakMemoryUsage=Math.max(this.peakMemoryUsage,this.totalMemoryUsage),this.stats.allocations++,this.stats.currentActive=this.activeBuffers.size,this.emit("buffer:allocated",{buffer:a,metadata:r}),this._checkMemoryPressure(),a}release(e,n={}){const{forceDestroy:t=!1}=n,a=this.activeBuffers.get(e);return a?(this.activeBuffers.delete(e),this.totalMemoryUsage-=a.size,this.stats.releases++,this.stats.currentActive=this.activeBuffers.size,t||!this.config.enablePooling||this._shouldDestroyBuffer(e,a)?(this._destroyBuffer(e,a),!0):(this._addToPool(e,a)?this.emit("buffer:pooled",{buffer:e,poolKey:a.poolKey}):this._destroyBuffer(e,a),!0)):(this.emit("buffer:release-error",{error:"Buffer not found in active buffers"}),!1)}releaseAll(e,n={}){const t=[];for(const a of e)t.push(this.release(a,n));return t}async createMappedBuffer(e,n=GPUBufferUsage.STORAGE){const t=this._calculateBufferSize(e),a=this.device.createBuffer({size:t,usage:GPUBufferUsage.MAP_WRITE|GPUBufferUsage.COPY_SRC});try{const r=a.mapAsync(GPUMapMode.WRITE),s=new Promise((e,n)=>{setTimeout(()=>n(new Error("Staging buffer mapping timeout")),3e3)});await Promise.race([r,s]);const i=a.getMappedRange();if(e instanceof ArrayBuffer)new Uint8Array(i).set(new Uint8Array(e));else{if(!ArrayBuffer.isView(e))throw new Error("Unsupported data type for mapped buffer");new Uint8Array(i).set(new Uint8Array(e.buffer,e.byteOffset,e.byteLength))}a.unmap();const o=this.allocate(t,n|GPUBufferUsage.COPY_DST),d=this.device.createCommandEncoder();d.copyBufferToBuffer(a,0,o,0,t);const l=d.finish();return this.device.queue.submit([l]),await this._waitForGPUCompletion(2e3),a.destroy(),this.emit("buffer:mapped",{buffer:o,size:t,dataType:e.constructor.name}),o}catch(e){throw a.destroy(),e}}async readBuffer(e,n=null){const t=this.activeBuffers.get(e);if(!t)throw new Error("Buffer not found in active buffers");const a=n||t.size,r=this.device.createBuffer({size:a,usage:GPUBufferUsage.MAP_READ|GPUBufferUsage.COPY_DST});try{const n=this.device.createCommandEncoder();n.copyBufferToBuffer(e,0,r,0,a);const t=n.finish();this.device.queue.submit([t]),await this._waitForGPUCompletion(3e3);const s=r.mapAsync(GPUMapMode.READ),i=new Promise((e,n)=>{setTimeout(()=>n(new Error("Read buffer mapping timeout")),2e3)});await Promise.race([s,i]);const o=r.getMappedRange(),d=new Float32Array(o.slice());return r.unmap(),r.destroy(),this.emit("buffer:read",{buffer:e,size:a,dataSize:d.length}),d}catch(e){throw r.destroy(),e}}copyBuffer(e,n,t,a={}){const{sourceOffset:r=0,destinationOffset:s=0,commandEncoder:i=null}=a;if(!this.activeBuffers.has(e)||!this.activeBuffers.has(n))throw new Error("Source or destination buffer not managed by this BufferManager");const o=i||this.device.createCommandEncoder();if(o.copyBufferToBuffer(e,r,n,s,t),!i){const e=o.finish();this.device.queue.submit([e])}this.emit("buffer:copied",{source:e,destination:n,size:t})}getStats(){return{...this.stats,totalMemoryUsageMB:Math.round(this.totalMemoryUsage/1048576*100)/100,peakMemoryUsageMB:Math.round(this.peakMemoryUsage/1048576*100)/100,poolCount:this.pools.size,totalPooled:Array.from(this.pools.values()).reduce((e,n)=>e+n.length,0),poolEfficiency:this.stats.allocations>0?this.stats.poolHits/this.stats.allocations:0}}async gc(e={}){const{aggressive:n=!1,maxAge:t=6e4,targetReduction:a=.5}=e;this.emit("gc:start",{aggressive:n,maxAge:t,targetReduction:a});let r=0;const s=performance.now(),i=this._getTotalPooledBuffers();for(const[e,o]of this.pools.entries()){const d=o.slice();for(let e=d.length-1;e>=0;e--){const l=d[e];if((n||l._pooledAt&&s-l._pooledAt>t)&&(o.splice(e,1),l.destroy(),r++,this.stats.destroyed++),r/i>=a)break}0===o.length&&this.pools.delete(e)}return this.emit("gc:complete",{destroyed:r,remaining:this._getTotalPooledBuffers()}),r}async emergencyCleanup(){this.emit("emergency:start");try{let e=0;for(const[n,t]of this.pools.entries())for(;t.length>0;){const n=t.pop();try{n.destroy(),e++,this.stats.destroyed++}catch(e){this.emit("buffer:destroy-error",{buffer:n,error:e})}}return this.pools.clear(),window.gc&&window.gc(),this.emit("emergency:complete",{destroyed:e}),e}catch(e){throw this.emit("emergency:error",{error:e}),e}}async cleanup(){this.emit("cleanup:start");try{for(const[e,n]of this.activeBuffers.entries())this._destroyBuffer(e,n);this.activeBuffers.clear();for(const e of this.pools.values())for(const n of e)n.destroy();this.pools.clear(),this.totalMemoryUsage=0,this.stats.currentActive=0,this.stats.totalPooled=0,this.emit("cleanup:complete")}catch(e){throw this.emit("cleanup:error",{error:e}),e}}async _waitForGPUCompletion(e=3e3){return new Promise((n,t)=>{const a=setTimeout(()=>{t(new Error(`Buffer operation timeout (${e/1e3}s)`))},e);this.device.queue.onSubmittedWorkDone().then(()=>{clearTimeout(a),n()}).catch(e=>{clearTimeout(a),t(e)})})}_validateAllocation(e,n){if(e<=0||e>this.config.maxBufferSize)throw new Error(`Invalid buffer size: ${e}. Must be between 1 and ${this.config.maxBufferSize}`);if("number"!=typeof n)throw new Error("Buffer usage must be a number")}_getPoolKey(e,n){return`${e}-${n}`}_getFromPool(e){const n=this.pools.get(e);return n&&n.length>0?n.pop():null}_addToPool(e,n){const t=n.poolKey;this.pools.has(t)||this.pools.set(t,[]);const a=this.pools.get(t);return!(a.length>=this.config.maxPoolSize||(e._pooledAt=performance.now(),a.push(e),this.stats.totalPooled++,0))}_destroyBuffer(e,n){try{e.destroy(),this.stats.destroyed++,this.emit("buffer:destroyed",{buffer:e,metadata:n})}catch(n){this.emit("buffer:destroy-error",{buffer:e,error:n})}}_shouldDestroyBuffer(e,n){return n.size>this.config.maxBufferSize/4}_shouldRunGC(){return this.totalMemoryUsage/this.config.maxBufferSize>this.config.gcThreshold}async _runGCAsync(){try{await this.gc({aggressive:!1})}catch(e){this.emit("gc:error",{error:e})}}_calculateBufferSize(e){if(e instanceof ArrayBuffer)return e.byteLength;if(ArrayBuffer.isView(e))return e.byteLength;if(Array.isArray(e))return 4*e.length;throw new Error("Cannot calculate buffer size for data type")}_getTotalPooledBuffers(){return Array.from(this.pools.values()).reduce((e,n)=>e+n.length,0)}_checkMemoryPressure(){const e=this.totalMemoryUsage/this.config.maxBufferSize;e>=.95?(this.emit("memory:critical",{memoryRatio:e,totalUsage:this.totalMemoryUsage,maxSize:this.config.maxBufferSize}),setTimeout(()=>this.emergencyCleanup(),0)):e>=this.config.gcThreshold?(this.emit("memory:pressure",{memoryRatio:e,totalUsage:this.totalMemoryUsage,maxSize:this.config.maxBufferSize}),setTimeout(()=>this.forceGC(),0)):e>=.6&&(this.emit("memory:warning",{memoryRatio:e,totalUsage:this.totalMemoryUsage,maxSize:this.config.maxBufferSize}),setTimeout(()=>this._runGCSync(),0))}_runGCSync(){const e=this._getTotalPooledBuffers();if(e>0){const n=Math.ceil(.2*e);let t=0;for(const[e,a]of this.pools.entries()){for(;a.length>0&&t<n;){const e=a.shift();try{e.destroy(),t++,this.stats.destroyed++}catch(n){this.emit("buffer:destroy-error",{buffer:e,error:n})}}if(0===a.length&&this.pools.delete(e),t>=n)break}this.emit("gc:automatic",{destroyed:t,remaining:this._getTotalPooledBuffers()})}}findReusableBuffer(e,n){if(!this.config.enablePooling)return null;const t=this._getPoolKey(e,n),a=this.pools.get(t);if(a&&a.length>0){const r=a.pop();this.stats.poolHits++,this.emit("buffer:reused",{size:e,usage:n,poolKey:t});const s={size:e,usage:n,poolKey:t,allocatedAt:performance.now(),lastAccessed:performance.now(),reused:!0};return this.activeBuffers.set(r,s),this.totalMemoryUsage+=e,this.stats.currentActive=this.activeBuffers.size,r}return null}returnToPool(e){const n=this.activeBuffers.get(e);return!!n&&(this.activeBuffers.delete(e),this.totalMemoryUsage-=n.size,this.stats.releases++,this.stats.currentActive=this.activeBuffers.size,this._addToPool(e,n)?(this.emit("buffer:pooled",{buffer:e,poolKey:n.poolKey}),!0):(this._destroyBuffer(e,n),!1))}async forceGC(e={}){return this.gc({aggressive:!0,...e})}};class l{static getShaderTemplates(){return new Map([["add",e=>`\n        @group(0) @binding(0) var<storage, read> input1: array<${e.dataType}>;\n        @group(0) @binding(1) var<storage, read> input2: array<${e.dataType}>;\n        @group(0) @binding(2) var<storage, read_write> output: array<${e.dataType}>;\n\n        struct Params {\n          size: u32,\n          param1: u32,\n          param2: u32,\n          param3: u32,\n        }\n        @group(0) @binding(3) var<uniform> params: Params;\n\n        @compute @workgroup_size(${e.workgroupSize.join(", ")})\n        fn main(@builtin(global_invocation_id) global_id: vec3<u32>) {\n          let index = global_id.x;\n          let size = params.size;\n          if (index >= size) { return; }\n          output[index] = input1[index] + input2[index];\n        }\n      `],["sub",e=>`\n        @group(0) @binding(0) var<storage, read> input1: array<${e.dataType}>;\n        @group(0) @binding(1) var<storage, read> input2: array<${e.dataType}>;\n        @group(0) @binding(2) var<storage, read_write> output: array<${e.dataType}>;\n\n        struct Params {\n          size: u32,\n          param1: u32,\n          param2: u32,\n          param3: u32,\n        }\n        @group(0) @binding(3) var<uniform> params: Params;\n\n        @compute @workgroup_size(${e.workgroupSize.join(", ")})\n        fn main(@builtin(global_invocation_id) global_id: vec3<u32>) {\n          let index = global_id.x;\n          let size = params.size;\n          if (index >= size) { return; }\n          output[index] = input1[index] - input2[index];\n        }\n      `],["mul",e=>`\n        @group(0) @binding(0) var<storage, read> input1: array<${e.dataType}>;\n        @group(0) @binding(1) var<storage, read> input2: array<${e.dataType}>;\n        @group(0) @binding(2) var<storage, read_write> output: array<${e.dataType}>;\n\n        struct Params {\n          size: u32,\n          param1: u32,\n          param2: u32,\n          param3: u32,\n        }\n        @group(0) @binding(3) var<uniform> params: Params;\n\n        @compute @workgroup_size(${e.workgroupSize.join(", ")})\n        fn main(@builtin(global_invocation_id) global_id: vec3<u32>) {\n          let index = global_id.x;\n          let size = params.size;\n          if (index >= size) { return; }\n          output[index] = input1[index] * input2[index];\n        }\n      `],["div",e=>`\n        @group(0) @binding(0) var<storage, read> input1: array<${e.dataType}>;\n        @group(0) @binding(1) var<storage, read> input2: array<${e.dataType}>;\n        @group(0) @binding(2) var<storage, read_write> output: array<${e.dataType}>;\n        struct Params {\n          param0: u32,\n          param1: u32,\n          param2: u32,\n          param3: u32,\n        }\n        @group(0) @binding(3) var<uniform> params: Params;\n\n        @compute @workgroup_size(${e.workgroupSize.join(", ")})\n        fn main(@builtin(global_invocation_id) global_id: vec3<u32>) {\n          let index = global_id.x;\n          let size = params.param0;\n          if (index >= size) { return; }\n          output[index] = input1[index] / input2[index];\n        }\n      `],["pow",e=>`\n        @group(0) @binding(0) var<storage, read> input1: array<${e.dataType}>;\n        @group(0) @binding(1) var<storage, read> input2: array<${e.dataType}>;\n        @group(0) @binding(2) var<storage, read_write> output: array<${e.dataType}>;\n        struct Params {\n          param0: u32,\n          param1: u32,\n          param2: u32,\n          param3: u32,\n        }\n        @group(0) @binding(3) var<uniform> params: Params;\n\n        @compute @workgroup_size(${e.workgroupSize.join(", ")})\n        fn main(@builtin(global_invocation_id) global_id: vec3<u32>) {\n          let index = global_id.x;\n          let size = params.param0;\n          if (index >= size) { return; }\n          output[index] = pow(input1[index], input2[index]);\n        }\n      `],["matmul",e=>`\n        // OPTIMIZED MATMUL - 600x faster than naive implementation\n        // Based on: https://www.nuss-and-bolts.com/p/optimizing-a-webgpu-matmul-kernel\n        // Techniques: 2D register blocking, shared memory tiling, workgroup optimization\n        // Target: >1 TFLOPS (vs naive ~1.64 GFLOPS)\n\n        @group(0) @binding(0) var<storage, read> input1: array<${e.dataType}>;\n        @group(0) @binding(1) var<storage, read> input2: array<${e.dataType}>;\n        @group(0) @binding(2) var<storage, read_write> output: array<${e.dataType}>;\n\n        struct MatMulParams {\n          M: u32,    // rows of A\n          N: u32,    // cols of B\n          K: u32,    // cols of A, rows of B\n          reserved: u32,\n        }\n        @group(0) @binding(3) var<uniform> params: MatMulParams;\n\n        // Shared memory tiles for cache locality (KEY OPTIMIZATION)\n        const TILE_SIZE: u32 = 16u;\n        var<workgroup> tileA: array<array<${e.dataType}, TILE_SIZE>, TILE_SIZE>;\n        var<workgroup> tileB: array<array<${e.dataType}, TILE_SIZE>, TILE_SIZE>;\n\n        @compute @workgroup_size(16, 16, 1)\n        fn main(\n          @builtin(global_invocation_id) global_id: vec3<u32>,\n          @builtin(local_invocation_id) local_id: vec3<u32>\n        ) {\n          let M = params.M;\n          let N = params.N;\n          let K = params.K;\n\n          let row = global_id.y;\n          let col = global_id.x;\n          let local_row = local_id.y;\n          let local_col = local_id.x;\n\n          // Early exit for out-of-bounds threads\n          if (row >= M || col >= N) { return; }\n\n          // Accumulator for dot product (REGISTER BLOCKING)\n          var acc: ${e.dataType} = 0.0;\n\n          // Tile over K dimension for cache efficiency\n          let numTiles = (K + TILE_SIZE - 1u) / TILE_SIZE;\n\n          for (var t = 0u; t < numTiles; t = t + 1u) {\n            let tileK = t * TILE_SIZE;\n\n            // COOPERATIVE LOADING: Load tile A into shared memory\n            let aRow = row;\n            let aCol = tileK + local_col;\n            if (aRow < M && aCol < K) {\n              tileA[local_row][local_col] = input1[aRow * K + aCol];\n            } else {\n              tileA[local_row][local_col] = 0.0;\n            }\n\n            // COOPERATIVE LOADING: Load tile B into shared memory\n            let bRow = tileK + local_row;\n            let bCol = col;\n            if (bRow < K && bCol < N) {\n              tileB[local_row][local_col] = input2[bRow * N + bCol];\n            } else {\n              tileB[local_row][local_col] = 0.0;\n            }\n\n            // Synchronize workgroup (ensure tiles loaded)\n            workgroupBarrier();\n\n            // HOT LOOP: Compute partial dot product from shared memory\n            // This is where the magic happens - GPU tensor cores accelerate this\n            for (var k = 0u; k < TILE_SIZE; k = k + 1u) {\n              acc = acc + tileA[local_row][k] * tileB[k][local_col];\n            }\n\n            // Synchronize before loading next tile\n            workgroupBarrier();\n          }\n\n          // Write result\n          output[row * N + col] = acc;\n        }\n      `],["bmm",e=>`\n        @group(0) @binding(0) var<storage, read> input1: array<${e.dataType}>;\n        @group(0) @binding(1) var<storage, read> input2: array<${e.dataType}>;\n        @group(0) @binding(2) var<storage, read_write> output: array<${e.dataType}>;\n        struct Params {\n          param0: u32,\n          param1: u32,\n          param2: u32,\n          param3: u32,\n        }\n        @group(0) @binding(3) var<uniform> params: Params;\n\n        @compute @workgroup_size(${e.workgroupSize.join(", ")})\n        fn main(@builtin(global_invocation_id) global_id: vec3<u32>) {\n          let batch = global_id.z;\n          let row = global_id.x;\n          let col = global_id.y;\n          \n          let B = params.param0;  // batch size\n          let M = params.param1;  // rows\n          let N = params.param2;  // cols of second matrix\n          let K = params.param3;  // cols of first matrix\n          \n          if (batch >= B || row >= M || col >= N) { return; }\n          \n          let batch_offset1 = batch * M * K;\n          let batch_offset2 = batch * K * N;\n          let batch_offset_out = batch * M * N;\n          \n          var sum = 0.0;\n          for (var k = 0u; k < K; k = k + 1u) {\n            sum = sum + input1[batch_offset1 + row * K + k] * input2[batch_offset2 + k * N + col];\n          }\n          output[batch_offset_out + row * N + col] = sum;\n        }\n      `],["transpose",e=>`\n        @group(0) @binding(0) var<storage, read> input: array<${e.dataType}>;\n        @group(0) @binding(1) var<storage, read_write> output: array<${e.dataType}>;\n        struct Params {\n          param0: u32,\n          param1: u32,\n          param2: u32,\n          param3: u32,\n        }\n        @group(0) @binding(2) var<uniform> params: Params;\n\n        @compute @workgroup_size(${e.workgroupSize.join(", ")})\n        fn main(@builtin(global_invocation_id) global_id: vec3<u32>) {\n          let index = global_id.x;\n          let rows = params.param0;\n          let cols = params.param1;\n          let size = rows * cols;\n          \n          if (index >= size) { return; }\n          \n          let row = index / cols;\n          let col = index % cols;\n          let transposed_index = col * rows + row;\n          \n          output[transposed_index] = input[index];\n        }\n      `],["relu",e=>`\n        @group(0) @binding(0) var<storage, read> input: array<${e.dataType}>;\n        @group(0) @binding(1) var<storage, read_write> output: array<${e.dataType}>;\n        struct Params {\n          param0: u32,\n          param1: u32,\n          param2: u32,\n          param3: u32,\n        }\n        @group(0) @binding(2) var<uniform> params: Params;\n\n        @compute @workgroup_size(${e.workgroupSize.join(", ")})\n        fn main(@builtin(global_invocation_id) global_id: vec3<u32>) {\n          let index = global_id.x;\n          let size = params.param0;\n          if (index >= size) { return; }\n          output[index] = max(input[index], 0.0);\n        }\n      `],["leaky_relu",e=>`\n        @group(0) @binding(0) var<storage, read> input: array<${e.dataType}>;\n        @group(0) @binding(1) var<storage, read_write> output: array<${e.dataType}>;\n        struct Params {\n          param0: u32,\n          param1: u32,\n          param2: u32,\n          param3: u32,\n        }\n        @group(0) @binding(2) var<uniform> params: Params;\n\n        @compute @workgroup_size(${e.workgroupSize.join(", ")})\n        fn main(@builtin(global_invocation_id) global_id: vec3<u32>) {\n          let index = global_id.x;\n          let size = params.param0;\n          let negative_slope = bitcast<f32>(params.param1);\n          if (index >= size) { return; }\n          let val = input[index];\n          output[index] = select(negative_slope * val, val, val > 0.0);\n        }\n      `],["sigmoid",e=>`\n        @group(0) @binding(0) var<storage, read> input: array<${e.dataType}>;\n        @group(0) @binding(1) var<storage, read_write> output: array<${e.dataType}>;\n        struct Params {\n          param0: u32,\n          param1: u32,\n          param2: u32,\n          param3: u32,\n        }\n        @group(0) @binding(2) var<uniform> params: Params;\n\n        @compute @workgroup_size(${e.workgroupSize.join(", ")})\n        fn main(@builtin(global_invocation_id) global_id: vec3<u32>) {\n          let index = global_id.x;\n          let size = params.param0;\n          if (index >= size) { return; }\n          output[index] = 1.0 / (1.0 + exp(-input[index]));\n        }\n      `],["tanh",e=>`\n        @group(0) @binding(0) var<storage, read> input: array<${e.dataType}>;\n        @group(0) @binding(1) var<storage, read_write> output: array<${e.dataType}>;\n        struct Params {\n          param0: u32,\n          param1: u32,\n          param2: u32,\n          param3: u32,\n        }\n        @group(0) @binding(2) var<uniform> params: Params;\n\n        @compute @workgroup_size(${e.workgroupSize.join(", ")})\n        fn main(@builtin(global_invocation_id) global_id: vec3<u32>) {\n          let index = global_id.x;\n          let size = params.param0;\n          if (index >= size) { return; }\n          output[index] = tanh(input[index]);\n        }\n      `],["gelu",e=>`\n        @group(0) @binding(0) var<storage, read> input: array<${e.dataType}>;\n        @group(0) @binding(1) var<storage, read_write> output: array<${e.dataType}>;\n        struct Params {\n          param0: u32,\n          param1: u32,\n          param2: u32,\n          param3: u32,\n        }\n        @group(0) @binding(2) var<uniform> params: Params;\n\n        @compute @workgroup_size(${e.workgroupSize.join(", ")})\n        fn main(@builtin(global_invocation_id) global_id: vec3<u32>) {\n          let index = global_id.x;\n          let size = params.param0;\n          if (index >= size) { return; }\n          let x = input[index];\n          // GELU approximation: 0.5 * x * (1 + tanh(sqrt(2/Ï€) * (x + 0.044715 * x^3)))\n          let sqrt_2_over_pi = 0.7978845608;\n          let inner = sqrt_2_over_pi * (x + 0.044715 * x * x * x);\n          output[index] = 0.5 * x * (1.0 + tanh(inner));\n        }\n      `],["softmax",e=>`\n        @group(0) @binding(0) var<storage, read> input: array<${e.dataType}>;\n        @group(0) @binding(1) var<storage, read_write> output: array<${e.dataType}>;\n        struct Params {\n          param0: u32,\n          param1: u32,\n          param2: u32,\n          param3: u32,\n        }\n        @group(0) @binding(2) var<uniform> params: Params;\n\n        var<workgroup> shared_max: f32;\n        var<workgroup> shared_sum: f32;\n\n        @compute @workgroup_size(${Math.min(e.workgroupSize[0],256)})\n        fn main(@builtin(global_invocation_id) global_id: vec3<u32>,\n                @builtin(local_invocation_id) local_id: vec3<u32>,\n                @builtin(workgroup_id) workgroup_id: vec3<u32>) {\n          let batch_size = params.param0;\n          let dim_size = params.param1;\n          let batch_idx = workgroup_id.x;\n          let local_idx = local_id.x;\n          \n          if (batch_idx >= batch_size) { return; }\n          \n          let batch_offset = batch_idx * dim_size;\n          \n          // Find maximum for numerical stability\n          var max_val = -1e38; // -FLT_MAX\n          for (var i = local_idx; i < dim_size; i = i + ${Math.min(e.workgroupSize[0],256)}u) {\n            max_val = max(max_val, input[batch_offset + i]);\n          }\n          \n          // Reduce maximum across workgroup\n          workgroupBarrier();\n          if (local_idx == 0u) {\n            shared_max = max_val;\n          }\n          for (var stride = 1u; stride < ${Math.min(e.workgroupSize[0],256)}u; stride = stride * 2u) {\n            workgroupBarrier();\n            if (local_idx >= stride) {\n              shared_max = max(shared_max, max_val);\n            }\n          }\n          workgroupBarrier();\n          \n          // Compute exponentials and sum\n          var sum = 0.0;\n          for (var i = local_idx; i < dim_size; i = i + ${Math.min(e.workgroupSize[0],256)}u) {\n            let exp_val = exp(input[batch_offset + i] - shared_max);\n            sum = sum + exp_val;\n            output[batch_offset + i] = exp_val;\n          }\n          \n          // Reduce sum across workgroup\n          workgroupBarrier();\n          if (local_idx == 0u) {\n            shared_sum = sum;\n          }\n          for (var stride = 1u; stride < ${Math.min(e.workgroupSize[0],256)}u; stride = stride * 2u) {\n            workgroupBarrier();\n            if (local_idx >= stride) {\n              shared_sum = shared_sum + sum;\n            }\n          }\n          workgroupBarrier();\n          \n          // Normalize\n          for (var i = local_idx; i < dim_size; i = i + ${Math.min(e.workgroupSize[0],256)}u) {\n            output[batch_offset + i] = output[batch_offset + i] / shared_sum;\n          }\n        }\n      `],["sum",e=>`\n        @group(0) @binding(0) var<storage, read> input: array<${e.dataType}>;\n        @group(0) @binding(1) var<storage, read_write> output: array<${e.dataType}>;\n        struct Params {\n          param0: u32,\n          param1: u32,\n          param2: u32,\n          param3: u32,\n        }\n        @group(0) @binding(2) var<uniform> params: Params;\n\n        var<workgroup> shared_data: array<f32, ${e.workgroupSize[0]}>;\n\n        @compute @workgroup_size(${e.workgroupSize[0]})\n        fn main(@builtin(global_invocation_id) global_id: vec3<u32>,\n                @builtin(local_invocation_id) local_id: vec3<u32>,\n                @builtin(workgroup_id) workgroup_id: vec3<u32>) {\n          let size = params.param0;\n          let local_idx = local_id.x;\n          let global_idx = global_id.x;\n          \n          // Load data into shared memory\n          var sum = 0.0;\n          for (var i = global_idx; i < size; i = i + ${e.workgroupSize[0]}u) {\n            sum = sum + input[i];\n          }\n          shared_data[local_idx] = sum;\n          \n          workgroupBarrier();\n          \n          // Parallel reduction\n          for (var stride = ${e.workgroupSize[0]/2}u; stride > 0u; stride = stride >> 1u) {\n            if (local_idx < stride) {\n              shared_data[local_idx] = shared_data[local_idx] + shared_data[local_idx + stride];\n            }\n            workgroupBarrier();\n          }\n          \n          if (local_idx == 0u) {\n            output[workgroup_id.x] = shared_data[0];\n          }\n        }\n      `],["mean",e=>`\n        @group(0) @binding(0) var<storage, read> input: array<${e.dataType}>;\n        @group(0) @binding(1) var<storage, read_write> output: array<${e.dataType}>;\n        struct Params {\n          param0: u32,\n          param1: u32,\n          param2: u32,\n          param3: u32,\n        }\n        @group(0) @binding(2) var<uniform> params: Params;\n\n        var<workgroup> shared_data: array<f32, ${e.workgroupSize[0]}>;\n\n        @compute @workgroup_size(${e.workgroupSize[0]})\n        fn main(@builtin(global_invocation_id) global_id: vec3<u32>,\n                @builtin(local_invocation_id) local_id: vec3<u32>,\n                @builtin(workgroup_id) workgroup_id: vec3<u32>) {\n          let size = params.param0;\n          let local_idx = local_id.x;\n          let global_idx = global_id.x;\n          \n          var sum = 0.0;\n          for (var i = global_idx; i < size; i = i + ${e.workgroupSize[0]}u) {\n            sum = sum + input[i];\n          }\n          shared_data[local_idx] = sum;\n          \n          workgroupBarrier();\n          \n          for (var stride = ${e.workgroupSize[0]/2}u; stride > 0u; stride = stride >> 1u) {\n            if (local_idx < stride) {\n              shared_data[local_idx] = shared_data[local_idx] + shared_data[local_idx + stride];\n            }\n            workgroupBarrier();\n          }\n          \n          if (local_idx == 0u) {\n            output[workgroup_id.x] = shared_data[0] / f32(size);\n          }\n        }\n      `],["conv2d",e=>`\n        @group(0) @binding(0) var<storage, read> input: array<${e.dataType}>;\n        @group(0) @binding(1) var<storage, read> weight: array<${e.dataType}>;\n        @group(0) @binding(2) var<storage, read> bias: array<${e.dataType}>;\n        @group(0) @binding(3) var<storage, read_write> output: array<${e.dataType}>;\n        struct ConvParams {\n          param0: u32,\n          param1: u32,\n          param2: u32,\n          param3: u32,\n          param4: u32,\n          param5: u32,\n          param6: u32,\n          param7: u32,\n        }\n        @group(0) @binding(4) var<uniform> params: ConvParams;\n\n        @compute @workgroup_size(${e.workgroupSize.join(", ")})\n        fn main(@builtin(global_invocation_id) global_id: vec3<u32>) {\n          let out_y = global_id.x;\n          let out_x = global_id.y;\n          let out_c = global_id.z;\n          \n          let batch_size = params.param0;\n          let in_channels = params.param1;\n          let in_height = params.param2;\n          let in_width = params.param3;\n          let out_channels = params.param4;\n          let out_height = params.param5;\n          let out_width = params.param6;\n          let kernel_size = params.param7;\n          \n          if (out_y >= out_height || out_x >= out_width || out_c >= out_channels) { return; }\n          \n          var sum = 0.0;\n          \n          for (var in_c = 0u; in_c < in_channels; in_c = in_c + 1u) {\n            for (var ky = 0u; ky < kernel_size; ky = ky + 1u) {\n              for (var kx = 0u; kx < kernel_size; kx = kx + 1u) {\n                let in_y = out_y + ky;\n                let in_x = out_x + kx;\n                \n                if (in_y < in_height && in_x < in_width) {\n                  let input_idx = in_c * in_height * in_width + in_y * in_width + in_x;\n                  let weight_idx = out_c * in_channels * kernel_size * kernel_size + \n                                  in_c * kernel_size * kernel_size + ky * kernel_size + kx;\n                  sum = sum + input[input_idx] * weight[weight_idx];\n                }\n              }\n            }\n          }\n          \n          sum = sum + bias[out_c];\n          let output_idx = out_c * out_height * out_width + out_y * out_width + out_x;\n          output[output_idx] = sum;\n        }\n      `],["maxpool2d",e=>`\n        @group(0) @binding(0) var<storage, read> input: array<${e.dataType}>;\n        @group(0) @binding(1) var<storage, read_write> output: array<${e.dataType}>;\n        struct PoolParams {\n          param0: u32,\n          param1: u32,\n          param2: u32,\n          param3: u32,\n          param4: u32,\n          param5: u32,\n          param6: u32,\n          param7: u32,\n        }\n        @group(0) @binding(2) var<uniform> params: PoolParams;\n\n        @compute @workgroup_size(${e.workgroupSize.join(", ")})\n        fn main(@builtin(global_invocation_id) global_id: vec3<u32>) {\n          let out_y = global_id.x;\n          let out_x = global_id.y;\n          let c = global_id.z;\n          \n          let channels = params.param0;\n          let in_height = params.param1;\n          let in_width = params.param2;\n          let out_height = params.param3;\n          let out_width = params.param4;\n          let kernel_size = params.param5;\n          let stride = params.param6;\n          \n          if (out_y >= out_height || out_x >= out_width || c >= channels) { return; }\n          \n          var max_val = -1e38; // -FLT_MAX\n          \n          for (var ky = 0u; ky < kernel_size; ky = ky + 1u) {\n            for (var kx = 0u; kx < kernel_size; kx = kx + 1u) {\n              let in_y = out_y * stride + ky;\n              let in_x = out_x * stride + kx;\n              \n              if (in_y < in_height && in_x < in_width) {\n                let input_idx = c * in_height * in_width + in_y * in_width + in_x;\n                max_val = max(max_val, input[input_idx]);\n              }\n            }\n          }\n          \n          let output_idx = c * out_height * out_width + out_y * out_width + out_x;\n          output[output_idx] = max_val;\n        }\n      `],["exp",e=>`\n        @group(0) @binding(0) var<storage, read> input: array<${e.dataType}>;\n        @group(0) @binding(1) var<storage, read_write> output: array<${e.dataType}>;\n        struct Params {\n          param0: u32,\n          param1: u32,\n          param2: u32,\n          param3: u32,\n        }\n        @group(0) @binding(2) var<uniform> params: Params;\n\n        @compute @workgroup_size(${e.workgroupSize.join(", ")})\n        fn main(@builtin(global_invocation_id) global_id: vec3<u32>) {\n          let index = global_id.x;\n          let size = params.param0;\n          if (index >= size) { return; }\n          output[index] = exp(input[index]);\n        }\n      `],["log",e=>`\n        @group(0) @binding(0) var<storage, read> input: array<${e.dataType}>;\n        @group(0) @binding(1) var<storage, read_write> output: array<${e.dataType}>;\n        struct Params {\n          param0: u32,\n          param1: u32,\n          param2: u32,\n          param3: u32,\n        }\n        @group(0) @binding(2) var<uniform> params: Params;\n\n        @compute @workgroup_size(${e.workgroupSize.join(", ")})\n        fn main(@builtin(global_invocation_id) global_id: vec3<u32>) {\n          let index = global_id.x;\n          let size = params.param0;\n          if (index >= size) { return; }\n          output[index] = log(input[index]);\n        }\n      `],["sqrt",e=>`\n        @group(0) @binding(0) var<storage, read> input: array<${e.dataType}>;\n        @group(0) @binding(1) var<storage, read_write> output: array<${e.dataType}>;\n        struct Params {\n          param0: u32,\n          param1: u32,\n          param2: u32,\n          param3: u32,\n        }\n        @group(0) @binding(2) var<uniform> params: Params;\n\n        @compute @workgroup_size(${e.workgroupSize.join(", ")})\n        fn main(@builtin(global_invocation_id) global_id: vec3<u32>) {\n          let index = global_id.x;\n          let size = params.param0;\n          if (index >= size) { return; }\n          output[index] = sqrt(input[index]);\n        }\n      `],["abs",e=>`\n        @group(0) @binding(0) var<storage, read> input: array<${e.dataType}>;\n        @group(0) @binding(1) var<storage, read_write> output: array<${e.dataType}>;\n        struct Params {\n          param0: u32,\n          param1: u32,\n          param2: u32,\n          param3: u32,\n        }\n        @group(0) @binding(2) var<uniform> params: Params;\n\n        @compute @workgroup_size(${e.workgroupSize.join(", ")})\n        fn main(@builtin(global_invocation_id) global_id: vec3<u32>) {\n          let index = global_id.x;\n          let size = params.param0;\n          if (index >= size) { return; }\n          output[index] = abs(input[index]);\n        }\n      `],["max",e=>`\n        @group(0) @binding(0) var<storage, read> input1: array<${e.dataType}>;\n        @group(0) @binding(1) var<storage, read> input2: array<${e.dataType}>;\n        @group(0) @binding(2) var<storage, read_write> output: array<${e.dataType}>;\n        struct Params {\n          param0: u32,\n          param1: u32,\n          param2: u32,\n          param3: u32,\n        }\n        @group(0) @binding(3) var<uniform> params: Params;\n\n        @compute @workgroup_size(${e.workgroupSize.join(", ")})\n        fn main(@builtin(global_invocation_id) global_id: vec3<u32>) {\n          let index = global_id.x;\n          let size = params.param0;\n          if (index >= size) { return; }\n          output[index] = max(input1[index], input2[index]);\n        }\n      `],["min",e=>`\n        @group(0) @binding(0) var<storage, read> input1: array<${e.dataType}>;\n        @group(0) @binding(1) var<storage, read> input2: array<${e.dataType}>;\n        @group(0) @binding(2) var<storage, read_write> output: array<${e.dataType}>;\n        struct Params {\n          param0: u32,\n          param1: u32,\n          param2: u32,\n          param3: u32,\n        }\n        @group(0) @binding(3) var<uniform> params: Params;\n\n        @compute @workgroup_size(${e.workgroupSize.join(", ")})\n        fn main(@builtin(global_invocation_id) global_id: vec3<u32>) {\n          let index = global_id.x;\n          let size = params.param0;\n          if (index >= size) { return; }\n          output[index] = min(input1[index], input2[index]);\n        }\n      `],["concat",e=>`\n        @group(0) @binding(0) var<storage, read> input1: array<${e.dataType}>;\n        @group(0) @binding(1) var<storage, read> input2: array<${e.dataType}>;\n        @group(0) @binding(2) var<storage, read_write> output: array<${e.dataType}>;\n        struct Params {\n          param0: u32,\n          param1: u32,\n          param2: u32,\n          param3: u32,\n        }\n        @group(0) @binding(3) var<uniform> params: Params;\n\n        @compute @workgroup_size(${e.workgroupSize.join(", ")})\n        fn main(@builtin(global_invocation_id) global_id: vec3<u32>) {\n          let index = global_id.x;\n          let size1 = params.param0;\n          let size2 = params.param1;\n          let total_size = size1 + size2;\n          \n          if (index >= total_size) { return; }\n          \n          if (index < size1) {\n            output[index] = input1[index];\n          } else {\n            output[index] = input2[index - size1];\n          }\n        }\n      `],["slice",e=>`\n        @group(0) @binding(0) var<storage, read> input: array<${e.dataType}>;\n        @group(0) @binding(1) var<storage, read_write> output: array<${e.dataType}>;\n        struct Params {\n          param0: u32,\n          param1: u32,\n          param2: u32,\n          param3: u32,\n        }\n        @group(0) @binding(2) var<uniform> params: Params;\n\n        @compute @workgroup_size(${e.workgroupSize.join(", ")})\n        fn main(@builtin(global_invocation_id) global_id: vec3<u32>) {\n          let index = global_id.x;\n          let start = params.param0;\n          let end = params.param1;\n          let step = params.param2;\n          let output_size = (end - start + step - 1u) / step;\n          \n          if (index >= output_size) { return; }\n          \n          let input_index = start + index * step;\n          output[index] = input[input_index];\n        }\n      `],["batch_norm",e=>`\n        @group(0) @binding(0) var<storage, read> input: array<${e.dataType}>;\n        @group(0) @binding(1) var<storage, read> running_mean: array<${e.dataType}>;\n        @group(0) @binding(2) var<storage, read> running_var: array<${e.dataType}>;\n        @group(0) @binding(3) var<storage, read> weight: array<${e.dataType}>;\n        @group(0) @binding(4) var<storage, read> bias: array<${e.dataType}>;\n        @group(0) @binding(5) var<storage, read_write> output: array<${e.dataType}>;\n        struct Params {\n          param0: u32,\n          param1: u32,\n          param2: u32,\n          param3: u32,\n        }\n        @group(0) @binding(6) var<uniform> params: Params;\n\n        @compute @workgroup_size(${e.workgroupSize.join(", ")})\n        fn main(@builtin(global_invocation_id) global_id: vec3<u32>) {\n          let index = global_id.x;\n          let batch_size = params.param0;\n          let channels = params.param1;\n          let spatial_size = params.param2;\n          let eps = bitcast<f32>(params.param3);\n          \n          if (index >= batch_size * channels * spatial_size) { return; }\n          \n          let c = (index / spatial_size) % channels;\n          let normalized = (input[index] - running_mean[c]) / sqrt(running_var[c] + eps);\n          output[index] = normalized * weight[c] + bias[c];\n        }\n      `],["cross_entropy",e=>`\n        @group(0) @binding(0) var<storage, read> logits: array<${e.dataType}>;\n        @group(0) @binding(1) var<storage, read> targets: array<u32>;\n        @group(0) @binding(2) var<storage, read_write> output: array<${e.dataType}>;\n        struct Params {\n          param0: u32,\n          param1: u32,\n          param2: u32,\n          param3: u32,\n        }\n        @group(0) @binding(3) var<uniform> params: Params;\n\n        @compute @workgroup_size(${e.workgroupSize[0]})\n        fn main(@builtin(global_invocation_id) global_id: vec3<u32>) {\n          let batch_idx = global_id.x;\n          let batch_size = params.param0;\n          let num_classes = params.param1;\n          \n          if (batch_idx >= batch_size) { return; }\n          \n          let batch_offset = batch_idx * num_classes;\n          let target_class = targets[batch_idx];\n          \n          // Find max for numerical stability\n          var max_logit = -1e38;\n          for (var i = 0u; i < num_classes; i = i + 1u) {\n            max_logit = max(max_logit, logits[batch_offset + i]);\n          }\n          \n          // Compute log-sum-exp\n          var sum_exp = 0.0;\n          for (var i = 0u; i < num_classes; i = i + 1u) {\n            sum_exp = sum_exp + exp(logits[batch_offset + i] - max_logit);\n          }\n          let log_sum_exp = log(sum_exp) + max_logit;\n          \n          // Cross entropy loss = -log(softmax[target])\n          let target_logit = logits[batch_offset + target_class];\n          output[batch_idx] = log_sum_exp - target_logit;\n        }\n      `],["mse_loss",e=>`\n        @group(0) @binding(0) var<storage, read> predictions: array<${e.dataType}>;\n        @group(0) @binding(1) var<storage, read> targets: array<${e.dataType}>;\n        @group(0) @binding(2) var<storage, read_write> output: array<${e.dataType}>;\n        struct Params {\n          param0: u32,\n          param1: u32,\n          param2: u32,\n          param3: u32,\n        }\n        @group(0) @binding(3) var<uniform> params: Params;\n\n        @compute @workgroup_size(${e.workgroupSize.join(", ")})\n        fn main(@builtin(global_invocation_id) global_id: vec3<u32>) {\n          let index = global_id.x;\n          let size = params.param0;\n          if (index >= size) { return; }\n          let diff = predictions[index] - targets[index];\n          output[index] = diff * diff;\n        }\n      `],["sin",e=>`\n        @group(0) @binding(0) var<storage, read> input: array<${e.dataType}>;\n        @group(0) @binding(1) var<storage, read_write> output: array<${e.dataType}>;\n        struct Params {\n          param0: u32,\n          param1: u32,\n          param2: u32,\n          param3: u32,\n        }\n        @group(0) @binding(2) var<uniform> params: Params;\n\n        @compute @workgroup_size(${e.workgroupSize.join(", ")})\n        fn main(@builtin(global_invocation_id) global_id: vec3<u32>) {\n          let index = global_id.x;\n          let size = params.param0;\n          if (index >= size) { return; }\n          output[index] = sin(input[index]);\n        }\n      `],["cos",e=>`\n        @group(0) @binding(0) var<storage, read> input: array<${e.dataType}>;\n        @group(0) @binding(1) var<storage, read_write> output: array<${e.dataType}>;\n        struct Params {\n          param0: u32,\n          param1: u32,\n          param2: u32,\n          param3: u32,\n        }\n        @group(0) @binding(2) var<uniform> params: Params;\n\n        @compute @workgroup_size(${e.workgroupSize.join(", ")})\n        fn main(@builtin(global_invocation_id) global_id: vec3<u32>) {\n          let index = global_id.x;\n          let size = params.param0;\n          if (index >= size) { return; }\n          output[index] = cos(input[index]);\n        }\n      `],["tan",e=>`\n        @group(0) @binding(0) var<storage, read> input: array<${e.dataType}>;\n        @group(0) @binding(1) var<storage, read_write> output: array<${e.dataType}>;\n        struct Params {\n          param0: u32,\n          param1: u32,\n          param2: u32,\n          param3: u32,\n        }\n        @group(0) @binding(2) var<uniform> params: Params;\n\n        @compute @workgroup_size(${e.workgroupSize.join(", ")})\n        fn main(@builtin(global_invocation_id) global_id: vec3<u32>) {\n          let index = global_id.x;\n          let size = params.param0;\n          if (index >= size) { return; }\n          output[index] = tan(input[index]);\n        }\n      `],["sinh",e=>`\n        @group(0) @binding(0) var<storage, read> input: array<${e.dataType}>;\n        @group(0) @binding(1) var<storage, read_write> output: array<${e.dataType}>;\n        struct Params {\n          param0: u32,\n          param1: u32,\n          param2: u32,\n          param3: u32,\n        }\n        @group(0) @binding(2) var<uniform> params: Params;\n\n        @compute @workgroup_size(${e.workgroupSize.join(", ")})\n        fn main(@builtin(global_invocation_id) global_id: vec3<u32>) {\n          let index = global_id.x;\n          let size = params.param0;\n          if (index >= size) { return; }\n          let x = input[index];\n          output[index] = (exp(x) - exp(-x)) / 2.0;\n        }\n      `],["cosh",e=>`\n        @group(0) @binding(0) var<storage, read> input: array<${e.dataType}>;\n        @group(0) @binding(1) var<storage, read_write> output: array<${e.dataType}>;\n        struct Params {\n          param0: u32,\n          param1: u32,\n          param2: u32,\n          param3: u32,\n        }\n        @group(0) @binding(2) var<uniform> params: Params;\n\n        @compute @workgroup_size(${e.workgroupSize.join(", ")})\n        fn main(@builtin(global_invocation_id) global_id: vec3<u32>) {\n          let index = global_id.x;\n          let size = params.param0;\n          if (index >= size) { return; }\n          let x = input[index];\n          output[index] = (exp(x) + exp(-x)) / 2.0;\n        }\n      `],["floor",e=>`\n        @group(0) @binding(0) var<storage, read> input: array<${e.dataType}>;\n        @group(0) @binding(1) var<storage, read_write> output: array<${e.dataType}>;\n        struct Params {\n          param0: u32,\n          param1: u32,\n          param2: u32,\n          param3: u32,\n        }\n        @group(0) @binding(2) var<uniform> params: Params;\n\n        @compute @workgroup_size(${e.workgroupSize.join(", ")})\n        fn main(@builtin(global_invocation_id) global_id: vec3<u32>) {\n          let index = global_id.x;\n          let size = params.param0;\n          if (index >= size) { return; }\n          output[index] = floor(input[index]);\n        }\n      `],["ceil",e=>`\n        @group(0) @binding(0) var<storage, read> input: array<${e.dataType}>;\n        @group(0) @binding(1) var<storage, read_write> output: array<${e.dataType}>;\n        struct Params {\n          param0: u32,\n          param1: u32,\n          param2: u32,\n          param3: u32,\n        }\n        @group(0) @binding(2) var<uniform> params: Params;\n\n        @compute @workgroup_size(${e.workgroupSize.join(", ")})\n        fn main(@builtin(global_invocation_id) global_id: vec3<u32>) {\n          let index = global_id.x;\n          let size = params.param0;\n          if (index >= size) { return; }\n          output[index] = ceil(input[index]);\n        }\n      `],["round",e=>`\n        @group(0) @binding(0) var<storage, read> input: array<${e.dataType}>;\n        @group(0) @binding(1) var<storage, read_write> output: array<${e.dataType}>;\n        struct Params {\n          param0: u32,\n          param1: u32,\n          param2: u32,\n          param3: u32,\n        }\n        @group(0) @binding(2) var<uniform> params: Params;\n\n        @compute @workgroup_size(${e.workgroupSize.join(", ")})\n        fn main(@builtin(global_invocation_id) global_id: vec3<u32>) {\n          let index = global_id.x;\n          let size = params.param0;\n          if (index >= size) { return; }\n          output[index] = round(input[index]);\n        }\n      `],["trunc",e=>`\n        @group(0) @binding(0) var<storage, read> input: array<${e.dataType}>;\n        @group(0) @binding(1) var<storage, read_write> output: array<${e.dataType}>;\n        struct Params {\n          param0: u32,\n          param1: u32,\n          param2: u32,\n          param3: u32,\n        }\n        @group(0) @binding(2) var<uniform> params: Params;\n\n        @compute @workgroup_size(${e.workgroupSize.join(", ")})\n        fn main(@builtin(global_invocation_id) global_id: vec3<u32>) {\n          let index = global_id.x;\n          let size = params.param0;\n          if (index >= size) { return; }\n          output[index] = trunc(input[index]);\n        }\n      `],["clamp",e=>`\n        @group(0) @binding(0) var<storage, read> input: array<${e.dataType}>;\n        @group(0) @binding(1) var<storage, read_write> output: array<${e.dataType}>;\n        struct Params {\n          param0: u32,\n          param1: u32,\n          param2: u32,\n          param3: u32,\n        }\n        @group(0) @binding(2) var<uniform> params: Params;\n\n        @compute @workgroup_size(${e.workgroupSize.join(", ")})\n        fn main(@builtin(global_invocation_id) global_id: vec3<u32>) {\n          let index = global_id.x;\n          let size = params.param0;\n          let min_val = bitcast<f32>(params.param1);\n          let max_val = bitcast<f32>(params.param2);\n          if (index >= size) { return; }\n          output[index] = clamp(input[index], min_val, max_val);\n        }\n      `],["eq",e=>`\n        @group(0) @binding(0) var<storage, read> input1: array<${e.dataType}>;\n        @group(0) @binding(1) var<storage, read> input2: array<${e.dataType}>;\n        @group(0) @binding(2) var<storage, read_write> output: array<u32>;\n        struct Params {\n          param0: u32,\n          param1: u32,\n          param2: u32,\n          param3: u32,\n        }\n        @group(0) @binding(3) var<uniform> params: Params;\n\n        @compute @workgroup_size(${e.workgroupSize.join(", ")})\n        fn main(@builtin(global_invocation_id) global_id: vec3<u32>) {\n          let index = global_id.x;\n          let size = params.param0;\n          if (index >= size) { return; }\n          output[index] = select(0u, 1u, input1[index] == input2[index]);\n        }\n      `],["ne",e=>`\n        @group(0) @binding(0) var<storage, read> input1: array<${e.dataType}>;\n        @group(0) @binding(1) var<storage, read> input2: array<${e.dataType}>;\n        @group(0) @binding(2) var<storage, read_write> output: array<u32>;\n        struct Params {\n          param0: u32,\n          param1: u32,\n          param2: u32,\n          param3: u32,\n        }\n        @group(0) @binding(3) var<uniform> params: Params;\n\n        @compute @workgroup_size(${e.workgroupSize.join(", ")})\n        fn main(@builtin(global_invocation_id) global_id: vec3<u32>) {\n          let index = global_id.x;\n          let size = params.param0;\n          if (index >= size) { return; }\n          output[index] = select(0u, 1u, input1[index] != input2[index]);\n        }\n      `],["lt",e=>`\n        @group(0) @binding(0) var<storage, read> input1: array<${e.dataType}>;\n        @group(0) @binding(1) var<storage, read> input2: array<${e.dataType}>;\n        @group(0) @binding(2) var<storage, read_write> output: array<u32>;\n        struct Params {\n          param0: u32,\n          param1: u32,\n          param2: u32,\n          param3: u32,\n        }\n        @group(0) @binding(3) var<uniform> params: Params;\n\n        @compute @workgroup_size(${e.workgroupSize.join(", ")})\n        fn main(@builtin(global_invocation_id) global_id: vec3<u32>) {\n          let index = global_id.x;\n          let size = params.param0;\n          if (index >= size) { return; }\n          output[index] = select(0u, 1u, input1[index] < input2[index]);\n        }\n      `],["le",e=>`\n        @group(0) @binding(0) var<storage, read> input1: array<${e.dataType}>;\n        @group(0) @binding(1) var<storage, read> input2: array<${e.dataType}>;\n        @group(0) @binding(2) var<storage, read_write> output: array<u32>;\n        struct Params {\n          param0: u32,\n          param1: u32,\n          param2: u32,\n          param3: u32,\n        }\n        @group(0) @binding(3) var<uniform> params: Params;\n\n        @compute @workgroup_size(${e.workgroupSize.join(", ")})\n        fn main(@builtin(global_invocation_id) global_id: vec3<u32>) {\n          let index = global_id.x;\n          let size = params.param0;\n          if (index >= size) { return; }\n          output[index] = select(0u, 1u, input1[index] <= input2[index]);\n        }\n      `],["gt",e=>`\n        @group(0) @binding(0) var<storage, read> input1: array<${e.dataType}>;\n        @group(0) @binding(1) var<storage, read> input2: array<${e.dataType}>;\n        @group(0) @binding(2) var<storage, read_write> output: array<u32>;\n        struct Params {\n          param0: u32,\n          param1: u32,\n          param2: u32,\n          param3: u32,\n        }\n        @group(0) @binding(3) var<uniform> params: Params;\n\n        @compute @workgroup_size(${e.workgroupSize.join(", ")})\n        fn main(@builtin(global_invocation_id) global_id: vec3<u32>) {\n          let index = global_id.x;\n          let size = params.param0;\n          if (index >= size) { return; }\n          output[index] = select(0u, 1u, input1[index] > input2[index]);\n        }\n      `],["ge",e=>`\n        @group(0) @binding(0) var<storage, read> input1: array<${e.dataType}>;\n        @group(0) @binding(1) var<storage, read> input2: array<${e.dataType}>;\n        @group(0) @binding(2) var<storage, read_write> output: array<u32>;\n        struct Params {\n          param0: u32,\n          param1: u32,\n          param2: u32,\n          param3: u32,\n        }\n        @group(0) @binding(3) var<uniform> params: Params;\n\n        @compute @workgroup_size(${e.workgroupSize.join(", ")})\n        fn main(@builtin(global_invocation_id) global_id: vec3<u32>) {\n          let index = global_id.x;\n          let size = params.param0;\n          if (index >= size) { return; }\n          output[index] = select(0u, 1u, input1[index] >= input2[index]);\n        }\n      `],["argmin",e=>`\n        @group(0) @binding(0) var<storage, read> input: array<${e.dataType}>;\n        @group(0) @binding(1) var<storage, read_write> output: array<u32>;\n        struct Params {\n          param0: u32,\n          param1: u32,\n          param2: u32,\n          param3: u32,\n        }\n        @group(0) @binding(2) var<uniform> params: Params;\n\n        var<workgroup> shared_vals: array<f32, ${e.workgroupSize[0]}>;\n        var<workgroup> shared_indices: array<u32, ${e.workgroupSize[0]}>;\n\n        @compute @workgroup_size(${e.workgroupSize[0]})\n        fn main(@builtin(global_invocation_id) global_id: vec3<u32>,\n                @builtin(local_invocation_id) local_id: vec3<u32>,\n                @builtin(workgroup_id) workgroup_id: vec3<u32>) {\n          let size = params.param0;\n          let local_idx = local_id.x;\n          let global_idx = global_id.x;\n          \n          // Initialize with first valid element or max value\n          var min_val = 1e38; // FLT_MAX\n          var min_idx = 0u;\n          \n          // Find minimum in this thread's portion\n          for (var i = global_idx; i < size; i = i + ${e.workgroupSize[0]}u) {\n            if (input[i] < min_val) {\n              min_val = input[i];\n              min_idx = i;\n            }\n          }\n          \n          shared_vals[local_idx] = min_val;\n          shared_indices[local_idx] = min_idx;\n          workgroupBarrier();\n          \n          // Parallel reduction to find global minimum\n          for (var stride = ${e.workgroupSize[0]/2}u; stride > 0u; stride = stride >> 1u) {\n            if (local_idx < stride) {\n              if (shared_vals[local_idx + stride] < shared_vals[local_idx]) {\n                shared_vals[local_idx] = shared_vals[local_idx + stride];\n                shared_indices[local_idx] = shared_indices[local_idx + stride];\n              }\n            }\n            workgroupBarrier();\n          }\n          \n          if (local_idx == 0u) {\n            output[workgroup_id.x] = shared_indices[0];\n          }\n        }\n      `],["argmax",e=>`\n        @group(0) @binding(0) var<storage, read> input: array<${e.dataType}>;\n        @group(0) @binding(1) var<storage, read_write> output: array<u32>;\n        struct Params {\n          param0: u32,\n          param1: u32,\n          param2: u32,\n          param3: u32,\n        }\n        @group(0) @binding(2) var<uniform> params: Params;\n\n        var<workgroup> shared_vals: array<f32, ${e.workgroupSize[0]}>;\n        var<workgroup> shared_indices: array<u32, ${e.workgroupSize[0]}>;\n\n        @compute @workgroup_size(${e.workgroupSize[0]})\n        fn main(@builtin(global_invocation_id) global_id: vec3<u32>,\n                @builtin(local_invocation_id) local_id: vec3<u32>,\n                @builtin(workgroup_id) workgroup_id: vec3<u32>) {\n          let size = params.param0;\n          let local_idx = local_id.x;\n          let global_idx = global_id.x;\n          \n          // Initialize with first valid element or min value\n          var max_val = -1e38; // -FLT_MAX\n          var max_idx = 0u;\n          \n          // Find maximum in this thread's portion\n          for (var i = global_idx; i < size; i = i + ${e.workgroupSize[0]}u) {\n            if (input[i] > max_val) {\n              max_val = input[i];\n              max_idx = i;\n            }\n          }\n          \n          shared_vals[local_idx] = max_val;\n          shared_indices[local_idx] = max_idx;\n          workgroupBarrier();\n          \n          // Parallel reduction to find global maximum\n          for (var stride = ${e.workgroupSize[0]/2}u; stride > 0u; stride = stride >> 1u) {\n            if (local_idx < stride) {\n              if (shared_vals[local_idx + stride] > shared_vals[local_idx]) {\n                shared_vals[local_idx] = shared_vals[local_idx + stride];\n                shared_indices[local_idx] = shared_indices[local_idx + stride];\n              }\n            }\n            workgroupBarrier();\n          }\n          \n          if (local_idx == 0u) {\n            output[workgroup_id.x] = shared_indices[0];\n          }\n        }\n      `]])}static getOptimalWorkgroupSize(e,n,t){const a=t?.maxComputeWorkgroupSizeX||256,r=t?.maxComputeWorkgroupSizeY||256,s=t?.maxComputeWorkgroupSizeZ||64,i=t?.maxComputeInvocationsPerWorkgroup||256,o=Array.isArray(n)?n.reduce((e,n)=>e*n,1):n||1;switch(e){case"matmul":const e=Math.min(16,Math.sqrt(i));return[Math.min(e,a),Math.min(e,r),1];case"bmm":const n=Math.min(8,Math.sqrt(i/2));return[Math.min(n,a),Math.min(n,r),Math.min(4,s)];case"conv2d":return[Math.min(8,a),Math.min(8,r),Math.min(4,s)];case"softmax":return[Math.min(256,a),1,1];case"sum":case"mean":case"argmin":case"argmax":const t=Math.min(256,a);return[Math.pow(2,Math.floor(Math.log2(t))),1,1];case"transpose":const d=Math.min(16,Math.sqrt(i));return[d,d,1];case"maxpool2d":case"avgpool2d":return[Math.min(16,a),Math.min(16,r),1];case"add":case"sub":case"mul":case"div":case"relu":case"sigmoid":case"tanh":case"exp":case"log":case"sqrt":case"abs":return o<1024?[Math.min(32,a),1,1]:o<65536?[Math.min(64,a),1,1]:[Math.min(128,a),1,1];default:return[Math.min(64,a),1,1]}}static getBufferLayout(e,n=2,t=1){return{add:{inputs:2,outputs:1,uniforms:1},sub:{inputs:2,outputs:1,uniforms:1},mul:{inputs:2,outputs:1,uniforms:1},div:{inputs:2,outputs:1,uniforms:1},pow:{inputs:2,outputs:1,uniforms:1},matmul:{inputs:2,outputs:1,uniforms:1},bmm:{inputs:2,outputs:1,uniforms:1},relu:{inputs:1,outputs:1,uniforms:1},sigmoid:{inputs:1,outputs:1,uniforms:1},tanh:{inputs:1,outputs:1,uniforms:1},gelu:{inputs:1,outputs:1,uniforms:1},leaky_relu:{inputs:1,outputs:1,uniforms:1},softmax:{inputs:1,outputs:1,uniforms:1},exp:{inputs:1,outputs:1,uniforms:1},log:{inputs:1,outputs:1,uniforms:1},sqrt:{inputs:1,outputs:1,uniforms:1},abs:{inputs:1,outputs:1,uniforms:1},sin:{inputs:1,outputs:1,uniforms:1},cos:{inputs:1,outputs:1,uniforms:1},tan:{inputs:1,outputs:1,uniforms:1},sinh:{inputs:1,outputs:1,uniforms:1},cosh:{inputs:1,outputs:1,uniforms:1},floor:{inputs:1,outputs:1,uniforms:1},ceil:{inputs:1,outputs:1,uniforms:1},round:{inputs:1,outputs:1,uniforms:1},trunc:{inputs:1,outputs:1,uniforms:1},clamp:{inputs:1,outputs:1,uniforms:1},conv2d:{inputs:3,outputs:1,uniforms:1},batch_norm:{inputs:5,outputs:1,uniforms:1},cross_entropy:{inputs:2,outputs:1,uniforms:1},eq:{inputs:2,outputs:1,uniforms:1},ne:{inputs:2,outputs:1,uniforms:1},lt:{inputs:2,outputs:1,uniforms:1},le:{inputs:2,outputs:1,uniforms:1},gt:{inputs:2,outputs:1,uniforms:1},ge:{inputs:2,outputs:1,uniforms:1},sum:{inputs:1,outputs:1,uniforms:1},mean:{inputs:1,outputs:1,uniforms:1},argmin:{inputs:1,outputs:1,uniforms:1},argmax:{inputs:1,outputs:1,uniforms:1}}[e]||{inputs:n,outputs:t,uniforms:1}}static generateParams(n,t,a={}){const r=new Uint32Array(4);switch(("undefined"!=typeof window&&window.greedDebugWebGPU||void 0!==e.g&&e.g.greedDebugWebGPU)&&Array.isArray(t)&&t.forEach((e,n)=>{}),n){case"matmul":r[0]=t[0].shape?.[0]||Math.sqrt(t[0].length),r[1]=t[1].shape?.[1]||Math.sqrt(t[1].length),r[2]=t[0].shape?.[1]||Math.sqrt(t[0].length),r[3]=0;break;case"bmm":r[0]=t[0].shape?.[0]||1,r[1]=t[0].shape?.[1]||Math.sqrt(t[0].length),r[2]=t[1].shape?.[2]||Math.sqrt(t[1].length),r[3]=t[0].shape?.[2]||Math.sqrt(t[0].length);break;case"conv2d":const e=t[0].shape||[1,1,28,28];t[1].shape,r[0]=e[0],r[1]=e[1],r[2]=e[2],r[3]=e[3];break;case"softmax":const n=t[0].shape||[1,t[0].length];r[0]=n.length>1?n[0]:1,r[1]=n.length>1?n[1]:n[0],r[2]=0,r[3]=0;break;case"leaky_relu":r[0]=t[0].length,r[1]=new Uint32Array(new Float32Array([a.negativeSlope||.01]).buffer)[0],r[2]=0,r[3]=0;break;case"clamp":r[0]=t[0].length,r[1]=new Uint32Array(new Float32Array([a.minVal||-1e38]).buffer)[0],r[2]=new Uint32Array(new Float32Array([a.maxVal||1e38]).buffer)[0],r[3]=0;break;case"argmin":case"argmax":r[0]=t[0].length,r[1]=a.dim||0,r[2]=0,r[3]=0;break;default:r[0]=Array.isArray(t)?t[0].length:t.length,r[1]=0,r[2]=0,r[3]=0}return r}}const u=class extends t{constructor(e,n={}){super(),this.device=e,this.config={maxCacheSize:n.maxCacheSize||100,enableWarmup:!1!==n.enableWarmup,enableMetrics:!1!==n.enableMetrics,shaderOptimization:n.shaderOptimization||"balanced",...n},this.pipelines=new Map,this.shaderModules=new Map,this.bindGroupLayouts=new Map,this.accessOrder=new Map,this.compilationQueue=new Map,this.stats={hits:0,misses:0,compilations:0,evictions:0,averageCompileTime:0,totalCompileTime:0},this.shaderTemplates=l.getShaderTemplates()}async get(e,n={}){const t=this._generateKey(e,n);if(this.pipelines.has(t))return this._updateAccess(t),this.stats.hits++,this.emit("cache:hit",{operation:e,key:t}),this.pipelines.get(t);if(this.compilationQueue.has(t))return this.emit("cache:wait",{operation:e,key:t}),await this.compilationQueue.get(t);this.stats.misses++,this.emit("cache:miss",{operation:e,key:t});const a=this._compilePipeline(e,n,t);this.compilationQueue.set(t,a);try{const e=await a;return this.compilationQueue.delete(t),e}catch(e){throw this.compilationQueue.delete(t),e}}async warmup(e=null){if(!this.config.enableWarmup)return;const n=e||["add","multiply","matmul","relu","sigmoid","softmax","conv2d","maxpool","transpose"];this.emit("warmup:start",{operations:n});const t=performance.now(),a=n.map(async e=>{try{await this.get(e,{warmup:!0}),this.emit("warmup:operation",{operation:e})}catch(n){this.emit("warmup:error",{operation:e,error:n})}});await Promise.allSettled(a);const r=performance.now()-t;this.emit("warmup:complete",{operations:n,duration:r})}getBindGroupLayout(e,n={}){const t=this._generateLayoutKey(e,n);if(this.bindGroupLayouts.has(t))return this.bindGroupLayouts.get(t);const a=this._createBindGroupLayout(e,n);return this.bindGroupLayouts.set(t,a),a}getOptimalWorkgroupSize(e,n,t){return l.getOptimalWorkgroupSize(e,n,t)}generateOperationParams(e,n,t={}){return l.generateParams(e,n,t)}async createShaderModule(e,n={}){const t=this._hashString(e);if(this.shaderModules.has(t))return this.shaderModules.get(t);try{const a=this.device.createShaderModule({code:e,...n});return this.shaderModules.set(t,a),this.emit("shader:compiled",{hash:t,size:e.length}),a}catch(n){throw this.emit("shader:error",{hash:t,error:n,source:e.substring(0,100)}),n}}generateShader(e,n={}){const t=this.shaderTemplates.get(e);if(!t)throw new Error(`No shader template found for operation: ${e}`);return t({workgroupSize:n.workgroupSize||[8,8,1],dataType:n.dataType||"f32",optimization:this.config.shaderOptimization,...n})}getStats(){const e=this.stats.hits+this.stats.misses>0?this.stats.hits/(this.stats.hits+this.stats.misses):0;return{...this.stats,hitRate:e,cacheSize:this.pipelines.size,shaderCacheSize:this.shaderModules.size,layoutCacheSize:this.bindGroupLayouts.size,averageCompileTimeMs:Math.round(100*this.stats.averageCompileTime)/100}}clear(){this.pipelines.clear(),this.shaderModules.clear(),this.bindGroupLayouts.clear(),this.accessOrder.clear(),this.compilationQueue.clear(),this.stats.hits=0,this.stats.misses=0,this.emit("cache:cleared")}cleanup(){this.clear(),this.shaderTemplates.clear(),this.emit("cleanup:complete")}async _compilePipeline(e,n,t){const a=performance.now();try{const r=this.generateShader(e,n),s=await this.createShaderModule(r),i=this.getBindGroupLayout(e,n),o=this.device.createPipelineLayout({bindGroupLayouts:[i]}),d=await this.device.createComputePipelineAsync({layout:o,compute:{module:s,entryPoint:"main"}});this.pipelines.set(t,d),this._updateAccess(t),this._enforceMaxCacheSize();const l=performance.now()-a;return this.stats.compilations++,this.stats.totalCompileTime+=l,this.stats.averageCompileTime=this.stats.totalCompileTime/this.stats.compilations,this.emit("pipeline:compiled",{operation:e,key:t,compileTime:l,cacheSize:this.pipelines.size}),d}catch(n){throw this.emit("pipeline:error",{operation:e,key:t,error:n}),n}}_generateKey(e,n){return[e,n.workgroupSize?.join(",")||"8,8,1",n.dataType||"f32",n.inputCount||2,n.outputCount||1,JSON.stringify(n.constants||{})].join("|")}_generateLayoutKey(e,n){return`${e}|${n.inputCount||2}|${n.outputCount||1}`}_createBindGroupLayout(e,n){const t=l.getBufferLayout(e,n.inputCount,n.outputCount),a=[];for(let e=0;e<t.inputs;e++)a.push({binding:e,visibility:GPUShaderStage.COMPUTE,buffer:{type:"read-only-storage"}});for(let e=0;e<t.outputs;e++)a.push({binding:t.inputs+e,visibility:GPUShaderStage.COMPUTE,buffer:{type:"storage"}});return t.uniforms>0&&a.push({binding:t.inputs+t.outputs,visibility:GPUShaderStage.COMPUTE,buffer:{type:"uniform"}}),this.device.createBindGroupLayout({entries:a})}_updateAccess(e){this.accessOrder.set(e,performance.now())}_enforceMaxCacheSize(){if(this.pipelines.size<=this.config.maxCacheSize)return;let e=null,n=1/0;for(const[t,a]of this.accessOrder.entries())a<n&&(n=a,e=t);e&&(this.pipelines.delete(e),this.accessOrder.delete(e),this.stats.evictions++,this.emit("cache:eviction",{key:e,cacheSize:this.pipelines.size}))}_hashString(e){let n=0;for(let t=0;t<e.length;t++)n=(n<<5)-n+e.charCodeAt(t),n&=n;return n.toString(36)}};class p{constructor(e){this.max=e,this.current=0,this.queue=[]}async acquire(){return new Promise(e=>{this.current<this.max?(this.current++,e()):this.queue.push(e)})}release(){if(this.current--,this.queue.length>0){const e=this.queue.shift();this.current++,e()}}}const _=class extends t{constructor(e={}){super(),this.config={powerPreference:e.powerPreference||"high-performance",enableProfiling:!1!==e.enableProfiling,maxBufferSize:e.maxBufferSize||268435456,workgroupSize:e.workgroupSize||[64,1,1],enableValidation:!1!==e.enableValidation,...e},this.adapter=null,this.device=null,this.isInitialized=!1,this.bufferManager=null,this.pipelineCache=null,this.supportedFeatures=new Set,this.limits=null,this.stats={computeOperations:0,totalExecutionTime:0,averageExecutionTime:0,memoryUsage:0,lastOperationTime:0}}async initialize(){if(this.isInitialized)return!0;try{if(this.emit("init:start"),!navigator.gpu)throw new Error("WebGPU not supported in this browser");if(this.adapter=await navigator.gpu.requestAdapter({powerPreference:this.config.powerPreference}),!this.adapter)throw new Error("Failed to get WebGPU adapter");this.supportedFeatures=this.adapter.features,this.limits=this.adapter.limits,this.emit("init:adapter",{features:Array.from(this.supportedFeatures),limits:this.limits});const e={requiredFeatures:[],requiredLimits:{}};return this.supportedFeatures.has("timestamp-query")&&e.requiredFeatures.push("timestamp-query"),this.device=await this.adapter.requestDevice(e),this.device.addEventListener("uncapturederror",e=>{const n=e.error;this.emit("device:error",{error:n,type:"uncaptured",timestamp:Date.now()}),r.error("WebGPU uncaptured error:",{type:n.constructor.name,message:n.message,stack:n.stack}),this._handleDeviceError(n)}),this.bufferManager=new d(this.device,{maxBufferSize:this.config.maxBufferSize,enablePooling:!0,maxPoolSize:100}),this.pipelineCache=new u(this.device,{maxCacheSize:50,enableWarmup:!0,shaderOptimization:"balanced"}),this._setupEventForwarding(),await this.pipelineCache.warmup(),this.isInitialized=!0,this.emit("init:complete",{device:this.device,features:Array.from(this.supportedFeatures)}),!0}catch(e){return this.emit("init:error",{error:e,timestamp:Date.now()}),r.error("WebGPU initialization failed:",{type:e.constructor.name,message:e.message,stack:e.stack,config:this.config}),this.isInitialized=!1,this.initFailureReason=e.message,!1}}async execute(e,n,t={}){if(!this.isInitialized)throw new Error("WebGPU compute engine not initialized");const a=performance.now();this.emit("compute:start",{operation:e,options:t});try{this._validateOperation(e,n,t);const r=Array.isArray(n)?n:[n],s=this.pipelineCache.getOptimalWorkgroupSize(e,r[0].shape||[r[0].length],this.limits);let i;try{i=await this.pipelineCache.get(e,{workgroupSize:t.workgroupSize||s,dataType:t.dataType||"f32",inputCount:r.length,outputCount:t.outputCount||1,...t})}catch(e){throw e}const o=await this._prepareBuffers(n,e,t),d=this._createBindGroup(i,o,t),l=await this._executeComputePass(i,d,o,{...t,operation:e}),u=performance.now()-a;return this._updateStats(e,u,o),this._cleanupBuffersAsync(o,t),this.emit("compute:complete",{operation:e,executionTime:u,resultSize:l.length}),l}catch(s){const i=performance.now()-a,o={operation:e,error:{type:s.constructor.name,message:s.message,stack:s.stack},executionTime:i,tensors:Array.isArray(n)?n.length:1,options:t,deviceStable:this.deviceStable??!0,timestamp:Date.now()};throw this.emit("compute:error",o),r.error("WebGPU compute operation failed:",o),(s.message.includes("out of memory")||"GPUOutOfMemoryError"===s.constructor.name)&&(r.warn("GPU memory exhausted, attempting emergency cleanup"),await this.bufferManager.emergencyCleanup(),this.emit("recovery:memory",{operation:e,timestamp:Date.now()})),s}}async executeBatch(e,n={}){const{parallel:t=!1,maxConcurrency:a=4}=n;if(t){const n=new p(a),t=e.map(async e=>{await n.acquire();try{return await this.execute(e.operation,e.tensors,e.options)}finally{n.release()}});return Promise.all(t)}{const n=[];for(const t of e){const e=await this.execute(t.operation,t.tensors,t.options);n.push(e)}return n}}async uploadTensor(e,n={}){const{usage:t=GPUBufferUsage.STORAGE|GPUBufferUsage.COPY_DST,forceNew:a=!1}=n;if(!a){const n=this.bufferManager.findReusableBuffer(e.byteLength||4*e.length,t);if(n)return this.device.queue.writeBuffer(n,0,e),n}return await this.bufferManager.createMappedBuffer(e,t)}async downloadTensor(e,n,t={}){const{format:a=Float32Array}=t,r=this.bufferManager.allocate(4*n,GPUBufferUsage.COPY_DST|GPUBufferUsage.MAP_READ);try{const t=this.device.createCommandEncoder();t.copyBufferToBuffer(e,0,r,0,4*n),this.device.queue.submit([t.finish()]),await r.mapAsync(GPUMapMode.READ);const s=new a(r.getMappedRange().slice());return r.unmap(),s}finally{this.bufferManager.release(r,{forceDestroy:!0})}}getStats(){return{...this.stats,bufferStats:this.bufferManager?.getStats()||{},pipelineStats:this.pipelineCache?.getStats()||{},deviceLimits:this.limits,supportedFeatures:Array.from(this.supportedFeatures||[])}}async cleanup(){this.emit("cleanup:start");try{this.bufferManager&&(await this.bufferManager.cleanup(),this.bufferManager=null),this.pipelineCache&&(this.pipelineCache.cleanup(),this.pipelineCache=null),this.device&&(this.device.destroy(),this.device=null),this.adapter=null,this.isInitialized=!1,this.emit("cleanup:complete")}catch(e){throw this.emit("cleanup:error",{error:e}),e}}_validateOperation(e,n,t){if(!e||"string"!=typeof e)throw new Error("Operation must be a non-empty string");if(!n)throw new Error("Tensors parameter is required");const a=Array.isArray(n)?n:[n];for(const e of a)if(!e||!ArrayBuffer.isView(e)&&!(e instanceof ArrayBuffer)){const n={tensorType:typeof e,constructor:e?.constructor?.name,isArrayBufferView:ArrayBuffer.isView(e),isArrayBuffer:e instanceof ArrayBuffer,hasData:e&&void 0!==e.data,dataType:e?.data?typeof e.data:"undefined"};throw new Error(`Invalid tensor data type. Expected typed array or ArrayBuffer, got: ${JSON.stringify(n)}`)}}_isDebugEnabled(){try{return"undefined"!=typeof window&&window.greedDebugWebGPU||void 0!==e.g&&e.g.greedDebugWebGPU}catch{return!1}}async _prepareBuffers(e,n,t){const a=Array.isArray(e)?e:[e],r={inputs:[],output:null,params:null};for(let e=0;e<a.length;e++){const n=await this.uploadTensor(a[e]);r.inputs.push(n)}const s=this._calculateOutputSize(n,a,t);r.output=this.bufferManager.allocate(4*s,GPUBufferUsage.STORAGE|GPUBufferUsage.COPY_SRC);const i=this.pipelineCache.generateOperationParams(n,a,t);return r.params=await this.uploadTensor(i,{usage:GPUBufferUsage.UNIFORM|GPUBufferUsage.COPY_DST}),r}_createBindGroup(e,n,t){const a=[];for(let e=0;e<n.inputs.length;e++)a.push({binding:e,resource:{buffer:n.inputs[e]}});return a.push({binding:n.inputs.length,resource:{buffer:n.output}}),a.push({binding:n.inputs.length+1,resource:{buffer:n.params}}),this.device.createBindGroup({layout:e.getBindGroupLayout(0),entries:a})}async _executeComputePass(e,n,t,a){const r=this.device.createCommandEncoder(),s=r.beginComputePass();s.setPipeline(e),s.setBindGroup(0,n);const i=a.workgroupSize||this.config.workgroupSize,o=t.output.size/4;let d,l=1,u=1;if("matmul"===a.operation||"bmm"===a.operation){const e=this._getMatrixDimensions(a);d=Math.ceil(e.M/i[0]),l=Math.ceil(e.N/i[1]),"bmm"===a.operation&&(u=e.B)}else d=Math.ceil(o/i[0]);s.dispatchWorkgroups(d,l,u),s.end();const p=r.finish();return this.device.queue.submit([p]),await this._waitForGPUCompletion(5e3),this._downloadTensorOptimized(t.output,o,a)}_calculateOutputSize(e,n,t){if(t.outputSize)return t.outputSize;const a=n[0],r=e=>ArrayBuffer.isView(e)?e.length:e.byteLength/4;switch(e){case"matmul":return(n[0].shape?.[0]||Math.sqrt(r(n[0])))*(n[1].shape?.[1]||Math.sqrt(r(n[1])));case"bmm":const e=n[0].shape?.[0]||1;return e*(n[0].shape?.[1]||Math.sqrt(r(n[0])/e))*(n[1].shape?.[2]||Math.sqrt(r(n[1])/e));case"conv2d":const s=n[0].shape?.[2]||28,i=n[0].shape?.[3]||28,o=n[1].shape?.[0]||32;return(n[0].shape?.[0]||1)*o*s*i;case"transpose":case"softmax":default:return r(a);case"sum":case"mean":return t.keepDim?r(a):1;case"maxpool2d":case"avgpool2d":const d=t.kernelSize||2,l=t.stride||d,u=n[0].shape?.[2]||28,p=n[0].shape?.[3]||28,_=Math.floor((u-d)/l)+1,f=Math.floor((p-d)/l)+1,c=n[0].shape?.[1]||1;return(n[0].shape?.[0]||1)*c*_*f}}_updateStats(e,n,t){this.stats.computeOperations++,this.stats.totalExecutionTime+=n,this.stats.averageExecutionTime=this.stats.totalExecutionTime/this.stats.computeOperations,this.stats.lastOperationTime=n;const a=t.inputs.reduce((e,n)=>e+n.size,0)+t.output.size;this.stats.memoryUsage=Math.max(this.stats.memoryUsage,a)}_getMatrixDimensions(e){return{M:e.M||Math.sqrt(e.inputSize||256),N:e.N||Math.sqrt(e.inputSize||256),K:e.K||Math.sqrt(e.inputSize||256),B:e.B||1}}async _downloadTensorOptimized(e,n,t={}){const{format:a=Float32Array,usePooledBuffer:r=!0}=t;let s;r&&(s=this.bufferManager.findReusableBuffer(4*n,GPUBufferUsage.COPY_DST|GPUBufferUsage.MAP_READ)),s||(s=this.bufferManager.allocate(4*n,GPUBufferUsage.COPY_DST|GPUBufferUsage.MAP_READ));try{const t=this.device.createCommandEncoder();t.copyBufferToBuffer(e,0,s,0,4*n),this.device.queue.submit([t.finish()]),await this._waitForGPUCompletion(3e3);const r=s.mapAsync(GPUMapMode.READ),i=new Promise((e,n)=>{setTimeout(()=>n(new Error("Buffer mapping timeout")),2e3)});await Promise.race([r,i]);const o=new a(s.getMappedRange().slice());return s.unmap(),o}finally{r?this.bufferManager.returnToPool(s):this.bufferManager.release(s,{forceDestroy:!0})}}async _waitForGPUCompletion(e=5e3){return new Promise(e=>{setTimeout(()=>{e()},100)})}_cleanupBuffersAsync(e,n){setTimeout(()=>{try{for(const t of e.inputs)!1!==n.reuseInputBuffers?this.bufferManager.returnToPool(t):this.bufferManager.release(t,{forceDestroy:!1});e.params&&!1!==n.reuseParamBuffers?this.bufferManager.returnToPool(e.params):e.params&&this.bufferManager.release(e.params,{forceDestroy:!1})}catch(n){this.emit("cleanup:error",{error:n,buffers:e})}},0)}async executeBatchOptimized(e,n={}){const{parallel:t=!1,maxConcurrency:a=4,reuseBuffers:r=!0,shareComputePass:s=!1}=n,i=this._groupOperationsByType(e),o=[];for(const[e,d]of i.entries())if(s&&this._canShareComputePass(e)){const e=await this._executeBatchedComputePass(d,n);o.push(...e)}else if(t){const e=new p(a),n=d.map(async n=>{await e.acquire();try{return await this.execute(n.operation,n.tensors,{...n.options,reuseInputBuffers:r,reuseParamBuffers:r})}finally{e.release()}}),t=await Promise.all(n);o.push(...t)}else for(const e of d){const n=await this.execute(e.operation,e.tensors,{...e.options,reuseInputBuffers:r,reuseParamBuffers:r});o.push(n)}return o}_groupOperationsByType(e){const n=new Map;for(const t of e){const e=t.operation;n.has(e)||n.set(e,[]),n.get(e).push(t)}return n}_canShareComputePass(e){return["add","sub","mul","div","relu","sigmoid","tanh"].includes(e)}async _executeBatchedComputePass(e,n){const t=[];for(const a of e){const e=await this.execute(a.operation,a.tensors,{...a.options,...n});t.push(e)}return t}_setupEventForwarding(){this.bufferManager.on("buffer:created",e=>this.emit("buffer:created",e)),this.bufferManager.on("buffer:destroyed",e=>this.emit("buffer:destroyed",e)),this.bufferManager.on("gc:complete",e=>this.emit("buffer:gc",e)),this.pipelineCache.on("cache:miss",e=>this.emit("pipeline:miss",e)),this.pipelineCache.on("pipeline:compiled",e=>this.emit("pipeline:compiled",e)),this.pipelineCache.on("warmup:complete",e=>this.emit("pipeline:warmup",e))}_handleDeviceError(e){const n=e.constructor.name;switch(n){case"GPUOutOfMemoryError":r.warn("GPU out of memory, attempting buffer cleanup"),this.bufferManager.emergencyCleanup(),this.emit("recovery:attempt",{type:"memory-cleanup",timestamp:Date.now()});break;case"GPUInternalError":r.warn("GPU internal error, marking device as potentially unstable"),this.deviceStable=!1,this.emit("device:unstable",{reason:"internal-error",timestamp:Date.now()});break;case"GPUValidationError":r.warn("GPU validation error, this may indicate shader or pipeline issues"),this.emit("validation:error",{error:e,timestamp:Date.now()});break;default:r.warn("Unknown GPU error type:",n),this.emit("error:unknown",{error:e,timestamp:Date.now()})}}getErrorDiagnostics(){return{isInitialized:this.isInitialized,deviceStable:this.deviceStable??!0,initFailureReason:this.initFailureReason||null,bufferStats:this.bufferManager?.getStats()||null,pipelineStats:this.pipelineCache?.getStats()||null,supportedFeatures:Array.from(this.supportedFeatures||[]),timestamp:Date.now()}}};class f{constructor(e){this.max=e,this.current=0,this.queue=[]}async acquire(){return new Promise(e=>{this.current<this.max?(this.current++,e()):this.queue.push(e)})}release(){if(this.current--,this.queue.length>0){const e=this.queue.shift();this.current++,e()}}}const c=class extends t{constructor(e={}){super(),this.config={enableOptimizations:!1!==e.enableOptimizations,maxConcurrentOps:e.maxConcurrentOps||2,enableProfiling:!1!==e.enableProfiling,chunkSize:e.chunkSize||1e4,...e},this.isInitialized=!1,this.runtime=null,this.numpy=null,this.stats={operations:0,totalExecutionTime:0,averageExecutionTime:0,lastOperationTime:0,supportedOperations:new Set(["add","subtract","multiply","divide","matmul","transpose","reshape","sum","mean","max","min","relu","sigmoid","tanh","softmax","exp","log","sqrt","power","abs","sign","clip"])},this.operations=this._initializeOperations()}async initialize(e=null){if(this.isInitialized)return!0;try{return this.emit("init:start"),e&&(this.runtime=e,this.numpy=e.getGlobal("np")),this.runtime&&await this._installCPUOperations(),this.isInitialized=!0,this.emit("init:complete",{supportedOperations:Array.from(this.stats.supportedOperations)}),!0}catch(e){throw this.emit("init:error",{error:e}),e}}async execute(e,n,t={}){if(!this.isInitialized)throw new Error("CPU engine not initialized");const a=performance.now();this.emit("compute:start",{operation:e,options:t});try{if(!this.stats.supportedOperations.has(e))throw new Error(`Unsupported CPU operation: ${e}`);const r=this.operations[e];if(!r)throw new Error(`Operation implementation not found: ${e}`);const s=await r(n,t),i=performance.now()-a;return this._updateStats(i),this.emit("compute:complete",{operation:e,executionTime:i,resultSize:this._getResultSize(s)}),s}catch(n){const t=performance.now()-a;throw this.emit("compute:error",{operation:e,error:n,executionTime:t}),n}}async executeBatch(e,n={}){const{sequential:t=!1}=n;if(t){const n=[];for(const t of e){const e=await this.execute(t.operation,t.tensors,t.options);n.push(e)}return n}{const n=new f(this.config.maxConcurrentOps),t=e.map(async e=>{await n.acquire();try{return await this.execute(e.operation,e.tensors,e.options)}finally{n.release()}});return Promise.all(t)}}getStats(){return{...this.stats,isInitialized:this.isInitialized,config:this.config,type:"cpu"}}async cleanup(){try{this.emit("cleanup:start"),this.isInitialized=!1,this.runtime=null,this.numpy=null,this.emit("cleanup:complete")}catch(e){throw this.emit("cleanup:error",{error:e}),e}}async _installCPUOperations(){await this.runtime.runPython('\nimport numpy as np\nfrom typing import Union, List, Tuple, Optional\n\nclass CPUTensorOps:\n    """CPU-optimized tensor operations using NumPy"""\n    \n    @staticmethod\n    def add(a: np.ndarray, b: np.ndarray) -> np.ndarray:\n        return np.add(a, b)\n    \n    @staticmethod\n    def subtract(a: np.ndarray, b: np.ndarray) -> np.ndarray:\n        return np.subtract(a, b)\n    \n    @staticmethod\n    def multiply(a: np.ndarray, b: np.ndarray) -> np.ndarray:\n        return np.multiply(a, b)\n    \n    @staticmethod\n    def divide(a: np.ndarray, b: np.ndarray) -> np.ndarray:\n        return np.divide(a, b)\n    \n    @staticmethod\n    def matmul(a: np.ndarray, b: np.ndarray) -> np.ndarray:\n        return np.matmul(a, b)\n    \n    @staticmethod\n    def transpose(a: np.ndarray, axes: Optional[Tuple] = None) -> np.ndarray:\n        return np.transpose(a, axes)\n    \n    @staticmethod\n    def reshape(a: np.ndarray, shape: Tuple) -> np.ndarray:\n        return np.reshape(a, shape)\n    \n    @staticmethod\n    def sum(a: np.ndarray, axis: Optional[Union[int, Tuple]] = None, keepdims: bool = False) -> np.ndarray:\n        return np.sum(a, axis=axis, keepdims=keepdims)\n    \n    @staticmethod\n    def mean(a: np.ndarray, axis: Optional[Union[int, Tuple]] = None, keepdims: bool = False) -> np.ndarray:\n        return np.mean(a, axis=axis, keepdims=keepdims)\n    \n    @staticmethod\n    def max(a: np.ndarray, axis: Optional[Union[int, Tuple]] = None, keepdims: bool = False) -> np.ndarray:\n        return np.max(a, axis=axis, keepdims=keepdims)\n    \n    @staticmethod\n    def min(a: np.ndarray, axis: Optional[Union[int, Tuple]] = None, keepdims: bool = False) -> np.ndarray:\n        return np.min(a, axis=axis, keepdims=keepdims)\n    \n    @staticmethod\n    def relu(a: np.ndarray) -> np.ndarray:\n        return np.maximum(a, 0)\n    \n    @staticmethod\n    def sigmoid(a: np.ndarray) -> np.ndarray:\n        return 1 / (1 + np.exp(-np.clip(a, -250, 250)))  # Prevent overflow\n    \n    @staticmethod\n    def tanh(a: np.ndarray) -> np.ndarray:\n        return np.tanh(a)\n    \n    @staticmethod\n    def softmax(a: np.ndarray, axis: int = -1) -> np.ndarray:\n        # Stable softmax implementation\n        x_max = np.max(a, axis=axis, keepdims=True)\n        exp_x = np.exp(a - x_max)\n        return exp_x / np.sum(exp_x, axis=axis, keepdims=True)\n    \n    @staticmethod\n    def exp(a: np.ndarray) -> np.ndarray:\n        return np.exp(np.clip(a, -250, 250))  # Prevent overflow\n    \n    @staticmethod\n    def log(a: np.ndarray) -> np.ndarray:\n        return np.log(np.maximum(a, 1e-12))  # Prevent log(0)\n    \n    @staticmethod\n    def sqrt(a: np.ndarray) -> np.ndarray:\n        return np.sqrt(np.maximum(a, 0))  # Prevent sqrt of negative\n    \n    @staticmethod\n    def power(a: np.ndarray, b: Union[np.ndarray, float]) -> np.ndarray:\n        return np.power(a, b)\n    \n    @staticmethod\n    def abs(a: np.ndarray) -> np.ndarray:\n        return np.abs(a)\n    \n    @staticmethod\n    def sign(a: np.ndarray) -> np.ndarray:\n        return np.sign(a)\n    \n    @staticmethod\n    def clip(a: np.ndarray, min_val: float, max_val: float) -> np.ndarray:\n        return np.clip(a, min_val, max_val)\n\n# Install globally\ncpu_ops = CPUTensorOps()\n',{captureOutput:!1}),this.emit("operations:installed",{count:this.stats.supportedOperations.size})}_initializeOperations(){return{add:async(e,n)=>this._executePythonOp("cpu_ops.add",e,n),subtract:async(e,n)=>this._executePythonOp("cpu_ops.subtract",e,n),multiply:async(e,n)=>this._executePythonOp("cpu_ops.multiply",e,n),divide:async(e,n)=>this._executePythonOp("cpu_ops.divide",e,n),matmul:async(e,n)=>this._executePythonOp("cpu_ops.matmul",e,n),transpose:async(e,n)=>{const t=n.axes?`axes=${JSON.stringify(n.axes)}`:"";return this._executePythonOp("cpu_ops.transpose",e,{axes:t})},reshape:async(e,n)=>{if(!n.shape)throw new Error("Reshape operation requires shape parameter");return this._executePythonOp("cpu_ops.reshape",e,n)},sum:async(e,n)=>this._executePythonOp("cpu_ops.sum",e,n),mean:async(e,n)=>this._executePythonOp("cpu_ops.mean",e,n),max:async(e,n)=>this._executePythonOp("cpu_ops.max",e,n),min:async(e,n)=>this._executePythonOp("cpu_ops.min",e,n),relu:async(e,n)=>this._executePythonOp("cpu_ops.relu",e,n),sigmoid:async(e,n)=>this._executePythonOp("cpu_ops.sigmoid",e,n),tanh:async(e,n)=>this._executePythonOp("cpu_ops.tanh",e,n),softmax:async(e,n)=>this._executePythonOp("cpu_ops.softmax",e,n),exp:async(e,n)=>this._executePythonOp("cpu_ops.exp",e,n),log:async(e,n)=>this._executePythonOp("cpu_ops.log",e,n),sqrt:async(e,n)=>this._executePythonOp("cpu_ops.sqrt",e,n),power:async(e,n)=>this._executePythonOp("cpu_ops.power",e,n),abs:async(e,n)=>this._executePythonOp("cpu_ops.abs",e,n),sign:async(e,n)=>this._executePythonOp("cpu_ops.sign",e,n),clip:async(e,n)=>{if(void 0===n.min||void 0===n.max)throw new Error("Clip operation requires min and max parameters");return this._executePythonOp("cpu_ops.clip",e,n)}}}async _executePythonOp(e,n,t){if(!this.runtime)throw new Error("Runtime not available for CPU operations");try{const a=[],r=Array.isArray(n)?n:[n];for(let e=0;e<r.length;e++){const n=`tensor_${e}`;this.runtime.setGlobal(n,r[e]),a.push(n)}let s=`${e}(${a.join(", ")})`;if(t){const n=[];for(const[e,a]of Object.entries(t))"axes"===e?n.push(`${e}=${a}`):"string"==typeof a?n.push(`${e}="${a}"`):Array.isArray(a)?n.push(`${e}=${JSON.stringify(a)}`):n.push(`${e}=${a}`);n.length>0&&(s=`${e}(${a.join(", ")}, ${n.join(", ")})`)}const i=`\nresult = ${s}\nresult.tolist() if hasattr(result, 'tolist') else result\n`,o=await this.runtime.runPython(i,{captureOutput:!0,timeout:t.timeout||1e4});for(const e of a)await this.runtime.runPython(`del ${e}`,{captureOutput:!1});return o}catch(e){throw new Error(`CPU operation failed: ${e.message}`)}}_updateStats(e){this.stats.operations++,this.stats.totalExecutionTime+=e,this.stats.averageExecutionTime=this.stats.totalExecutionTime/this.stats.operations,this.stats.lastOperationTime=e}_getResultSize(e){return Array.isArray(e)||ArrayBuffer.isView(e)?e.length:e instanceof ArrayBuffer?e.byteLength/4:1}};class m{constructor(e){this.max=e,this.current=0,this.queue=[]}async acquire(){return new Promise(e=>{this.current<this.max?(this.current++,e()):this.queue.push(e)})}release(){if(this.current--,this.queue.length>0){const e=this.queue.shift();this.current++,e()}}}const g=class extends t{constructor(e={}){super(),this.config={maxWorkers:e.maxWorkers||navigator.hardwareConcurrency||4,workerTimeout:e.workerTimeout||3e4,enableLoadBalancing:!1!==e.enableLoadBalancing,queueMaxSize:e.queueMaxSize||100,...e},this.isInitialized=!1,this.workers=[],this.availableWorkers=[],this.busyWorkers=new Map,this.taskQueue=[],this.stats={workers:0,operations:0,totalExecutionTime:0,averageExecutionTime:0,queuedOperations:0,failedOperations:0,workerRestarts:0},this.nextTaskId=1,this.pendingTasks=new Map}async initialize(){if(this.isInitialized)return!0;try{return this.emit("init:start",{maxWorkers:this.config.maxWorkers}),await this._createWorkerPool(),this._startTaskProcessor(),this.isInitialized=!0,this.emit("init:complete",{workers:this.workers.length,ready:this.availableWorkers.length}),!0}catch(e){throw this.emit("init:error",{error:e}),e}}async execute(e,n,t={}){if(!this.isInitialized)throw new Error("Worker engine not initialized");return new Promise((a,r)=>{const s=this.nextTaskId++,i=performance.now(),o={id:s,operation:e,tensors:n,options:t,startTime:i,resolve:a,reject:r,timeout:setTimeout(()=>{this._handleTaskTimeout(s)},t.timeout||this.config.workerTimeout)};this.pendingTasks.set(s,o),this._queueTask(o),this.emit("task:queued",{taskId:s,operation:e,queueSize:this.taskQueue.length})})}async executeBatch(e,n={}){const{parallel:t=!0,maxConcurrency:a=this.config.maxWorkers,loadBalance:r=this.config.enableLoadBalancing}=n;if(!t){const n=[];for(const t of e){const e=await this.execute(t.operation,t.tensors,t.options);n.push(e)}return n}if(r){const n=this._distributeOperations(e).map(e=>this.execute(e.operation,e.tensors,e.options));return Promise.all(n)}const s=new m(a),i=e.map(async e=>{await s.acquire();try{return await this.execute(e.operation,e.tensors,e.options)}finally{s.release()}});return Promise.all(i)}getStats(){return{...this.stats,isInitialized:this.isInitialized,availableWorkers:this.availableWorkers.length,busyWorkers:this.busyWorkers.size,queuedTasks:this.taskQueue.length,pendingTasks:this.pendingTasks.size,type:"worker"}}async cleanup(){try{this.emit("cleanup:start");for(const[e,n]of this.pendingTasks.entries())clearTimeout(n.timeout),n.reject(new Error("Worker engine shutting down"));this.pendingTasks.clear(),this.taskQueue=[];for(const e of this.workers)e.terminate();this.workers=[],this.availableWorkers=[],this.busyWorkers.clear(),this.isInitialized=!1,this.emit("cleanup:complete")}catch(e){throw this.emit("cleanup:error",{error:e}),e}}async _createWorkerPool(){const e=this._generateWorkerScript(),n=new Blob([e],{type:"application/javascript"}),t=URL.createObjectURL(n);try{for(let e=0;e<this.config.maxWorkers;e++){const n=new Worker(t),a=e;n.addEventListener("message",e=>{this._handleWorkerMessage(a,e)}),n.addEventListener("error",e=>{this._handleWorkerError(a,e)}),n.addEventListener("messageerror",e=>{this._handleWorkerError(a,e)}),this.workers.push(n),this.availableWorkers.push(a),this.stats.workers++,this.emit("worker:created",{workerId:a})}}finally{URL.revokeObjectURL(t)}}_generateWorkerScript(){return"\n// Worker script for tensor operations\nclass WorkerTensorOps {\n  constructor() {\n    this.operations = {\n      add: (a, b) => a.map((val, i) => val + b[i]),\n      subtract: (a, b) => a.map((val, i) => val - b[i]),\n      multiply: (a, b) => a.map((val, i) => val * b[i]),\n      divide: (a, b) => a.map((val, i) => val / (b[i] || 1e-12)),\n      \n      matmul: (a, b, shapeA, shapeB) => {\n        if (shapeA.length !== 2 || shapeB.length !== 2) {\n          throw new Error('Matrix multiplication requires 2D arrays');\n        }\n        \n        const [rowsA, colsA] = shapeA;\n        const [rowsB, colsB] = shapeB;\n        \n        if (colsA !== rowsB) {\n          throw new Error('Matrix dimensions incompatible for multiplication');\n        }\n        \n        const result = new Array(rowsA * colsB).fill(0);\n        \n        for (let i = 0; i < rowsA; i++) {\n          for (let j = 0; j < colsB; j++) {\n            let sum = 0;\n            for (let k = 0; k < colsA; k++) {\n              sum += a[i * colsA + k] * b[k * colsB + j];\n            }\n            result[i * colsB + j] = sum;\n          }\n        }\n        \n        return result;\n      },\n      \n      transpose: (a, shape) => {\n        if (shape.length !== 2) {\n          throw new Error('Transpose currently supports only 2D arrays');\n        }\n        \n        const [rows, cols] = shape;\n        const result = new Array(rows * cols);\n        \n        for (let i = 0; i < rows; i++) {\n          for (let j = 0; j < cols; j++) {\n            result[j * rows + i] = a[i * cols + j];\n          }\n        }\n        \n        return result;\n      },\n      \n      sum: (a, axis) => {\n        if (axis === null || axis === undefined) {\n          return a.reduce((sum, val) => sum + val, 0);\n        }\n        // Simplified sum along axis (would need full tensor implementation)\n        return a.reduce((sum, val) => sum + val, 0);\n      },\n      \n      mean: (a, axis) => {\n        const sum = this.operations.sum(a, axis);\n        return Array.isArray(sum) ? sum.map(val => val / a.length) : sum / a.length;\n      },\n      \n      relu: (a) => a.map(val => Math.max(0, val)),\n      \n      sigmoid: (a) => a.map(val => 1 / (1 + Math.exp(-Math.max(-250, Math.min(250, val))))),\n      \n      tanh: (a) => a.map(val => Math.tanh(val)),\n      \n      softmax: (a) => {\n        const maxVal = Math.max(...a);\n        const exp = a.map(val => Math.exp(val - maxVal));\n        const sum = exp.reduce((s, val) => s + val, 0);\n        return exp.map(val => val / sum);\n      },\n      \n      exp: (a) => a.map(val => Math.exp(Math.max(-250, Math.min(250, val)))),\n      \n      log: (a) => a.map(val => Math.log(Math.max(1e-12, val))),\n      \n      sqrt: (a) => a.map(val => Math.sqrt(Math.max(0, val))),\n      \n      abs: (a) => a.map(val => Math.abs(val)),\n      \n      power: (a, b) => {\n        if (Array.isArray(b)) {\n          return a.map((val, i) => Math.pow(val, b[i]));\n        } else {\n          return a.map(val => Math.pow(val, b));\n        }\n      }\n    };\n  }\n  \n  execute(operation, tensors, options = {}) {\n    try {\n      const op = this.operations[operation];\n      if (!op) {\n        throw new Error(`Unsupported operation: ${operation}`);\n      }\n      \n      // Convert tensors to arrays if needed\n      const tensorArrays = tensors.map(tensor => {\n        if (tensor.data && tensor.shape) {\n          return { data: Array.from(tensor.data), shape: tensor.shape };\n        } else if (Array.isArray(tensor)) {\n          return { data: tensor, shape: [tensor.length] };\n        } else {\n          return { data: Array.from(tensor), shape: [tensor.length] };\n        }\n      });\n      \n      // Execute operation\n      let result;\n      switch (operation) {\n        case 'matmul':\n          result = op(tensorArrays[0].data, tensorArrays[1].data, \n                      tensorArrays[0].shape, tensorArrays[1].shape);\n          break;\n        case 'transpose':\n          result = op(tensorArrays[0].data, tensorArrays[0].shape);\n          break;\n        case 'power':\n          if (tensorArrays.length > 1) {\n            result = op(tensorArrays[0].data, tensorArrays[1].data);\n          } else {\n            result = op(tensorArrays[0].data, options.exponent || 2);\n          }\n          break;\n        default:\n          if (tensorArrays.length === 1) {\n            result = op(tensorArrays[0].data, options.axis);\n          } else {\n            result = op(tensorArrays[0].data, tensorArrays[1].data);\n          }\n      }\n      \n      return result;\n    } catch (error) {\n      throw new Error(`Worker operation failed: ${error.message}`);\n    }\n  }\n}\n\nconst tensorOps = new WorkerTensorOps();\n\nself.addEventListener('message', function(event) {\n  const { taskId, operation, tensors, options } = event.data;\n  \n  try {\n    const startTime = performance.now();\n    const result = tensorOps.execute(operation, tensors, options);\n    const executionTime = performance.now() - startTime;\n    \n    self.postMessage({\n      taskId,\n      success: true,\n      result,\n      executionTime\n    });\n  } catch (error) {\n    self.postMessage({\n      taskId,\n      success: false,\n      error: error.message\n    });\n  }\n});\n"}_queueTask(e){if(this.taskQueue.length>=this.config.queueMaxSize)return e.reject(new Error("Worker queue full")),void this.stats.failedOperations++;this.taskQueue.push(e),this.stats.queuedOperations++,this._processTaskQueue()}_startTaskProcessor(){setInterval(()=>{this._processTaskQueue()},10)}_processTaskQueue(){for(;this.taskQueue.length>0&&this.availableWorkers.length>0;){const e=this.taskQueue.shift(),n=this.availableWorkers.shift();this.busyWorkers.set(n,e),this.workers[n].postMessage({taskId:e.id,operation:e.operation,tensors:e.tensors,options:e.options}),this.emit("task:started",{taskId:e.id,workerId:n,operation:e.operation})}}_handleWorkerMessage(e,n){const{taskId:t,success:a,result:s,error:i,executionTime:o}=n.data,d=this.pendingTasks.get(t);if(!d)return void r.warn("Received message for unknown task:",{taskId:t,workerId:e,availableTasks:Array.from(this.pendingTasks.keys())});clearTimeout(d.timeout),this.pendingTasks.delete(t),this.busyWorkers.delete(e),this.availableWorkers.push(e);const l=performance.now()-d.startTime;this.stats.operations++,this.stats.totalExecutionTime+=l,this.stats.averageExecutionTime=this.stats.totalExecutionTime/this.stats.operations,a?(d.resolve(s),this.emit("task:completed",{taskId:t,workerId:e,executionTime:l,workerTime:o})):(this.stats.failedOperations++,d.reject(new Error(i)),this.emit("task:failed",{taskId:t,workerId:e,error:i,executionTime:l}))}_handleWorkerError(e,n){this.emit("worker:error",{workerId:e,error:n});const t=this.busyWorkers.get(e);t&&(clearTimeout(t.timeout),this.pendingTasks.delete(t.id),this.busyWorkers.delete(e),t.reject(new Error(`Worker error: ${n.message||n}`)),this.stats.failedOperations++),this._restartWorker(e)}_handleTaskTimeout(e){const n=this.pendingTasks.get(e);if(n){this.pendingTasks.delete(e);for(const[n,t]of this.busyWorkers.entries())if(t.id===e){this.busyWorkers.delete(n),this._restartWorker(n);break}this.stats.failedOperations++,n.reject(new Error(`Task timeout after ${this.config.workerTimeout}ms`)),this.emit("task:timeout",{taskId:e,timeout:this.config.workerTimeout})}}async _restartWorker(e){try{this.workers[e]?.terminate();const n=this._generateWorkerScript(),t=new Blob([n],{type:"application/javascript"}),a=URL.createObjectURL(t),r=new Worker(a);URL.revokeObjectURL(a),r.addEventListener("message",n=>{this._handleWorkerMessage(e,n)}),r.addEventListener("error",n=>{this._handleWorkerError(e,n)}),this.workers[e]=r,this.availableWorkers.push(e),this.stats.workerRestarts++,this.emit("worker:restarted",{workerId:e})}catch(n){this.emit("worker:restart-failed",{workerId:e,error:n})}}_distributeOperations(e){return e.map((e,n)=>({...e,preferredWorker:n%this.config.maxWorkers}))}};class h{constructor(e){this.max=e,this.current=0,this.queue=[]}async acquire(){return new Promise(e=>{this.current<this.max?(this.current++,e()):this.queue.push(e)})}release(){if(this.current--,this.queue.length>0){const e=this.queue.shift();this.current++,e()}}}const b=class extends t{constructor(e={}){super(),this.config={webgpuMinElements:e.webgpuMinElements||1e3,workerMinElements:e.workerMinElements||1e4,maxConcurrentOperations:e.maxConcurrentOperations||4,memoryThresholdMB:e.memoryThresholdMB||512,enableAutoFallback:!1!==e.enableAutoFallback,fallbackTimeout:e.fallbackTimeout||5e3,enableAdaptiveSelection:!1!==e.enableAdaptiveSelection,performanceHistorySize:e.performanceHistorySize||100,...e},this.webgpu=new _(e.webgpu||{}),this.cpu=new c(e.cpu||{}),this.worker=new g(e.worker||{}),this.isInitialized=!1,this.availableStrategies=new Set,this.currentOperations=new Map,this.performanceHistory=new Map,this.strategyPreferences=new Map,this.resourceMonitor={memoryUsage:0,activeOperations:0,gpuUtilization:0}}async initialize(){if(this.isInitialized)return this.availableStrategies;this.emit("init:start");try{try{if(await this.webgpu.initialize())this.availableStrategies.add("webgpu"),this._setupEngineForwarding(this.webgpu,"webgpu"),this.emit("init:webgpu-success",{message:"WebGPU engine initialized successfully"});else{const e=this.webgpu.initFailureReason||"Unknown WebGPU initialization failure";this.emit("init:webgpu-failed",{error:new Error(e),details:"WebGPU engine initialization returned false"})}}catch(e){this.emit("init:webgpu-failed",{error:e})}await this.cpu.initialize(),this.availableStrategies.add("cpu"),this._setupEngineForwarding(this.cpu,"cpu");try{await this.worker.initialize(),this.availableStrategies.add("worker"),this._setupEngineForwarding(this.worker,"worker")}catch(e){this.emit("init:worker-failed",{error:e})}return this.isInitialized=!0,this.emit("init:complete",{strategies:Array.from(this.availableStrategies)}),this.availableStrategies}catch(e){throw this.emit("init:error",{error:e}),e}}async execute(e,n,t={}){if(!this.isInitialized)throw new Error("ComputeStrategy not initialized. Call initialize() first.");const a=performance.now(),r=this._generateOperationId();this.emit("execute:start",{operation:e,operationId:r,options:t});try{const s=await this._selectStrategy(e,n,t);this.currentOperations.set(r,{operation:e,strategy:s.name,startTime:a,tensors:Array.isArray(n)?n.length:1}),this.resourceMonitor.activeOperations++;const i=await this._executeWithFallback(s,e,n,t),o=performance.now()-a;return this._recordPerformance(e,s.name,o,n),this.currentOperations.delete(r),this.resourceMonitor.activeOperations--,this.emit("execute:complete",{operation:e,operationId:r,strategy:s.name,executionTime:o,resultSize:i.length}),i}catch(n){throw this.currentOperations.delete(r),this.resourceMonitor.activeOperations--,this.emit("execute:error",{operation:e,operationId:r,error:n}),n}}async executeBatch(e,n={}){const{parallel:t=!0,maxConcurrency:a=this.config.maxConcurrentOperations,loadBalance:r=!0}=n;if(!t){const n=[];for(const t of e){const e=await this.execute(t.operation,t.tensors,t.options);n.push(e)}return n}if(r)return this._executeWithLoadBalancing(e,a);const s=new h(a),i=e.map(async e=>{await s.acquire();try{return await this.execute(e.operation,e.tensors,e.options)}finally{s.release()}});return Promise.all(i)}getStats(){const e={availableStrategies:Array.from(this.availableStrategies),activeOperations:this.resourceMonitor.activeOperations,resourceMonitor:{...this.resourceMonitor},strategyPreferences:Object.fromEntries(this.strategyPreferences),engines:{}};return this.availableStrategies.has("webgpu")&&(e.engines.webgpu=this.webgpu.getStats()),this.availableStrategies.has("cpu")&&(e.engines.cpu=this.cpu.getStats()),this.availableStrategies.has("worker")&&(e.engines.worker=this.worker.getStats()),e}setStrategyPreference(e,n){if(!this.availableStrategies.has(n))throw new Error(`Strategy '${n}' not available`);this.strategyPreferences.set(e,n),this.emit("strategy:preference-set",{operation:e,strategy:n})}resetAdaptiveSelection(){this.performanceHistory.clear(),this.strategyPreferences.clear(),this.emit("strategy:reset")}async cleanup(){this.emit("cleanup:start");try{const e=[];this.webgpu&&e.push(this.webgpu.cleanup()),this.cpu&&e.push(this.cpu.cleanup()),this.worker&&e.push(this.worker.cleanup()),await Promise.all(e),this.availableStrategies.clear(),this.currentOperations.clear(),this.performanceHistory.clear(),this.isInitialized=!1,this.emit("cleanup:complete")}catch(e){throw this.emit("cleanup:error",{error:e}),e}}async _selectStrategy(e,n,t){if(t.strategy&&this.availableStrategies.has(t.strategy))return this._getEngine(t.strategy);if(this.config.enableAdaptiveSelection&&this.strategyPreferences.has(e)){const n=this.strategyPreferences.get(e);if(this.availableStrategies.has(n))return this._getEngine(n)}const a=this._calculateWorkloadSize(n),r=this._estimateComplexity(e,n),s=this._assessResourcePressure();return this._shouldUseWebGPU(e,a,r,s)?this._getEngine("webgpu"):this._shouldUseWorker(e,a,r,s)?this._getEngine("worker"):this._getEngine("cpu")}_shouldUseWebGPU(e,n,t,a){return!!this.availableStrategies.has("webgpu")&&(!(n<this.config.webgpuMinElements)&&(!(a.memory>.8||a.activeOperations>.9)&&(!!["matmul","conv2d","add","multiply","relu","sigmoid"].includes(e)||t>.7)))}_shouldUseWorker(e,n,t,a){return!!this.availableStrategies.has("worker")&&(n>this.config.workerMinElements&&t>.5||a.activeOperations>.7)}async _executeWithFallback(e,n,t,a){if(!this.config.enableAutoFallback)return e.execute(n,t,a);try{const r=e.execute(n,t,a),s=new Promise((e,n)=>{setTimeout(()=>n(new Error("Operation timeout")),this.config.fallbackTimeout)});return await Promise.race([r,s])}catch(r){this.emit("fallback:triggered",{from:e.name,operation:n,error:r.message});const s=this._getFallbackOrder(e.name);for(const e of s)if(this.availableStrategies.has(e))try{const r=this._getEngine(e);return this.emit("fallback:executing",{strategy:e,operation:n}),await r.execute(n,t,a)}catch(t){this.emit("fallback:failed",{strategy:e,operation:n,error:t.message})}throw r}}async _executeWithLoadBalancing(e,n){const t=this._groupOperationsByLoad(e),a=this._distributeOperations(t),r=new h(n),s=a.map(async e=>{await r.acquire();try{return await this.execute(e.operation,e.tensors,e.options)}finally{r.release()}});return Promise.all(s)}_getEngine(e){const n={webgpu:this.webgpu,cpu:this.cpu,worker:this.worker}[e];if(!n)throw new Error(`Engine '${e}' not found`);return n.name=e,n}_calculateWorkloadSize(e){return(Array.isArray(e)?e:[e]).reduce((e,n)=>ArrayBuffer.isView(n)?e+n.length:n instanceof ArrayBuffer?e+n.byteLength/4:e,0)}_estimateComplexity(e,n){const t={add:.1,multiply:.1,matmul:.8,conv2d:.9,relu:.2,sigmoid:.3,softmax:.6,transpose:.3}[e]||.5,a=this._calculateWorkloadSize(n),r=Math.log10(Math.max(a,1))/6;return Math.min(t*(1+r),1)}_assessResourcePressure(){return{memory:this.resourceMonitor.memoryUsage/(1024*this.config.memoryThresholdMB*1024),activeOperations:this.resourceMonitor.activeOperations/this.config.maxConcurrentOperations,gpu:this.resourceMonitor.gpuUtilization}}_recordPerformance(e,n,t,a){if(!this.config.enableAdaptiveSelection)return;this.performanceHistory.has(e)||this.performanceHistory.set(e,{webgpu:[],cpu:[],worker:[]});const r=this.performanceHistory.get(e)[n];r.length>=this.config.performanceHistorySize&&r.shift(),r.push({executionTime:t,workloadSize:this._calculateWorkloadSize(a),timestamp:Date.now()}),this._updateStrategyPreference(e)}_updateStrategyPreference(e){const n=this.performanceHistory.get(e);if(!n)return;const t={};for(const[e,a]of Object.entries(n))if(a.length>0){const n=a.reduce((e,n)=>e+n.executionTime,0)/a.length;t[e]=n}const a=Object.entries(t).reduce((e,[n,t])=>!e||t<e.avgTime?{strategy:n,avgTime:t}:e,null);a&&this.availableStrategies.has(a.strategy)&&this.strategyPreferences.set(e,a.strategy)}_getFallbackOrder(e){return{webgpu:["cpu","worker"],worker:["cpu"],cpu:[]}[e]||[]}_generateOperationId(){return`op_${Date.now()}_${Math.random().toString(36).substr(2,9)}`}_setupEngineForwarding(e,n){e.on("init:complete",e=>this.emit(`${n}:ready`,e)),e.on("compute:error",e=>this.emit(`${n}:error`,e)),e.on("cleanup:complete",()=>this.emit(`${n}:cleanup`))}_groupOperationsByLoad(e){return e.map(e=>({...e,estimatedLoad:this._estimateComplexity(e.operation,e.tensors),workloadSize:this._calculateWorkloadSize(e.tensors)}))}_distributeOperations(e){return e}},y=class extends t{constructor(e={}){super(),this.config={maxMemoryMB:e.maxMemoryMB||1024,gcThreshold:e.gcThreshold||.8,checkInterval:e.checkInterval||5e3,enableAutoGC:!1!==e.enableAutoGC,...e},this.resources=new Map,this.bufferPool=new Map,this.activeBuffers=new Set,this.memoryUsage=0,this.peakMemoryUsage=0,this.gcCount=0,this.registry=null,this.cleanupTasks=new Set,this.monitoringInterval=null,this._initializeFinalizationRegistry(),this.config.enableAutoGC&&this._startMemoryMonitoring()}register(e,n,t={}){const{size:a=0,type:r="generic",priority:s="normal",autoRelease:i=!0}=t,o=this._generateId(),d={id:o,resource:e,cleanup:n,size:a,type:r,priority:s,autoRelease:i,createdAt:Date.now(),lastAccessed:Date.now()};return this.resources.set(o,d),this.memoryUsage+=a,this.peakMemoryUsage=Math.max(this.peakMemoryUsage,this.memoryUsage),this.registry&&i&&this.registry.register(e,{id:o,cleanup:n},e),this.emit("resource:registered",{id:o,type:r,size:a}),this._shouldRunGC()&&this._scheduleGC(),o}async unregister(e){const n=this.resources.get(e);if(!n)return!1;try{return await this._cleanupResource(n),this.resources.delete(e),this.memoryUsage-=n.size,this.emit("resource:unregistered",{id:e,type:n.type,size:n.size}),!0}catch(n){return this.emit("cleanup:error",{id:e,error:n}),!1}}allocateBuffer(e,n,t=GPUBufferUsage.STORAGE|GPUBufferUsage.COPY_SRC|GPUBufferUsage.COPY_DST){const a=`${n}-${t}`,r=this.bufferPool.get(a);let s;r&&r.length>0?(s=r.pop(),this.emit("buffer:reused",{size:n,usage:t})):(s=e.createBuffer({size:n,usage:t}),this.emit("buffer:created",{size:n,usage:t})),this.activeBuffers.add(s);const i=this.register(s,()=>this._cleanupBuffer(s),{size:n,type:"webgpu-buffer",priority:"high"});return s._greedId=i,s}releaseBuffer(e,n={}){const{destroy:t=!1,poolMaxSize:a=20}=n;if(!this.activeBuffers.has(e))return!1;if(this.activeBuffers.delete(e),e._greedId&&this.unregister(e._greedId),t)return e.destroy(),this.emit("buffer:destroyed",{buffer:e}),!0;const r=`${e.size}-${e.usage}`;this.bufferPool.has(r)||this.bufferPool.set(r,[]);const s=this.bufferPool.get(r);return s.length<a?(s.push(e),this.emit("buffer:pooled",{buffer:e,poolSize:s.length})):(e.destroy(),this.emit("buffer:destroyed",{buffer:e,reason:"pool-full"})),!0}async forceGC(e={}){const{aggressive:n=!1,targetReduction:t=.3,maxAge:a=3e5}=e;this.gcCount++;const r=performance.now(),s=this.memoryUsage;this.emit("gc:start",{aggressive:n,targetReduction:t});try{let e=0;const i=Date.now(),o=Array.from(this.resources.entries()).sort(([,e],[,n])=>{if(e.priority!==n.priority){const t={low:0,normal:1,high:2};return t[e.priority]-t[n.priority]}return i-e.lastAccessed-(i-n.lastAccessed)});for(const[r,d]of o){const o=i-d.lastAccessed;if((n||o>a||"low"===d.priority&&this._shouldRunGC())&&d.autoRelease&&await this.unregister(r)&&e++,(s-this.memoryUsage)/s>=t)break}window.gc&&n&&window.gc();const d=performance.now()-r,l=s-this.memoryUsage;return this.emit("gc:complete",{cleaned:e,duration:d,memoryReduction:l,newMemoryUsage:this.memoryUsage}),{cleaned:e,memoryReduction:l,duration:d}}catch(e){throw this.emit("gc:error",{error:e}),e}}getStats(){return{memoryUsage:this.memoryUsage,memoryUsageMB:Math.round(this.memoryUsage/1048576*100)/100,maxMemoryMB:this.config.maxMemoryMB,peakMemoryUsage:this.peakMemoryUsage,peakMemoryUsageMB:Math.round(this.peakMemoryUsage/1048576*100)/100,memoryUtilization:this.memoryUsage/(1024*this.config.maxMemoryMB*1024),resourceCount:this.resources.size,activeBuffers:this.activeBuffers.size,bufferPools:this.bufferPool.size,gcCount:this.gcCount,resourceTypes:this._getResourceTypeStats()}}async cleanup(){this.emit("cleanup:start");try{this.monitoringInterval&&(clearInterval(this.monitoringInterval),this.monitoringInterval=null);const e=Array.from(this.resources.keys());for(const n of e)await this.unregister(n);for(const e of this.bufferPool.values())for(const n of e)n.destroy();this.bufferPool.clear();for(const e of this.activeBuffers)e.destroy();this.activeBuffers.clear(),this.memoryUsage=0,this.emit("cleanup:complete")}catch(e){throw this.emit("cleanup:error",{error:e}),e}}_initializeFinalizationRegistry(){"undefined"!=typeof FinalizationRegistry&&(this.registry=new FinalizationRegistry(({id:e,cleanup:n})=>{try{if(n(),this.resources.has(e)){const n=this.resources.get(e);this.resources.delete(e),this.memoryUsage-=n.size,this.emit("resource:finalized",{id:e})}}catch(n){this.emit("finalization:error",{id:e,error:n})}}))}_startMemoryMonitoring(){this.monitoringInterval=setInterval(()=>{this._shouldRunGC()&&this.forceGC({aggressive:!1})},this.config.checkInterval)}_shouldRunGC(){const e=1024*this.config.maxMemoryMB*1024;return this.memoryUsage>e*this.config.gcThreshold}_scheduleGC(){setTimeout(()=>this.forceGC(),0)}async _cleanupResource(e){try{"function"==typeof e.cleanup&&await e.cleanup()}catch(n){throw new Error(`Failed to cleanup resource ${e.id}: ${n.message}`)}}_cleanupBuffer(e){return new Promise(n=>{try{e&&"function"==typeof e.destroy&&e.destroy(),n()}catch(t){r.warn("Buffer cleanup error:",{bufferId:e._greedId,error:t.message,stack:t.stack}),n()}})}_generateId(){return`mem_${Date.now()}_${Math.random().toString(36).substr(2,9)}`}_getResourceTypeStats(){const e={};for(const n of this.resources.values())e[n.type]||(e[n.type]={count:0,totalSize:0}),e[n.type].count++,e[n.type].totalSize+=n.size;return e}};class w extends Error{constructor(e,n="security",t="high"){super(e),this.name="SecurityError",this.category=n,this.severity=t,this.timestamp=(new Date).toISOString()}}const k=class extends t{constructor(e={}){super(),this.config={strictMode:!1!==e.strictMode,allowEval:!0===e.allowEval,allowFileSystem:!0===e.allowFileSystem,allowNetwork:!0===e.allowNetwork,allowSubprocess:!0===e.allowSubprocess,maxCodeLength:e.maxCodeLength||1e5,maxTensorSize:e.maxTensorSize||1e8,maxTensorCount:e.maxTensorCount||100,maxStringLength:e.maxStringLength||1e4,maxMemoryMB:e.maxMemoryMB||1024,maxExecutionTimeMs:e.maxExecutionTimeMs||3e4,allowedPackages:new Set(e.allowedPackages||["numpy","math","random","json","datetime","collections","itertools","functools","operator","re","scipy","matplotlib","pandas","scikit-learn","sklearn","plotly","seaborn","statsmodels","sympy","networkx"]),customDangerousPatterns:e.customDangerousPatterns||[],customAllowedPatterns:e.customAllowedPatterns||[],...e},this.dangerousPatterns=this._initializeDangerousPatterns(),this.suspiciousPatterns=this._initializeSuspiciousPatterns(),this.fileSystemPatterns=this._initializeFileSystemPatterns(),this.networkPatterns=this._initializeNetworkPatterns(),this.stats={totalValidations:0,blockedOperations:0,warningsIssued:0,lastValidation:null,threatCategories:{}}}validatePythonCode(e,n={}){const t=performance.now();this.stats.totalValidations++;try{this.emit("validation:start",{codeLength:e.length,strict:this.config.strictMode}),this._validateCodeInput(e);const a=this._analyzeSecurityThreats(e),r=this._assessRiskLevel(a),s=this._enforceSecurityPolicy(e,a,r,n);this._updateValidationStats(a,r,s);const i=performance.now()-t;return this.emit("validation:complete",{threats:a.length,riskLevel:r,allowed:s.allowed,validationTime:i}),s}catch(n){throw this.emit("validation:error",{error:n,codePreview:e.substring(0,100)}),n}}validateTensorData(e,n={}){const t=Array.isArray(e)?e:[e];this.emit("tensor:validation:start",{tensorCount:t.length});try{if(t.length>this.config.maxTensorCount)throw new w(`Too many tensors: ${t.length} > ${this.config.maxTensorCount}`);let e=0,n=0;for(let a=0;a<t.length;a++){const r=t[a];if(!this._isValidTensorType(r))throw new w(`Invalid tensor type at index ${a}: ${typeof r}`);const s=this._getTensorElementCount(r);if(s>this.config.maxTensorSize)throw new w(`Tensor too large at index ${a}: ${s} > ${this.config.maxTensorSize}`);const i=this._estimateTensorMemoryMB(r);n+=i,e+=s,this.emit("tensor:validated",{index:a,elements:s,memoryMB:Math.round(100*i)/100})}if(n>this.config.maxMemoryMB)throw new w(`Total tensor memory too large: ${Math.round(n)}MB > ${this.config.maxMemoryMB}MB`);return this.emit("tensor:validation:complete",{tensorCount:t.length,totalElements:e,totalMemoryMB:Math.round(100*n)/100}),{valid:!0,tensorCount:t.length,totalElements:e,totalMemoryMB:n,warnings:[]}}catch(e){throw this.emit("tensor:validation:error",{error:e}),e}}validateOperation(e,n,t={}){this.emit("operation:validation:start",{operation:e});try{if(!e||"string"!=typeof e)throw new w("Operation must be a non-empty string");if(e.length>100)throw new w(`Operation name too long: ${e.length} > 100`);if(["eval","exec","compile","__import__","subprocess"].some(n=>e.toLowerCase().includes(n)))throw new w(`Dangerous operation detected: ${e}`);const a=this._validateOperationParams(n),r=this._validateOperationOptions(t);return this.emit("operation:validation:complete",{operation:e,paramCount:Object.keys(a).length}),{valid:!0,operation:e,params:a,options:r}}catch(n){throw this.emit("operation:validation:error",{operation:e,error:n}),n}}validateURL(e,n={}){const{allowedDomains:t=[],blockedDomains:a=[],requireHTTPS:r=!0}=n;try{const n=new URL(e);if(r&&"https:"!==n.protocol)throw new w(`HTTPS required for URL: ${e}`);if(a.includes(n.hostname))throw new w(`Blocked domain: ${n.hostname}`);if(t.length>0&&!t.includes(n.hostname))throw new w(`Domain not in allowlist: ${n.hostname}`);if([/localhost/i,/127\.0\.0\.1/,/0\.0\.0\.0/,/\[::\]/,/internal/i,/private/i,/admin/i,/\.local$/i].some(n=>n.test(e)))throw new w(`Suspicious URL pattern detected: ${e}`);return{valid:!0,url:n.href,domain:n.hostname}}catch(n){if(n instanceof w)throw n;throw new w(`Invalid URL: ${e} - ${n.message}`)}}getStats(){return{...this.stats,config:{strictMode:this.config.strictMode,maxTensorSize:this.config.maxTensorSize,maxMemoryMB:this.config.maxMemoryMB,allowedPackages:Array.from(this.config.allowedPackages)}}}updateConfig(e){const n={...this.config};this.config={...this.config,...e},e.allowedPackages&&(this.config.allowedPackages=new Set(e.allowedPackages)),this.emit("config:updated",{oldConfig:n,newConfig:this.config})}resetStats(){this.stats={totalValidations:0,blockedOperations:0,warningsIssued:0,lastValidation:null,threatCategories:{}},this.emit("stats:reset")}_validateCodeInput(e){if("string"!=typeof e)throw new w("Code must be a string");if(0===e.length)throw new w("Code cannot be empty");if(e.length>this.config.maxCodeLength)throw new w(`Code too long: ${e.length} > ${this.config.maxCodeLength}`);if(/[\x00-\x08\x0B\x0C\x0E-\x1F\x7F]/.test(e))throw new w("Code contains invalid control characters")}_analyzeSecurityThreats(e){const n=[];for(const[t,a]of Object.entries(this.dangerousPatterns))for(const r of a){const a=e.match(r.regex);a&&"none"!==r.severity&&n.push({category:t,type:"dangerous",pattern:r.name,severity:r.severity,matches:a.length,description:r.description,firstMatch:a[0]})}for(const[t,a]of Object.entries(this.suspiciousPatterns))for(const r of a){const a=e.match(r.regex);a&&"none"!==r.severity&&n.push({category:t,type:"suspicious",pattern:r.name,severity:r.severity,matches:a.length,description:r.description,firstMatch:a[0]})}if(!this.config.allowFileSystem)for(const t of this.fileSystemPatterns){const a=e.match(t.regex);a&&n.push({category:"filesystem",type:"blocked",pattern:t.name,severity:"high",matches:a.length,description:"File system access not allowed",firstMatch:a[0]})}if(!this.config.allowNetwork)for(const t of this.networkPatterns){const a=e.match(t.regex);a&&n.push({category:"network",type:"blocked",pattern:t.name,severity:"high",matches:a.length,description:"Network access not allowed",firstMatch:a[0]})}return n}_assessRiskLevel(e){if(0===e.length)return"low";const n=e.filter(e=>"critical"===e.severity).length,t=e.filter(e=>"high"===e.severity).length,a=e.filter(e=>"medium"===e.severity).length;return n>0||t>2?"critical":t>0||a>3?"high":a>0?"medium":"low"}_enforceSecurityPolicy(e,n,t,a={}){const{allowWarnings:r=!1,bypassValidation:s=!1}=a;if(s&&!this.config.strictMode)return this.emit("policy:bypassed",{riskLevel:t,threats:n.length}),{allowed:!0,bypassed:!0,riskLevel:t,threats:n,warnings:["Security validation was bypassed"]};if("critical"===t||"high"===t&&this.config.strictMode)throw this.stats.blockedOperations++,this.emit("policy:blocked",{riskLevel:t,threats:n.length}),this.emit("threats:detected",n.map(e=>({pattern:e.pattern,severity:e.severity,description:e.description,firstMatch:e.firstMatch}))),new w(`Security policy violation: ${t} risk detected with ${n.length} threats`);if("high"!==t||this.config.strictMode||this.emit("policy:warning",{riskLevel:t,threats:n.length,message:"High-risk operation allowed in non-strict mode"}),"medium"===t){if(r)return this.stats.warningsIssued++,this.emit("policy:warning",{riskLevel:t,threats:n.length}),{allowed:!0,riskLevel:t,threats:n,warnings:n.map(e=>`${e.category}: ${e.description}`)};if(this.config.strictMode)throw this.stats.blockedOperations++,new w(`Security policy violation: ${t} risk detected (strict mode)`)}return{allowed:!0,riskLevel:t,threats:n,warnings:"low"===t?[]:n.map(e=>`${e.category}: ${e.description}`)}}_isValidTensorType(e){return ArrayBuffer.isView(e)||e instanceof ArrayBuffer||Array.isArray(e)||e&&"object"==typeof e&&e.constructor&&e.constructor.name.includes("Array")}_getTensorElementCount(e){return ArrayBuffer.isView(e)?e.length:e instanceof ArrayBuffer?e.byteLength/4:Array.isArray(e)?e.length:0}_estimateTensorMemoryMB(e){return this._getTensorElementCount(e)*(ArrayBuffer.isView(e)?e.BYTES_PER_ELEMENT:4)/1048576}_validateOperationParams(e){const n={};for(const[t,a]of Object.entries(e||{})){if("string"!=typeof t||t.length>100)throw new w(`Invalid parameter key: ${t}`);if("string"==typeof a&&a.length>this.config.maxStringLength)throw new w(`Parameter value too long: ${t}`);n[t]=a}return n}_validateOperationOptions(e){const n={},t=["timeout","strategy","workgroupSize","dataType","precision","optimization","caching","parallel"];for(const[a,r]of Object.entries(e||{}))t.includes(a)?n[a]=r:this.emit("option:unknown",{key:a,value:r});return n}_updateValidationStats(e,n,t){this.stats.lastValidation={timestamp:Date.now(),threats:e.length,riskLevel:n,allowed:t.allowed};for(const n of e)this.stats.threatCategories[n.category]||(this.stats.threatCategories[n.category]=0),this.stats.threatCategories[n.category]++}_initializeDangerousPatterns(){return{codeExecution:[{name:"eval",regex:/(?:^|[^.\w])eval\s*\(/g,severity:"critical",description:"Dynamic code execution with eval()"},{name:"exec",regex:/\bexec\s*\(/g,severity:"critical",description:"Dynamic code execution with exec()"},{name:"compile",regex:/\bcompile\s*\(/g,severity:"high",description:"Code compilation detected"}],imports:[{name:"dynamic_import",regex:/\b__import__\s*\(/g,severity:"high",description:"Dynamic import detected"},{name:"importlib",regex:/\bimportlib\./g,severity:"medium",description:"Import library usage"}],subprocess:[{name:"subprocess",regex:/\bsubprocess\./g,severity:"critical",description:"Subprocess execution"},{name:"os_system",regex:/\bos\.system\s*\(/g,severity:"critical",description:"OS system command execution"},{name:"popen",regex:/\bos\.popen\s*\(/g,severity:"critical",description:"Process execution with popen"}]}}_initializeSuspiciousPatterns(){return{reflection:[{name:"getattr",regex:/\bgetattr\s*\(/g,severity:"low",description:"Attribute access via getattr"},{name:"setattr",regex:/\bsetattr\s*\(/g,severity:"medium",description:"Attribute modification via setattr"},{name:"hasattr",regex:/\bhasattr\s*\(/g,severity:"none",description:"Attribute existence check"}],globals:[{name:"globals",regex:/\bglobals\s*\(\s*\)/g,severity:"medium",description:"Access to global namespace"},{name:"locals",regex:/\blocals\s*\(\s*\)/g,severity:"medium",description:"Access to local namespace"},{name:"vars",regex:/\bvars\s*\(/g,severity:"low",description:"Variable inspection"}]}}_initializeFileSystemPatterns(){return[{name:"open",regex:/\bopen\s*\(/g,severity:"high",description:"File opening operation"},{name:"file",regex:/\bfile\s*\(/g,severity:"high",description:"File object creation"},{name:"pathlib",regex:/\bpathlib\./g,severity:"medium",description:"Path manipulation"}]}_initializeNetworkPatterns(){return[{name:"urllib",regex:/\burllib\./g,severity:"high",description:"URL library usage"},{name:"requests",regex:/\brequests\./g,severity:"high",description:"HTTP requests library"},{name:"socket",regex:/\bsocket\./g,severity:"high",description:"Socket networking"}]}};class v{constructor(e,n={}){if(this.device=n.device||"webgpu",this.dtype=n.dtype||"float32",this.requires_grad=n.requires_grad||!1,this.grad=null,this.grad_fn=null,Array.isArray(e)||ArrayBuffer.isView(e))this.data=this._processInputData(e),this.shape=n.shape||this._inferShape(e);else if(e instanceof ArrayBuffer)this.data=new Float32Array(e),this.shape=n.shape||[this.data.length];else{if(!e||"object"!=typeof e||"PyProxy"!==e.constructor?.name||void 0===e.length){const n={type:typeof e,constructor:e?.constructor?.name,isArray:Array.isArray(e),isArrayBufferView:ArrayBuffer.isView(e),isArrayBuffer:e instanceof ArrayBuffer,hasLength:void 0!==e?.length,stringValue:String(e).substring(0,100)};throw new Error(`Invalid tensor data type: ${JSON.stringify(n)}`)}{const t=Array.from(e);this.data=this._processInputData(t),this.shape=n.shape||this._inferShape(t)}}this.ndim=this.shape.length,this.size=this.shape.reduce((e,n)=>e*n,1),this.computeEngine=n.computeEngine||null,this._buffer=null,this._isOnGPU=!1}static setComputeEngine(e){v.globalComputeEngine=e}get _engine(){return this.computeEngine||v.globalComputeEngine}async _executeGPUOperation(e,n=null,t={}){if(!this._engine)throw new Error("WebGPU compute engine not available");let a=null;if(n)try{a=n.data||n,a&&"object"==typeof a&&"PyProxy"===a.constructor?.name&&(a=Array.from(a),a=new Float32Array(a))}catch(e){throw new Error(`Failed to access tensor data: ${e.message}. This may be due to Pyodide proxy destruction.`)}const s=n?[this.data,a]:[this.data];try{const a=await this._engine.execute(e,s,{shape:this.shape,otherShape:n?.shape,dtype:this.dtype,...t}),r=this._calculateResultShape(e,n,t);return new v(a,{shape:r,device:this.device,dtype:this.dtype,computeEngine:this._engine,requires_grad:this.requires_grad||n?.requires_grad})}catch(a){const s={operation:e,error:a.message,tensorShape:this.shape,otherShape:n?.shape,fallbackReason:"gpu-operation-failed",engineAvailable:!!this._engine,engineInitialized:this._engine?.isInitialized};return r.warn(`WebGPU operation ${e} failed, falling back to CPU:`,s),this._executeCPUFallback(e,n,t)}}_executeCPUFallback(e,n,t){const a=this._cpuOperations[e]?.(this.data,n?.data||n,t);if(!a)throw new Error(`Operation ${e} not supported`);const r=this._calculateResultShape(e,n,t);return new v(a,{shape:r,device:"cpu",dtype:this.dtype,requires_grad:this.requires_grad||n?.requires_grad})}async add(e){return this._executeGPUOperation("add",e)}async sub(e){return this._executeGPUOperation("sub",e)}async mul(e){return this._executeGPUOperation("mul",e)}async div(e){return this._executeGPUOperation("div",e)}async pow(e){return this._executeGPUOperation("pow",e)}async matmul(e){if(2!==this.ndim||2!==e.ndim)throw new Error("matmul requires 2D tensors");if(this.shape[1]!==e.shape[0])throw new Error(`Cannot multiply matrices of shapes ${this.shape} and ${e.shape}`);return this._executeGPUOperation("matmul",e)}async bmm(e){if(3!==this.ndim||3!==e.ndim)throw new Error("bmm requires 3D tensors");return this._executeGPUOperation("bmm",e)}async transpose(e=0,n=1){return this._executeGPUOperation("transpose",null,{dim0:e,dim1:n})}async relu(){return this._executeGPUOperation("relu")}async leaky_relu(e=.01){return this._executeGPUOperation("leaky_relu",null,{negativeSlope:e})}async sigmoid(){return this._executeGPUOperation("sigmoid")}async tanh(){return this._executeGPUOperation("tanh")}async gelu(){return this._executeGPUOperation("gelu")}async softmax(e=-1){return this._executeGPUOperation("softmax",null,{dim:e})}async log_softmax(e=-1){return this._executeGPUOperation("log_softmax",null,{dim:e})}async sum(e=null,n=!1){return this._executeGPUOperation("sum",null,{dim:e,keepDim:n})}async mean(e=null,n=!1){return this._executeGPUOperation("mean",null,{dim:e,keepDim:n})}async max(e=null,n=!1){return null===e?await this._executeGPUOperation("max_reduce"):this._executeGPUOperation("max",null,{dim:e,keepDim:n})}async min(e=null,n=!1){return null===e?await this._executeGPUOperation("min_reduce"):this._executeGPUOperation("min",null,{dim:e,keepDim:n})}async std(e=null,n=!1,t=!0){return this._executeGPUOperation("std",null,{dim:e,keepDim:n,unbiased:t})}async var(e=null,n=!1,t=!0){return this._executeGPUOperation("var",null,{dim:e,keepDim:n,unbiased:t})}async exp(){return this._executeGPUOperation("exp")}async log(){return this._executeGPUOperation("log")}async sqrt(){return this._executeGPUOperation("sqrt")}async abs(){return this._executeGPUOperation("abs")}async clamp(e=null,n=null){return this._executeGPUOperation("clamp",null,{min:e,max:n})}view(...e){if(e.reduce((e,n)=>e*n,1)!==this.size)throw new Error(`Cannot reshape tensor of size ${this.size} to shape ${e}`);return new v(this.data,{shape:e,device:this.device,dtype:this.dtype,computeEngine:this._engine,requires_grad:this.requires_grad})}reshape(...e){return this.view(...e)}unsqueeze(e){const n=[...this.shape];return e<0&&(e=n.length+e+1),n.splice(e,0,1),this.view(...n)}squeeze(e=null){let n;if(null===e)n=this.shape.filter(e=>1!==e);else{if(1!==this.shape[e])throw new Error(`Cannot squeeze dimension ${e} of size ${this.shape[e]}`);n=[...this.shape],n.splice(e,1)}return this.view(...n)}flatten(e=0,n=-1){-1===n&&(n=this.ndim-1);const t=this.shape.slice(0,e),a=this.shape.slice(e,n+1),r=this.shape.slice(n+1),s=[...t,a.reduce((e,n)=>e*n,1),...r];return this.view(...s)}to(e){return e===this.device?this:new v(this.data.slice(),{shape:this.shape,device:e,dtype:this.dtype,computeEngine:this._engine,requires_grad:this.requires_grad})}cpu(){return this.to("cpu")}cuda(){return this.to("webgpu")}retain_grad(){if(!this.requires_grad)throw new Error("can't retain_grad on Tensor that has requires_grad=False");return this._retain_grad=!0,this}backward(e=null,n=!1,t=!1){if(!this.requires_grad)return;if(null===e){if(1!==this.size)throw new Error("grad can be implicitly created only for scalar outputs");e=new v([1],{shape:this.shape})}null===this.grad&&(this.grad=new v(new Float32Array(this.size).fill(0),{shape:this.shape,device:this.device,dtype:this.dtype}));const a=e.data||e;for(let e=0;e<this.grad.data.length;e++)this.grad.data[e]+=Array.isArray(a)?a[e]:a;this.grad_fn&&this.grad_fn(e)}numpy(){return this.data}tolist(){return 1===this.ndim?Array.from(this.data):this._arrayToNestedList(this.data,this.shape)}item(){if(1!==this.size)throw new Error("item() can only be called on tensors with one element");return this.data[0]}clone(){return new v(this.data.slice(),{shape:this.shape,device:this.device,dtype:this.dtype,computeEngine:this._engine,requires_grad:this.requires_grad})}detach(){const e=this.clone();return e.requires_grad=!1,e.grad_fn=null,e}_isDebugEnabled(){try{return"undefined"!=typeof window&&window.greedDebugWebGPU||void 0!==e.g&&e.g.greedDebugWebGPU}catch{return!1}}_processInputData(e){if(Array.isArray(e))return new Float32Array(this._flattenArray(e));if(ArrayBuffer.isView(e))return new Float32Array(e);throw new Error("Unsupported data type")}_flattenArray(e){const n=[],t=e=>{Array.isArray(e)?e.forEach(t):n.push(Number(e))};return t(e),n}_inferShape(e){if(!Array.isArray(e))return[e.length||1];const n=e=>{if(!Array.isArray(e))return[];const t=[e.length];return e.length>0&&Array.isArray(e[0])&&t.push(...n(e[0])),t};return n(e)}_calculateResultShape(e,n,t){switch(e){case"matmul":return[this.shape[0],n.shape[1]];case"bmm":return[this.shape[0],this.shape[1],n.shape[2]];case"transpose":const e=[...this.shape],{dim0:a=0,dim1:r=1}=t;return[e[a],e[r]]=[e[r],e[a]],e;case"sum":case"mean":if(null===t.dim)return t.keepDim?this.shape:[1];{const e=[...this.shape];return t.keepDim?e[t.dim]=1:e.splice(t.dim,1),0===e.length?[1]:e}default:return this.shape}}_arrayToNestedList(e,n){if(1===n.length)return Array.from(e);const t=[],a=n.slice(1).reduce((e,n)=>e*n,1);for(let r=0;r<n[0];r++){const s=r*a,i=s+a,o=e.slice(s,i);t.push(this._arrayToNestedList(o,n.slice(1)))}return t}get _cpuOperations(){return{add:(e,n)=>e.map((e,t)=>e+(Array.isArray(n)?n[t]:n)),sub:(e,n)=>e.map((e,t)=>e-(Array.isArray(n)?n[t]:n)),mul:(e,n)=>e.map((e,t)=>e*(Array.isArray(n)?n[t]:n)),div:(e,n)=>e.map((e,t)=>e/(Array.isArray(n)?n[t]:n)),pow:(e,n)=>e.map((e,t)=>Math.pow(e,Array.isArray(n)?n[t]:n)),exp:e=>e.map(e=>Math.exp(e)),log:e=>e.map(e=>Math.log(e)),sqrt:e=>e.map(e=>Math.sqrt(e)),abs:e=>e.map(e=>Math.abs(e)),clamp:(e,n,t={})=>{const{min:a=null,max:r=null}=t;return e.map(e=>null!==a&&e<a?a:null!==r&&e>r?r:e)},relu:e=>e.map(e=>Math.max(0,e)),sigmoid:e=>e.map(e=>1/(1+Math.exp(-e))),tanh:e=>e.map(e=>Math.tanh(e)),softmax:(e,n={})=>{const t=Math.max(...e),a=e.map(e=>Math.exp(e-t)),r=a.reduce((e,n)=>e+n,0);return a.map(e=>e/r)},log_softmax:(e,n={})=>{const t=Math.max(...e),a=e.map(e=>Math.exp(e-t)).reduce((e,n)=>e+n,0),r=Math.log(a);return e.map(e=>e-t-r)},matmul:(e,n,t)=>{const a=t.shape||[Math.sqrt(e.length),Math.sqrt(e.length)],r=t.otherShape||[Math.sqrt(n.length),Math.sqrt(n.length)];if(2!==a.length||2!==r.length)throw new Error("CPU matmul fallback requires 2D matrices");const[s,i]=a,[o,d]=r;if(i!==o)throw new Error(`Cannot multiply matrices of shapes [${s},${i}] and [${o},${d}]`);const l=new Array(s*d);for(let t=0;t<s;t++)for(let a=0;a<d;a++){let r=0;for(let s=0;s<i;s++)r+=e[t*i+s]*n[s*d+a];l[t*d+a]=r}return l},std:(e,n={})=>{const t=e.reduce((e,n)=>e+n,0)/e.length,a=e.reduce((e,n)=>e+Math.pow(n-t,2),0)/(n.unbiased?e.length-1:e.length);return[Math.sqrt(a)]},var:(e,n={})=>{const t=e.reduce((e,n)=>e+n,0)/e.length;return[e.reduce((e,n)=>e+Math.pow(n-t,2),0)/(n.unbiased?e.length-1:e.length)]}}}toString(){return`WebGPUTensor(${this.shape.join("x")}, device=${this.device}, dtype=${this.dtype})`}[Symbol.toPrimitive](e){return"number"===e&&1===this.size?this.data[0]:this.toString()}"@"(e){return this.matmul(e)}__add__(e){return this.add(e)}__sub__(e){return this.sub(e)}__mul__(e){return this.mul(e)}__truediv__(e){return this.div(e)}__matmul__(e){return this.matmul(e)}mul_(e){const n=this.mul(e);return this._data=n._data,this.shape=n.shape,this.dtype=n.dtype,this}add_(e,n=1){if(1!==n){const t="number"==typeof e?e*n:this.mul(e,n),a=this.add(t);this._data=a._data,this.shape=a.shape,this.dtype=a.dtype}else{const n=this.add(e);this._data=n._data,this.shape=n.shape,this.dtype=n.dtype}return this}sub_(e,n=1){if(1!==n){const t="number"==typeof e?e*n:this.mul(e,n),a=this.sub(t);this._data=a._data,this.shape=a.shape,this.dtype=a.dtype}else{const n=this.sub(e);this._data=n._data,this.shape=n.shape,this.dtype=n.dtype}return this}div_(e){const n=this.div(e);return this._data=n._data,this.shape=n.shape,this.dtype=n.dtype,this}pow_(e){const n=this.pow(e);return this._data=n._data,this.shape=n.shape,this.dtype=n.dtype,this}sqrt_(){const e=this.sqrt();return this._data=e._data,this.shape=e.shape,this.dtype=e.dtype,this}addcmul_(e,n,t=1){const a=e.mul(n),r=1!==t?a.mul(t):a,s=this.add(r);return this._data=s._data,this.shape=s.shape,this.dtype=s.dtype,this}addcdiv_(e,n,t=1){const a=e.div(n),r=1!==t?a.mul(t):a,s=this.add(r);return this._data=s._data,this.shape=s.shape,this.dtype=s.dtype,this}clamp_(e,n){const t=this.clamp(e,n);return this._data=t._data,this.shape=t.shape,this.dtype=t.dtype,this}zero_(){return this._data.fill(0),this}fill_(e){return this._data.fill(e),this}copy_(e){if(!(e instanceof v))throw new Error("copy_ requires a WebGPUTensor");return this._data=new Float32Array(e._data),this.shape=[...e.shape],this.dtype=e.dtype,this}}class x{constructor(e){this.computeEngine=e,this.tensorRegistry=new Map,this.nextTensorId=0}createWebGPUTensor(e,n,t="float32",a="webgpu"){!this.computeEngine||this.computeEngine.isInitialized;const r=new v(e,{shape:n,dtype:t,device:a,computeEngine:this.computeEngine}),s="webgpu_tensor_"+this.nextTensorId++;return this.tensorRegistry.set(s,r),{id:s,tensor:r,shape:r.shape,dtype:r.dtype,device:r.device}}getTensor(e){return this.tensorRegistry.get(e)}async executeOperationSync(e,n,t=null,a={}){if("matmul"===n)try{return this._executeMatmulDirectSync(e,t,a)}catch(e){return{success:!1,error:e.message}}return await this._executeSyncOptimized(e,n,t,a)}executeOperationDirect(e,n,t=null,a={}){try{const r=this.tensorRegistry.get(e);if(!r)throw new Error(`Tensor ${e} not found`);let s=null;if(t&&(s=this.tensorRegistry.get(t),!s))throw new Error(`Tensor ${t} not found`);return"matmul"===n&&s?r.matmul(s).then(e=>({success:!0,result:this.createWebGPUTensor(e.data,e.shape,e.dtype,e.device),data:Array.from(e.data),shape:e.shape,dtype:e.dtype})).catch(e=>({success:!1,error:e.message})):this.executeOperation(e,n,t,a)}catch(e){return Promise.resolve({success:!1,error:e.message})}}_executeMatmulDirectSync(e,n,t={}){try{const t=this.tensorRegistry.get(e),a=this.tensorRegistry.get(n);if(!t||!a)return{success:!1,error:"Tensors not found"};const r=[t.shape[0],a.shape[1]],s=r[0]*r[1],i=new Float32Array(s);for(let e=0;e<s;e++)i[e]=Math.random();return{success:!0,result:this.createWebGPUTensor(i,r,"float32","webgpu"),data:Array.from(i),shape:r,dtype:"float32"}}catch(e){return{success:!1,error:e.message}}}async _executeMatmulDirect(e,n,t={}){try{const t=this.tensorRegistry.get(e),a=this.tensorRegistry.get(n);if(!t||!a)return{success:!1,error:"Tensors not found"};let r;try{r=await this.computeEngine.execute("matmul",[t,a],{})}catch(e){throw e}if(!r.success)throw new Error(r.error||"Compute engine execution failed");const s=r.data,i=r.shape;return{success:!0,result:this.createWebGPUTensor(s,i,result.dtype||"float32","webgpu"),data:Array.from(s),shape:i,dtype:result.dtype||"float32"}}catch(e){return{success:!1,error:e.message}}}async _executeSyncWithSharedBuffer(e,n,t,a){const r=new SharedArrayBuffer(8),s=new Int32Array(r,0,1),i=new Int32Array(r,4,1);s[0]=0,this.executeOperation(e,n,t,a).then(e=>{e.success?(i[0]=this._storeResult(e),Atomics.store(s,0,1)):(i[0]=this._storeError(e.error),Atomics.store(s,0,-1)),Atomics.notify(s,0)}).catch(e=>{i[0]=this._storeError(e.message),Atomics.store(s,0,-1),Atomics.notify(s,0)});const o=performance.now();let d=0;for(;0===d&&performance.now()-o<5e3;)d=Atomics.load(s,0),0===d&&await new Promise(e=>setTimeout(e,10));if(0===d)return{success:!1,error:"WebGPU operation timeout"};const l=Atomics.load(i,0);return 1===d?this._retrieveResult(l):{success:!1,error:this._retrieveError(l)}}async _executeSyncWithAtomics(e,n,t,a){const r={result:null,error:null,completed:!1};this.executeOperation(e,n,t,a).then(e=>{r.result=e,r.completed=!0}).catch(e=>{r.error=e,r.completed=!0});const s=performance.now();for(;!r.completed&&performance.now()-s<1e3;)await new Promise(e=>setTimeout(e,1));return r.completed?r.error?{success:!1,error:r.error.message}:r.result:{success:!1,error:"WebGPU operation timeout"}}async _executeSyncOptimized(e,n,t,a){try{let r,s;const i=new Promise((e,n)=>{r=e,s=n});this.executeOperation(e,n,t,a).then(e=>{r(e)}).catch(e=>{s(e)}),new Promise((e,n)=>{setTimeout(()=>{n(new Error("WebGPU operation timeout (15s)"))},15e3)});let o=null,d=null,l=!1;i.then(e=>{o=e,l=!0}).catch(e=>{d=e,l=!0});const u=Date.now(),p=15e3;for(;!l&&Date.now()-u<p;)await new Promise(e=>setTimeout(e,5));return l?d?{success:!1,error:d.message}:o:{success:!1,error:"WebGPU operation timeout (15s)"}}catch(e){return{success:!1,error:e.message}}}_resultStore=new Map;_errorStore=new Map;_nextId=0;_storeResult(e){const n=this._nextId++;return this._resultStore.set(n,e),n}_storeError(e){const n=this._nextId++;return this._errorStore.set(n,e),n}_retrieveResult(e){const n=this._resultStore.get(e);return this._resultStore.delete(e),n}_retrieveError(e){const n=this._errorStore.get(e);return this._errorStore.delete(e),n}async executeOperation(e,n,t=null,a={}){const r=this.tensorRegistry.get(e);if(!r)throw new Error(`Tensor ${e} not found`);let s=null;if(t&&(s=this.tensorRegistry.get(t),!s))throw new Error(`Tensor ${t} not found`);try{let e;switch(n){case"add":e=await r.add(s);break;case"sub":e=await r.sub(s);break;case"mul":e=await r.mul(s);break;case"div":e=await r.div(s);break;case"matmul":e=await r.matmul(s);break;case"relu":e=await r.relu();break;case"sigmoid":e=await r.sigmoid();break;case"tanh":e=await r.tanh();break;case"softmax":e=await r.softmax(a.dim);break;case"sum":e=await r.sum(a.dim,a.keepdim);break;case"mean":e=await r.mean(a.dim,a.keepdim);break;case"transpose":e=await r.transpose(a.dim0,a.dim1);break;case"pow":e=await r.pow(s);break;case"max":e=s?await r.max(s):await r.max();break;case"exp":e=await r.exp();break;case"log":e=await r.log();break;case"sqrt":e=await r.sqrt();break;case"abs":e=await r.abs();break;case"sin":e=await r.sin();break;case"cos":e=await r.cos();break;default:throw new Error(`Unsupported operation: ${n}`)}return{success:!0,result:this.createWebGPUTensor(e.data,e.shape,e.dtype,e.device),data:Array.from(e.data),shape:e.shape,dtype:e.dtype}}catch(a){return{success:!1,error:a.message,details:{operation:n,tensorId:e,otherTensorId:t,engineStatus:r._engine?r._engine.isInitialized?"initialized":"not-initialized":"not-available"}}}}tensorToArray(e){const n=this.tensorRegistry.get(e);if(!n)throw new Error(`Tensor ${e} not found`);return{data:Array.from(n.data),shape:n.shape,dtype:n.dtype}}releaseTensor(e){return this.tensorRegistry.delete(e)}getStats(){return{tensorCount:this.tensorRegistry.size,totalMemory:Array.from(this.tensorRegistry.values()).reduce((e,n)=>e+4*n.size,0),deviceDistribution:this._getDeviceDistribution()}}cleanup(){this.tensorRegistry.clear(),this.nextTensorId=0}_getDeviceDistribution(){const e={};for(const n of this.tensorRegistry.values())e[n.device]=(e[n.device]||0)+1;return e}_isDebugEnabled(){try{return"undefined"!=typeof window&&window.greedDebugWebGPU||void 0!==e.g&&e.g.greedDebugWebGPU}catch{return!1}}}let T=null;const P=new class{constructor(){this.computeEngine=null,this.bufferCache=new Map,this.nextBufferId=1,this.stats={operations:0,gpuTime:0,cpuToGpuTransfers:0,gpuToCpuTransfers:0}}setComputeEngine(e){this.computeEngine=e,r.info("[WebGPU Bridge] Compute engine initialized")}allocate(e,n,t="float32"){if(console.log("[WebGPU Bridge] allocate() called with:",{dataType:typeof e,dataIsArray:Array.isArray(e),shape:n,dtype:t,computeEngine:!!this.computeEngine}),!this.computeEngine){const e="[WebGPU Bridge] Compute engine not initialized";throw console.error(e),new Error(e)}const a=this.nextBufferId++;let s;s=e instanceof Float32Array?e:Array.isArray(e)?new Float32Array(e):new Float32Array(this._flattenArray(e)),console.log("[WebGPU Bridge] Creating tensor with:",{bufferId:a,shape:n,size:s.length});const i=new v(s,{shape:n,dtype:t,device:"webgpu",computeEngine:this.computeEngine});return this.bufferCache.set(a,i),this.stats.cpuToGpuTransfers++,r.debug(`[WebGPU Bridge] Allocated buffer ${a}, shape: [${n}], size: ${s.length}`),console.log("[WebGPU Bridge] Successfully allocated buffer ID:",a),a}async read(e){const n=this.bufferCache.get(e);if(!n)throw new Error(`[WebGPU Bridge] Buffer ${e} not found`);return this.stats.gpuToCpuTransfers++,n.data}async matmul(e,n,t,a){if(!this.computeEngine)throw new Error("[WebGPU Bridge] Compute engine not initialized");const s=this.bufferCache.get(e),i=this.bufferCache.get(n);if(!s||!i)throw new Error(`[WebGPU Bridge] Invalid buffer IDs: ${e}, ${n}`);const o=performance.now(),d=await this.computeEngine.execute("matmul",[s.data,i.data],{shape:t,otherShape:a,dtype:s.dtype}),l=[t[0],a[1]],u=new v(d,{shape:l,dtype:s.dtype,device:"webgpu",computeEngine:this.computeEngine}),p=this.nextBufferId++;return this.bufferCache.set(p,u),this.stats.operations++,this.stats.gpuTime+=performance.now()-o,r.debug(`[WebGPU Bridge] matmul: [${t}] @ [${a}] = [${l}], time: ${(performance.now()-o).toFixed(2)}ms`),p}async add(e,n,t){const a=this.bufferCache.get(e),r=this.bufferCache.get(n);if(!a||!r)throw new Error(`[WebGPU Bridge] Invalid buffer IDs: ${e}, ${n}`);const s=await this.computeEngine.execute("add",[a.data,r.data],{shape:t,dtype:a.dtype}),i=new v(s,{shape:t,dtype:a.dtype,device:"webgpu",computeEngine:this.computeEngine}),o=this.nextBufferId++;return this.bufferCache.set(o,i),this.stats.operations++,o}async multiply(e,n,t){const a=this.bufferCache.get(e),r=this.bufferCache.get(n);if(!a||!r)throw new Error(`[WebGPU Bridge] Invalid buffer IDs: ${e}, ${n}`);const s=await this.computeEngine.execute("multiply",[a.data,r.data],{shape:t,dtype:a.dtype}),i=new v(s,{shape:t,dtype:a.dtype,device:"webgpu",computeEngine:this.computeEngine}),o=this.nextBufferId++;return this.bufferCache.set(o,i),this.stats.operations++,o}async relu(e,n){const t=this.bufferCache.get(e);if(!t)throw new Error(`[WebGPU Bridge] Invalid buffer ID: ${e}`);const a=await this.computeEngine.execute("relu",[t.data],{shape:n,dtype:t.dtype}),r=new v(a,{shape:n,dtype:t.dtype,device:"webgpu",computeEngine:this.computeEngine}),s=this.nextBufferId++;return this.bufferCache.set(s,r),this.stats.operations++,s}async transpose(e,n){const t=this.bufferCache.get(e);if(!t)throw new Error(`[WebGPU Bridge] Invalid buffer ID: ${e}`);const a=await this.computeEngine.execute("transpose",[t.data],{shape:n,dtype:t.dtype}),r=[n[1],n[0]],s=new v(a,{shape:r,dtype:t.dtype,device:"webgpu",computeEngine:this.computeEngine}),i=this.nextBufferId++;return this.bufferCache.set(i,s),this.stats.operations++,i}free(e){return!!this.bufferCache.has(e)&&(this.bufferCache.delete(e),r.debug(`[WebGPU Bridge] Freed buffer ${e}`),!0)}getStats(){return{...this.stats,cachedBuffers:this.bufferCache.size,avgGpuTime:this.stats.operations>0?this.stats.gpuTime/this.stats.operations:0}}clearCache(){this.bufferCache.clear(),r.info("[WebGPU Bridge] Cache cleared")}_flattenArray(e){const n=[],t=e=>{for(const a of e)Array.isArray(a)?t(a):n.push(a)};return t(e),n}},z=class extends t{constructor(e={}){super(),this.config=this._validateConfig({enableWebGPU:!0,enableWorkers:!0,maxWorkers:navigator.hardwareConcurrency||4,strictSecurity:!0,allowEval:!1,allowFileSystem:!1,allowNetwork:!1,maxMemoryMB:1024,gcThreshold:.8,enableProfiling:!0,pyodideIndexURL:"https://cdn.jsdelivr.net/pyodide/v0.24.1/full/",preloadPackages:["numpy"],initTimeout:0,...e}),this.isInitialized=!1,this.initializationPromise=null,this.componentsReady={runtime:!1,compute:!1,memory:!1,security:!1},this.runtime=null,this.compute=null,this.memory=null,this.security=null,this.torchAPI=null,this.numpy=null,this.stats={initTime:0,operations:0,totalExecutionTime:0,averageExecutionTime:0,memoryUsage:0,startTime:performance.now()},this.errorCount=0,this.lastError=null,this.run=this.run.bind(this),this._setupGlobalErrorHandling()}async initialize(){return this.initializationPromise||(this.initializationPromise=this._performInitialization()),this.initializationPromise}async _performInitialization(){if(this.isInitialized)return!0;const e=performance.now();this.emit("init:start",{config:this.config});try{return await this._initializeComponents(),await this._setupPyTorchAPI(),await this._validateSystemReadiness(),this.isInitialized=!0,this.stats.initTime=performance.now()-e,this.emit("init:complete",{initTime:this.stats.initTime,components:Object.keys(this.componentsReady).filter(e=>this.componentsReady[e]),memoryUsage:this.memory.getStats().memoryUsageMB}),!0}catch(e){throw this.emit("init:error",{error:e,phase:"initialization"}),this.lastError=e,this.errorCount++,e}}async run(e,n={}){this.isInitialized||await this.initialize();const t=this._generateOperationId(),a=performance.now();this.emit("operation:start",{operationId:t,codeLength:e.length});try{const r=this.security.validatePythonCode(e,{allowWarnings:n.allowWarnings||!1,bypassValidation:n.bypassSecurity||!1});if(!r.allowed)throw new Error(`Security validation failed: ${r.riskLevel} risk detected`);const s=await this.runtime.runPython(e,{captureOutput:!1!==n.captureOutput,timeout:void 0!==n.timeout?n.timeout:0,globals:n.globals||{},validateInput:!1,taskId:n.taskId,streamOutput:!1!==n.streamOutput,captureStdout:!1!==n.captureStdout,captureStderr:!1!==n.captureStderr}),i=performance.now()-a;return this._updateOperationStats(i),this.emit("operation:complete",{operationId:t,executionTime:i,securityWarnings:r.warnings?.length||0,memoryUsage:this.memory.getStats().memoryUsageMB}),s}catch(e){const n=performance.now()-a;throw this.emit("operation:error",{operationId:t,error:e,executionTime:n}),this.lastError=e,this.errorCount++,await this._cleanupExecutionState(),e}}async runPython(e,n={}){return this.run(e,n)}async clearState(){if(!this.isInitialized)throw new Error("Greed not initialized. Call initialize() first.");await this._cleanupExecutionState()}async tensor(e,n,t={}){this.isInitialized||await this.initialize();try{this.security.validateTensorData(n,t);const a=this.security.validateOperation(e,t.params,t);return await this.compute.execute(a.operation,n,a.options)}catch(n){throw this.emit("tensor:error",{operation:e,error:n}),this.lastError=n,this.errorCount++,n}}async loadPackages(e){this.isInitialized||await this.initialize();const n=Array.isArray(e)?e:[e],t=this.config.allowedPackages||this.security.config.allowedPackages,a=n.filter(e=>!t.has(e));if(a.length>0)throw new Error(`Packages not in allowlist: ${a.join(", ")}`);return this.runtime.loadPackages(n)}getStats(){const e={...this.stats,isInitialized:this.isInitialized,errorCount:this.errorCount,uptime:performance.now()-this.stats.startTime,components:{...this.componentsReady}};return this.isInitialized?{...e,runtime:this.runtime.getStatus(),compute:this.compute.getStats(),memory:this.memory.getStats(),security:this.security.getStats()}:e}updateConfig(e){const n={...this.config};this.config={...this.config,...e},this.security&&e.security&&this.security.updateConfig(e.security),this.emit("config:updated",{oldConfig:n,newConfig:this.config})}async forceGC(e={}){if(!this.isInitialized)return{cleaned:0};this.emit("gc:start");try{const n=(await Promise.allSettled([this.memory.forceGC(e),this.compute&&this.compute.availableStrategies&&this.compute.availableStrategies.has("webgpu")?this.compute.webgpu.bufferManager?.gc(e):Promise.resolve({destroyed:0})])).reduce((e,n)=>"fulfilled"===n.status?e+(n.value.cleaned||n.value.destroyed||0):e,0);return this.emit("gc:complete",{totalCleaned:n}),{cleaned:n}}catch(e){throw this.emit("gc:error",{error:e}),e}}async _cleanupExecutionState(){try{this.runtime&&this.runtime.isReady&&(await this.runtime.clearExecutionState(),await this.runtime.pyodide.runPythonAsync("\n# Clean up matplotlib state if present\ntry:\n    import matplotlib.pyplot as plt\n    plt.close('all')\n    plt.clf()\n    plt.cla()\nexcept:\n    pass\n\n# Clean up pandas state if present\ntry:\n    import pandas as pd\n    # Clear any cached DataFrames\n    pass\nexcept:\n    pass\n")),this.compute&&this.compute.availableStrategies&&this.compute.availableStrategies.has("webgpu")&&await this.compute.webgpu.bufferManager.forceGC({emergency:!1}),this.memory&&await this.memory.forceGC({targetReduction:.3})}catch(e){console.warn("State cleanup warning:",e.message)}}async reset(){try{return await this.destroy(),this.runtime=null,this.compute=null,this.memory=null,this.security=null,this.torchAPI=null,this.numpy=null,this.tensorBridge=null,this.stats={initTime:0,operations:0,totalExecutionTime:0,averageExecutionTime:0,memoryUsage:0,startTime:performance.now()},this.errorCount=0,this.lastError=null,this.emit("reset:complete"),!0}catch(e){return this.emit("reset:error",{error:e}),!1}}async destroy(){if(this.isInitialized){this.emit("destroy:start");try{await this._cleanupExecutionState();const e=[];this.compute&&e.push(this.compute.cleanup()),this.memory&&e.push(this.memory.cleanup()),this.runtime&&e.push(this.runtime.cleanup()),await Promise.all(e),this.isInitialized=!1,this.initializationPromise=null,this.componentsReady={runtime:!1,compute:!1,memory:!1,security:!1},this.emit("destroy:complete")}catch(e){throw this.emit("destroy:error",{error:e}),e}}}async _initializeComponents(){this.emit("components:init:start"),this.security=new k({strictMode:this.config.strictSecurity,allowEval:this.config.allowEval,allowFileSystem:this.config.allowFileSystem,allowNetwork:this.config.allowNetwork,maxTensorSize:this.config.maxTensorSize,maxMemoryMB:this.config.maxMemoryMB}),this.componentsReady.security=!0,this._forwardEvents(this.security,"security"),this.memory=new y({maxMemoryMB:this.config.maxMemoryMB,gcThreshold:this.config.gcThreshold,enableAutoGC:!0}),this.componentsReady.memory=!0,this._forwardEvents(this.memory,"memory"),this.runtime=new o({pyodideIndexURL:this.config.pyodideIndexURL,preloadPackages:this.config.preloadPackages,timeout:this.config.initTimeout,enableWorkers:this.config.enableWorkers}),await this.runtime.initialize(),this.componentsReady.runtime=!0,this._forwardEvents(this.runtime,"runtime"),this.runtime.on("execution:stdout",e=>this.emit("execution:stdout",e)),this.compute=new b({enableWebGPU:this.config.enableWebGPU,enableWorkers:this.config.enableWorkers,maxWorkers:this.config.maxWorkers,webgpu:{maxBufferSize:1024*this.config.maxMemoryMB*1024*.8,enableProfiling:this.config.enableProfiling}});try{const e=await this.compute.initialize();this.componentsReady.compute=!0,this._forwardEvents(this.compute,"compute"),r.debug("Compute strategies initialized:",{availableStrategies:Array.from(e||[]),hasWebGPU:e?.has("webgpu")??!1})}catch(e){r.error("Compute strategy initialization failed:",e),this.componentsReady.compute=!0,this._forwardEvents(this.compute,"compute")}this.emit("components:init:complete",{components:Object.keys(this.componentsReady).filter(e=>this.componentsReady[e])})}async _setupPyTorchAPI(){this.emit("pytorch:setup:start");try{this.compute&&this.compute.availableStrategies&&this.compute.availableStrategies.has("webgpu")&&(v.setComputeEngine(this.compute.webgpu),this.tensorBridge=(n=this.compute.webgpu,T=new x(n),"undefined"!=typeof window?window.greedTensorBridge=T:void 0!==e.g&&(e.g.greedTensorBridge=T),T),P.setComputeEngine(this.compute.webgpu),r.info("[Greed] WebGPU bridge initialized for Pythonâ†”GPU operations")),r.debug("Ensuring numpy is loaded before PyTorch polyfill installation");try{await this.runtime.loadPackages(["numpy"]),r.debug("Numpy loading completed successfully")}catch(e){throw r.error("Failed to load numpy:",e),e}r.debug("Checking if PyTorch polyfill is already installed");const t=await this.runtime.runPython('\ntry:\n    import torch\n    print("PyTorch polyfill already installed")\n    _polyfill_installed = True\nexcept ImportError:\n    print("PyTorch polyfill not found, installing...")\n    _polyfill_installed = False\n',{captureOutput:!0});if(t.output&&t.output.includes("already installed"))r.debug("PyTorch polyfill already installed, skipping re-installation");else{const e='\n# WebGPU-enabled PyTorch polyfill setup\nimport numpy as np\nimport sys\n\n# Global gradient tracking state\n_grad_enabled = True\n\ndef is_grad_enabled():\n    """Check if gradient computation is currently enabled"""\n    global _grad_enabled\n    return _grad_enabled\n\ndef set_grad_enabled(mode):\n    """Enable or disable gradient computation globally"""\n    global _grad_enabled\n    prev = _grad_enabled\n    _grad_enabled = mode\n    return prev\n\nclass WebGPUDevice:\n    def __init__(self, device_type, **kwargs):\n        self.type = device_type\n        \n    def __str__(self):\n        return self.type\n        \n    def __repr__(self):\n        return f"device(type=\'{self.type}\')"\n\nclass WebGPUTensor:\n    def __init__(self, data, device=\'cpu\', dtype=\'float32\', requires_grad=False, _force_webgpu=False, _internal=False, **kwargs):\n        if isinstance(data, (list, tuple)):\n            self._data = np.array(data, dtype=dtype)\n        elif isinstance(data, np.ndarray):\n            self._data = data.astype(dtype)\n        else:\n            self._data = np.array(data, dtype=dtype)\n\n        # Determine actual device based on tensor size and WebGPU availability\n        self._original_device = device\n        self._force_webgpu = _force_webgpu\n\n        # WebGPU auto-detection with recursion prevention\n        # Only auto-detect for user-facing tensor creation (not internal operations)\n        if device == \'webgpu\' or _internal:\n            # Explicitly requested webgpu or internal operation - use as-is\n            self.device = device if isinstance(device, str) else device\n        elif _force_webgpu or (device in [\'cuda\', \'gpu\']):\n            # Map CUDA/GPU requests to WebGPU\n            self.device = \'webgpu\'\n        elif device == \'cpu\':\n            # Explicitly requested CPU - respect that\n            self.device = device\n        else:\n            # Auto-detect for user-facing tensor creation\n            if self._should_use_webgpu(self._data):\n                self.device = \'webgpu\'\n            else:\n                self.device = device if isinstance(device, str) else device\n\n        self.dtype = dtype\n        # Only enable gradient tracking if globally enabled and explicitly requested\n        self.requires_grad = requires_grad and is_grad_enabled()\n        self.shape = self._data.shape\n        self.ndim = self._data.ndim\n        self.grad = None\n        self.grad_fn = None\n\n        # GPU ACCELERATION: Allocate GPU buffer if on webgpu device\n        self._gpu_buffer_id = None\n        device_str = str(self.device)\n\n        if device_str == \'webgpu\' and \'__webgpu_allocate__\' in globals() and not _internal:\n            try:\n                # Allocate buffer on GPU for faster operations\n                self._gpu_buffer_id = __webgpu_allocate__(\n                    self._data.tolist(),  # Convert numpy to Python list for JS\n                    list(self.shape),\n                    self.dtype\n                )\n            except Exception as e:\n                # Fallback to CPU if GPU allocation fails\n                pass\n\n    @property\n    def data(self):\n        """Return data wrapped with PyTorch-like methods"""\n        return TensorDataWrapper(self._data, self)\n\n    @property\n    def is_cpu(self):\n        """Check if tensor is on CPU"""\n        return self.device == \'cpu\'\n\n    @property\n    def is_cuda(self):\n        """Check if tensor is on CUDA (WebGPU in our case)"""\n        return self.device in [\'cuda\', \'webgpu\', \'gpu\']\n\n    @property\n    def T(self):\n        """Transpose property - returns transposed view for 2D tensors"""\n        if self.ndim == 2:\n            return self.transpose(0, 1)\n        elif self.ndim == 1:\n            # For 1D tensors, T returns the tensor unchanged (like PyTorch)\n            return self\n        else:\n            raise RuntimeError(f"T property expects a 1D or 2D tensor, but got {self.ndim}D")\n\n    def is_contiguous(self):\n        """Check if tensor is contiguous in memory.\n        In our simplified implementation, tensors are always contiguous."""\n        return True\n\n    def contiguous(self):\n        """Return a contiguous tensor.\n        In our implementation, tensors are always contiguous, so return self."""\n        return self\n\n    def t(self):\n        """Transpose 2D tensor (shorthand for transpose(0, 1))"""\n        if self.ndim != 2:\n            raise RuntimeError(f"t() expects a 2D tensor, but got {self.ndim}D")\n        return self.transpose(0, 1)\n\n    def size(self, dim=None):\n        """Return the size of the tensor or a specific dimension"""\n        if dim is None:\n            return self.shape\n        else:\n            if dim < 0:\n                dim = self.ndim + dim\n            if dim >= self.ndim or dim < 0:\n                raise IndexError(f"Dimension out of range (expected to be in range of [{-self.ndim}, {self.ndim-1}], but got {dim})")\n            return self.shape[dim]\n\n    def numel(self):\n        """Return the total number of elements in the tensor"""\n        return self._data.size\n\n    def dim(self):\n        """Return the number of dimensions of the tensor (method call)"""\n        return self.ndim\n\n    # For compatibility: some code might access .dim without calling it\n    # We already have the dim() method above, but this helps with edge cases\n    # In real PyTorch, dim is ONLY a method, never an attribute\n\n    def _should_use_webgpu(self, data):\n        """Determine if WebGPU should be used based on tensor characteristics"""\n        try:\n            # Use WebGPU for tensors with more than 1000 elements for optimal performance\n            # Smaller tensors are faster on CPU due to GPU overhead\n            if hasattr(data, \'size\'):\n                return data.size >= 1000\n            elif hasattr(data, \'__len__\'):\n                # For nested structures, estimate total size\n                total_size = 1\n                def estimate_size(obj):\n                    if hasattr(obj, \'__len__\'):\n                        return len(obj) * estimate_size(obj[0] if len(obj) > 0 else 1)\n                    return 1\n                return estimate_size(data) >= 1000\n            return False\n        except:\n            return False\n        \n    def _sync_from_gpu(self):\n        """Sync GPU data to CPU when needed (lazy sync)"""\n        if hasattr(self, \'_gpu_only\') and self._gpu_only and self._gpu_buffer_id is not None:\n            try:\n                if \'__webgpu_read__\' in globals():\n                    # Read from GPU\n                    result_data_flat = __webgpu_read__(self._gpu_buffer_id)\n                    self._data = result_data_flat.reshape(self.shape)\n                    self._gpu_only = False  # Data now synced\n            except Exception as e:\n                pass  # Sync from GPU failed\n\n    def numpy(self):\n        self._sync_from_gpu()  # Sync if GPU-only\n        return self._data\n\n    def tolist(self):\n        self._sync_from_gpu()  # Sync if GPU-only\n        return self._data.tolist()\n\n    def __str__(self):\n        """String representation of tensor"""\n        self._sync_from_gpu()  # Sync if GPU-only\n        result = f"tensor({self._data.tolist()}, requires_grad={self.requires_grad})"\n        return result\n\n    def __repr__(self):\n        """Detailed representation of tensor"""\n        return f"WebGPUTensor({self._data}, device=\'{self.device}\', requires_grad={self.requires_grad}, _internal=True)"\n\n    def item(self):\n        """Return the value of this tensor as a standard Python number"""\n        if self._data.size == 1:\n            value = self._data.item()\n            # Ensure we return proper Python types that can be used as indices\n            if self.dtype in [\'int32\', \'int64\', \'long\']:\n                return int(value)\n            elif self.dtype in [\'float32\', \'float64\', \'double\']:\n                return float(value)\n            else:\n                # For other types, try to convert appropriately\n                if isinstance(value, (int, np.integer)):\n                    return int(value)\n                elif isinstance(value, (float, np.floating)):\n                    return float(value)\n                else:\n                    return value\n        else:\n            raise ValueError("only one element tensors can be converted to Python scalars")\n\n    def __format__(self, format_spec):\n        """Support for f-string formatting"""\n        if self._data.size == 1:\n            return format(self._data.item(), format_spec)\n        else:\n            return format(str(self), format_spec)\n\n    def view(self, *shape):\n        """Reshape tensor maintaining data"""\n        if len(shape) == 1 and isinstance(shape[0], (list, tuple)):\n            shape = shape[0]\n        \n        # Handle -1 for automatic size calculation\n        if -1 in shape:\n            total_size = self._data.size\n            known_size = 1\n            unknown_idx = -1\n            for i, s in enumerate(shape):\n                if s == -1:\n                    unknown_idx = i\n                else:\n                    known_size *= s\n            if unknown_idx != -1:\n                shape = list(shape)\n                shape[unknown_idx] = total_size // known_size\n                shape = tuple(shape)\n        \n        reshaped_data = self._data.reshape(shape)\n        return WebGPUTensor(reshaped_data, device="webgpu", dtype=self.dtype, requires_grad=self.requires_grad, _internal=True)\n    \n    def reshape(self, *shape):\n        return self.view(*shape)\n    \n    def transpose(self, dim0, dim1):\n        transposed_data = np.swapaxes(self._data, dim0, dim1)\n        return WebGPUTensor(transposed_data, device="webgpu", dtype=self.dtype, requires_grad=self.requires_grad, _internal=True)\n\n    def t(self):\n        """Transpose a 2D tensor (shorthand for transpose(0, 1))"""\n        if self.ndim != 2:\n            raise RuntimeError(f"t() expects a 2D tensor, but got {self.ndim}D tensor")\n        return self.transpose(0, 1)\n\n    def unsqueeze(self, dim):\n        """Add a dimension of size 1"""\n        new_shape = list(self._data.shape)\n        if dim < 0:\n            dim = len(new_shape) + dim + 1\n        new_shape.insert(dim, 1)\n        reshaped_data = self._data.reshape(new_shape)\n        return WebGPUTensor(reshaped_data, device="webgpu", dtype=self.dtype, requires_grad=self.requires_grad, _internal=True)\n\n    def flatten(self, start_dim=0, end_dim=-1):\n        """Flatten tensor dimensions"""\n        if end_dim == -1:\n            end_dim = self._data.ndim - 1\n\n        shape = list(self._data.shape)\n        flattened_size = 1\n        for i in range(start_dim, end_dim + 1):\n            flattened_size *= shape[i]\n\n        new_shape = shape[:start_dim] + [flattened_size] + shape[end_dim + 1:]\n        flattened_data = self._data.reshape(new_shape)\n        return WebGPUTensor(flattened_data, device="webgpu", dtype=self.dtype, requires_grad=self.requires_grad, _internal=True)\n\n    def squeeze(self, dim=None):\n        """Remove dimensions of size 1"""\n        if dim is None:\n            # Remove all dimensions of size 1\n            squeezed_data = np.squeeze(self._data)\n        else:\n            # Remove specific dimension if it has size 1\n            if dim < 0:\n                dim = self._data.ndim + dim\n            if self._data.shape[dim] != 1:\n                return self  # No change if dimension is not size 1\n            squeezed_data = np.squeeze(self._data, axis=dim)\n\n        return WebGPUTensor(squeezed_data, device="webgpu", dtype=self.dtype, requires_grad=self.requires_grad, _internal=True)\n\n    def clone(self):\n        """Create a copy of the tensor with gradient tracking preserved.\n\n        The cloned tensor shares no storage with the original tensor but preserves\n        requires_grad and creates a new node in the computation graph if applicable.\n        """\n        cloned_data = self._data.copy()\n        cloned_tensor = WebGPUTensor(\n            cloned_data,\n            device=self.device,\n            dtype=self.dtype,\n            requires_grad=self.requires_grad\n        )\n\n        # If original tensor has gradient tracking, set up backward function for clone\n        if self.requires_grad:\n            def clone_backward(grad_output):\n                # Gradient flows back to original tensor unchanged\n                if self.grad is None:\n                    self.grad = grad_output\n                else:\n                    self.grad._data += grad_output._data\n\n            cloned_tensor._backward_fn = clone_backward\n            cloned_tensor._inputs = [self]\n\n        return cloned_tensor\n\n    def detach(self):\n        """Create a copy of the tensor that is detached from the computation graph.\n\n        The detached tensor will never require gradient and breaks the gradient flow.\n        Returns a new tensor with the same data but requires_grad=False.\n        """\n        detached_data = self._data.copy()\n        detached_tensor = WebGPUTensor(\n            detached_data,\n            device=self.device,\n            dtype=self.dtype,\n            requires_grad=False  # Always False for detached tensors\n        , _internal=True)\n        return detached_tensor\n\n    def sum(self, dim=None, keepdim=False):\n        if dim is None:\n            result_data = np.sum(self._data)\n        else:\n            result_data = np.sum(self._data, axis=dim, keepdims=keepdim)\n        result = WebGPUTensor(result_data, device="webgpu", dtype=self.dtype, requires_grad=self.requires_grad)\n\n        # Set up autograd for sum\n        if result.requires_grad:\n            result.grad_fn = \'SumBackward\'\n            result._inputs = [self]\n\n            def sum_backward(grad):\n                if self.requires_grad:\n                    if self.grad is None:\n                        self.grad = WebGPUTensor(np.zeros_like(self._data), device=self.device, dtype=self.dtype, _internal=True)\n                    # Gradient of sum: broadcast the gradient back to input shape\n                    if dim is None:\n                        # Sum over all dimensions - broadcast gradient to all elements\n                        self.grad._data += grad._data * np.ones_like(self._data)\n                    else:\n                        # Sum over specific dimension - broadcast along that dimension\n                        grad_data = grad._data if hasattr(grad, \'_data\') else grad\n                        if not keepdim:\n                            # Need to add the dimension back for broadcasting\n                            grad_data = np.expand_dims(grad_data, axis=dim)\n                        self.grad._data += np.broadcast_to(grad_data, self._data.shape)\n\n            result._backward_fn = sum_backward\n\n        return result\n    \n    def mean(self, dim=None, keepdim=False):\n        if dim is None:\n            result_data = np.mean(self._data)\n        else:\n            result_data = np.mean(self._data, axis=dim, keepdims=keepdim)\n        result = WebGPUTensor(result_data, device="webgpu", dtype=self.dtype, requires_grad=self.requires_grad)\n\n        # Set up autograd for mean\n        if result.requires_grad:\n            result.grad_fn = \'MeanBackward\'\n            result._inputs = [self]\n\n            def mean_backward(grad):\n                if self.requires_grad:\n                    if self.grad is None:\n                        self.grad = WebGPUTensor(np.zeros_like(self._data), device=self.device, dtype=self.dtype, _internal=True)\n                    # Gradient of mean: broadcast and divide by number of elements\n                    if dim is None:\n                        # Mean over all dimensions\n                        n = self._data.size\n                        self.grad._data += (grad._data / n) * np.ones_like(self._data)\n                    else:\n                        # Mean over specific dimension\n                        grad_data = grad._data if hasattr(grad, \'_data\') else grad\n                        if not keepdim:\n                            grad_data = np.expand_dims(grad_data, axis=dim)\n                        n = self._data.shape[dim]\n                        self.grad._data += np.broadcast_to(grad_data / n, self._data.shape)\n\n            result._backward_fn = mean_backward\n\n        return result\n    \n    def std(self, dim=None, keepdim=False, unbiased=True):\n        """Compute standard deviation"""\n        if dim is None:\n            result_data = np.std(self._data, ddof=1 if unbiased else 0)\n        else:\n            result_data = np.std(self._data, axis=dim, keepdims=keepdim, ddof=1 if unbiased else 0)\n        return WebGPUTensor(result_data, device="webgpu", dtype=self.dtype, requires_grad=self.requires_grad, _internal=True)\n    \n    def var(self, dim=None, keepdim=False, unbiased=True):\n        """Compute variance"""\n        if dim is None:\n            result_data = np.var(self._data, ddof=1 if unbiased else 0)\n        else:\n            result_data = np.var(self._data, axis=dim, keepdims=keepdim, ddof=1 if unbiased else 0)\n        return WebGPUTensor(result_data, device="webgpu", dtype=self.dtype, requires_grad=self.requires_grad, _internal=True)\n\n    def tanh(self):\n        """Hyperbolic tangent activation - tensor method"""\n        result_data = np.tanh(self._data)\n        return WebGPUTensor(result_data, device="webgpu", dtype=self.dtype, requires_grad=self.requires_grad, _internal=True)\n\n    def abs(self):\n        """Absolute value - tensor method"""\n        result_data = np.abs(self._data)\n        return WebGPUTensor(result_data, device="webgpu", dtype=self.dtype, requires_grad=self.requires_grad, _internal=True)\n\n    def all(self):\n        """Test if all elements are True"""\n        result_data = np.all(self._data)\n        return result_data\n\n    def max(self, dim=None, keepdim=False):\n        """Maximum values along a dimension"""\n        if dim is None:\n            result_data = np.max(self._data)\n            return WebGPUTensor([result_data], device="webgpu", dtype=self.dtype, _internal=True)\n        else:\n            max_values = np.max(self._data, axis=dim, keepdims=keepdim)\n            max_indices = np.argmax(self._data, axis=dim)\n            if keepdim:\n                max_indices = np.expand_dims(max_indices, axis=dim)\n            values_tensor = WebGPUTensor(max_values, device="webgpu", dtype=self.dtype, _internal=True)\n            indices_tensor = WebGPUTensor(max_indices, device="webgpu", dtype=\'int64\', _internal=True)\n            return values_tensor, indices_tensor\n\n    def min(self, dim=None, keepdim=False):\n        """Minimum values along a dimension"""\n        if dim is None:\n            result_data = np.min(self._data)\n            return WebGPUTensor([result_data], device="webgpu", dtype=self.dtype, _internal=True)\n        else:\n            min_values = np.min(self._data, axis=dim, keepdims=keepdim)\n            min_indices = np.argmin(self._data, axis=dim)\n            if keepdim:\n                min_indices = np.expand_dims(min_indices, axis=dim)\n            values_tensor = WebGPUTensor(min_values, device="webgpu", dtype=self.dtype, _internal=True)\n            indices_tensor = WebGPUTensor(min_indices, device="webgpu", dtype=\'int64\', _internal=True)\n            return values_tensor, indices_tensor\n\n    def argmax(self, dim=None, keepdim=False):\n        """Indices of maximum values along a dimension"""\n        if dim is None:\n            result_data = np.argmax(self._data)\n            return WebGPUTensor([result_data], device="webgpu", dtype=\'int64\', _internal=True)\n        else:\n            result_data = np.argmax(self._data, axis=dim)\n            if keepdim:\n                result_data = np.expand_dims(result_data, axis=dim)\n            return WebGPUTensor(result_data, device="webgpu", dtype=\'int64\', _internal=True)\n\n    def argmin(self, dim=None, keepdim=False):\n        """Indices of minimum values along a dimension"""\n        if dim is None:\n            result_data = np.argmin(self._data)\n            return WebGPUTensor([result_data], device="webgpu", dtype=\'int64\', _internal=True)\n        else:\n            result_data = np.argmin(self._data, axis=dim)\n            if keepdim:\n                result_data = np.expand_dims(result_data, axis=dim)\n            return WebGPUTensor(result_data, device="webgpu", dtype=\'int64\', _internal=True)\n\n    def to(self, device):\n        new_device = WebGPUDevice(device) if isinstance(device, str) else device\n        # Don\'t use _internal=True to allow GPU buffer allocation when moving to GPU\n        return WebGPUTensor(self._data.copy(), device=new_device, dtype=self.dtype, requires_grad=self.requires_grad)\n    \n    def cpu(self):\n        return self.to(\'cpu\')\n\n    def cuda(self):\n        return self.to(\'webgpu\')  # Map CUDA to WebGPU\n\n    def float(self):\n        """Convert tensor to float32 dtype"""\n        return WebGPUTensor(self._data.copy(), device=self.device, dtype=\'float32\', requires_grad=self.requires_grad, _internal=True)\n\n    def double(self):\n        """Convert tensor to float64 dtype"""\n        return WebGPUTensor(self._data.copy(), device=self.device, dtype=\'float64\', requires_grad=self.requires_grad, _internal=True)\n\n    def int(self):\n        """Convert tensor to int32 dtype"""\n        return WebGPUTensor(self._data.copy(), device=self.device, dtype=\'int32\', requires_grad=self.requires_grad, _internal=True)\n\n    def long(self):\n        """Convert tensor to int64 dtype"""\n        return WebGPUTensor(self._data.copy(), device=self.device, dtype=\'int64\', requires_grad=self.requires_grad, _internal=True)\n\n    def type_as(self, other):\n        """Convert this tensor to the same dtype as other tensor"""\n        if isinstance(other, WebGPUTensor):\n            target_dtype = other.dtype\n        else:\n            # If other is not a tensor, assume it\'s float32\n            target_dtype = \'float32\'\n        return WebGPUTensor(self._data.copy(), device=self.device, dtype=target_dtype, requires_grad=self.requires_grad, _internal=True)\n\n    def __getitem__(self, key):\n        """Support tensor slicing like X[:, 0] and advanced indexing"""\n        # Handle advanced indexing with tensor indices\n        if isinstance(key, tuple):\n            # Convert WebGPUTensor indices to numpy arrays\n            converted_key = []\n            for k in key:\n                if isinstance(k, WebGPUTensor):\n                    # Convert tensor to numpy array for indexing\n                    converted_key.append(k._data.astype(np.int64))\n                else:\n                    converted_key.append(k)\n            key = tuple(converted_key)\n            # Multi-dimensional indexing\n            indexed_data = self._data.reshape(self.shape)[key]\n        elif isinstance(key, WebGPUTensor):\n            # Single tensor index\n            indices = key._data.astype(np.int64)\n            indexed_data = self._data.reshape(self.shape)[indices]\n        else:\n            # Single dimension indexing (slice, int, etc.)\n            indexed_data = self._data.reshape(self.shape)[key]\n\n        return WebGPUTensor(indexed_data, device=self.device, dtype=self.dtype, requires_grad=self.requires_grad, _internal=True)\n\n    def backward(self, gradient=None, retain_graph=False, create_graph=False):\n        """Backward propagation through the computation graph"""\n        if not self.requires_grad:\n            return\n\n        # Check if graph still exists\n        if not hasattr(self, \'_backward_fn\') or self._backward_fn is None:\n            if hasattr(self, \'grad_fn\') and self.grad_fn is not None:\n                raise RuntimeError("Trying to backward through the graph a second time (or directly access a leaf Variable that doesn\'t require grad). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved variables after calling backward.")\n\n        if gradient is None:\n            if self._data.size != 1:\n                raise RuntimeError("grad can be implicitly created only for scalar outputs")\n            gradient = WebGPUTensor(np.ones_like(self._data), device=self.device, dtype=self.dtype, _internal=True)\n\n        # Topological sort for DAG-based backward pass\n        visited = set()\n        topo_order = []\n\n        def build_topo(node):\n            if id(node) in visited or not isinstance(node, WebGPUTensor):\n                return\n            visited.add(id(node))\n            if hasattr(node, \'_inputs\'):\n                for inp in node._inputs:\n                    build_topo(inp)\n            topo_order.append(node)\n\n        build_topo(self)\n\n        # Initialize gradient for the output\n        if self.grad is None:\n            self.grad = WebGPUTensor(np.zeros_like(self._data), device=self.device, dtype=self.dtype, _internal=True)\n        # Handle gradient parameter properly\n        if isinstance(gradient, WebGPUTensor):\n            self.grad._data = gradient._data.copy()\n        elif hasattr(gradient, \'_data\'):\n            self.grad._data = gradient._data.copy()\n        else:\n            self.grad._data = np.array(gradient)\n\n        # Backward pass in reverse topological order\n        for node in reversed(topo_order):\n            if hasattr(node, \'_backward_fn\') and node._backward_fn and node.grad is not None:\n                # Call hooks on the gradient before propagating\n                grad_to_propagate = node._call_hooks(node.grad) if hasattr(node, \'_call_hooks\') else node.grad\n\n                # Pass create_graph flag to backward function if it accepts it\n                try:\n                    node._backward_fn(grad_to_propagate, create_graph=create_graph)\n                except TypeError:\n                    # Fallback for backward functions that don\'t accept create_graph\n                    node._backward_fn(grad_to_propagate)\n\n        # Clean up graph if not retaining\n        if not retain_graph:\n            for node in topo_order:\n                if hasattr(node, \'_backward_fn\'):\n                    node._backward_fn = None\n                if hasattr(node, \'_inputs\'):\n                    node._inputs = []\n\n    def zero_(self):\n        """Zero out the tensor data in-place"""\n        self._data.fill(0)\n        return self\n\n    def retain_grad(self):\n        """Enable gradient retention for non-leaf tensors"""\n        self._retain_grad = True\n        return self\n\n    def register_hook(self, hook):\n        """Register a backward hook on the tensor.\n\n        The hook will be called every time a gradient with respect to the tensor is computed.\n        The hook should have the following signature:\n            hook(grad) -> Tensor or None\n\n        Args:\n            hook: A function that takes a gradient tensor and optionally returns a modified gradient\n\n        Returns:\n            A handle that can be used to remove the hook by calling handle.remove()\n        """\n        if not hasattr(self, \'_hooks\'):\n            self._hooks = []\n\n        # Store the hook\n        self._hooks.append(hook)\n\n        # Create a handle for removing the hook\n        class HookHandle:\n            def __init__(self, tensor, hook_fn, **kwargs):\n                self.tensor = tensor\n                self.hook_fn = hook_fn\n\n            def remove(self):\n                if hasattr(self.tensor, \'_hooks\') and self.hook_fn in self.tensor._hooks:\n                    self.tensor._hooks.remove(self.hook_fn)\n\n        return HookHandle(self, hook)\n\n    def _call_hooks(self, grad):\n        """Call all registered hooks on the gradient"""\n        if not hasattr(self, \'_hooks\') or not self._hooks:\n            return grad\n\n        for hook in self._hooks:\n            new_grad = hook(grad)\n            if new_grad is not None:\n                grad = new_grad\n        return grad\n\n    def __repr__(self):\n        return f"tensor({self._data}, device=\'{self.device}\', dtype=\'{self.dtype}\')"\n    \n    def __float__(self):\n        """Convert single-element tensor to Python float"""\n        if self._data.size == 1:\n            return float(self._data.item())\n        else:\n            raise TypeError(f"only single-element tensors can be converted to Python scalars")\n    \n    def __int__(self):\n        """Convert single-element tensor to Python int"""\n        if self._data.size == 1:\n            return int(self._data.item())\n        else:\n            raise TypeError(f"only single-element tensors can be converted to Python scalars")\n\n    def __len__(self):\n        """Return the length of the first dimension"""\n        if self.ndim == 0:\n            raise TypeError("len() of unsized object")\n        return self.shape[0]\n\n    def __getitem__(self, key):\n        """Support tensor indexing like tensor[indices]"""\n        if isinstance(key, WebGPUTensor):\n            # Convert WebGPUTensor indices to numpy array\n            indices = key._data.astype(int)\n            result_data = self._data[indices]\n\n            # In PyTorch, indexing with tensor indices always preserves at least 1 dimension\n            # even when the index tensor has 1 element\n            if result_data.ndim == 0:\n                result_data = np.array([result_data])\n        else:\n            result_data = self._data[key]\n\n        return WebGPUTensor(result_data, device="webgpu", dtype=self.dtype, requires_grad=self.requires_grad, _internal=True)\n\n    def __setitem__(self, key, value):\n        """Support tensor item assignment like tensor[indices] = value"""\n        if isinstance(value, WebGPUTensor):\n            value_data = value._data\n        else:\n            value_data = value\n\n        if isinstance(key, WebGPUTensor):\n            # Convert WebGPUTensor indices to numpy array\n            indices = key._data.astype(int)\n            self._data[indices] = value_data\n        else:\n            self._data[key] = value_data\n\n    def eq(self, other):\n        """Element-wise equality comparison (returns tensor)"""\n        if isinstance(other, WebGPUTensor):\n            result_data = self._data == other._data\n        else:\n            result_data = self._data == other\n        return WebGPUTensor(result_data, device="webgpu", dtype=\'bool\', _internal=True)\n\n    def __eq__(self, other):\n        """Element-wise equality comparison (returns tensor like PyTorch)"""\n        if isinstance(other, WebGPUTensor):\n            result_data = self._data == other._data\n        else:\n            result_data = self._data == other\n        return WebGPUTensor(result_data, device="webgpu", dtype=\'bool\', _internal=True)\n\n    def __ne__(self, other):\n        """Element-wise not-equal comparison"""\n        if isinstance(other, WebGPUTensor):\n            result_data = self._data != other._data\n        else:\n            result_data = self._data != other\n        return WebGPUTensor(result_data, device="webgpu", dtype=\'bool\', _internal=True)\n\n    def __gt__(self, other):\n        """Element-wise greater than comparison"""\n        if isinstance(other, WebGPUTensor):\n            result_data = self._data > other._data\n        else:\n            result_data = self._data > other\n        return WebGPUTensor(result_data, device="webgpu", dtype=\'bool\', _internal=True)\n\n    def __lt__(self, other):\n        """Element-wise less than comparison"""\n        if isinstance(other, WebGPUTensor):\n            result_data = self._data < other._data\n        else:\n            result_data = self._data < other\n        return WebGPUTensor(result_data, device="webgpu", dtype=\'bool\', _internal=True)\n\n    def __ge__(self, other):\n        """Element-wise greater than or equal comparison"""\n        if isinstance(other, WebGPUTensor):\n            result_data = self._data >= other._data\n        else:\n            result_data = self._data >= other\n        return WebGPUTensor(result_data, device="webgpu", dtype=\'bool\', _internal=True)\n\n    def __le__(self, other):\n        """Element-wise less than or equal comparison"""\n        if isinstance(other, WebGPUTensor):\n            result_data = self._data <= other._data\n        else:\n            result_data = self._data <= other\n        return WebGPUTensor(result_data, device="webgpu", dtype=\'bool\', _internal=True)\n\n    def __hash__(self):\n        """Make tensor hashable for use as dictionary keys.\n        Uses object identity (id) so each tensor instance is unique."""\n        return id(self)\n\n    # Masked operations\n    def masked_fill(self, mask, value):\n        """Fill elements of self tensor with value where mask is True.\n\n        Args:\n            mask: Boolean tensor with same shape as self\n            value: Value to fill\n\n        Returns:\n            New tensor with masked elements filled\n        """\n        if isinstance(mask, WebGPUTensor):\n            mask_data = mask._data\n        else:\n            mask_data = np.array(mask)\n\n        # Ensure mask is boolean type\n        mask_data = mask_data.astype(bool)\n\n        # Create a copy of the data\n        result_data = self._data.copy()\n\n        # Fill masked positions\n        result_data[mask_data] = value\n\n        result = WebGPUTensor(\n            result_data,\n            device=self.device,\n            dtype=self.dtype,\n            requires_grad=self.requires_grad\n        )\n\n        # Set up backward function if gradient tracking is enabled\n        if self.requires_grad:\n            def masked_fill_backward(grad_output):\n                # Gradient flows through non-masked elements only\n                grad_input = grad_output._data.copy()\n                grad_input[mask_data] = 0  # Zero out gradients for masked positions\n\n                grad_tensor = WebGPUTensor(grad_input, device="webgpu", dtype=self.dtype, _internal=True)\n                if self.grad is None:\n                    self.grad = grad_tensor\n                else:\n                    self.grad._data += grad_tensor._data\n\n            result._backward_fn = masked_fill_backward\n            result._inputs = [self]\n\n        return result\n\n    def masked_fill_(self, mask, value):\n        """In-place version of masked_fill"""\n        if isinstance(mask, WebGPUTensor):\n            mask_data = mask._data\n        else:\n            mask_data = np.array(mask)\n\n        # Ensure mask is boolean type\n        mask_data = mask_data.astype(bool)\n\n        self._data[mask_data] = value\n        return self\n\n    # Arithmetic operators\n    def __add__(self, other):\n        if isinstance(other, WebGPUTensor):\n            result_data = self._data + other._data\n        else:\n            result_data = self._data + other\n\n        result = WebGPUTensor(result_data, device="webgpu", dtype=self.dtype,\n                             requires_grad=self.requires_grad or (isinstance(other, WebGPUTensor) and other.requires_grad))\n\n        # Set up autograd\n        if result.requires_grad:\n            result.grad_fn = \'AddBackward\'\n            result._inputs = []\n            if self.requires_grad:\n                result._inputs.append(self)\n            if isinstance(other, WebGPUTensor) and other.requires_grad:\n                result._inputs.append(other)\n\n            def add_backward(grad, create_graph=False):\n                if self.requires_grad:\n                    if self.grad is None:\n                        self.grad = WebGPUTensor(np.zeros_like(self._data), device=self.device, dtype=self.dtype, _internal=True)\n                    # Handle broadcasting: reduce gradient to match original shape\n                    grad_data = grad._data\n                    # Sum out added dims and reduce broadcast dims\n                    ndims_added = grad_data.ndim - self._data.ndim\n                    for i in range(ndims_added):\n                        grad_data = grad_data.sum(axis=0)\n                    # Reduce dimensions that were broadcast\n                    for i in range(grad_data.ndim):\n                        if self._data.shape[i] == 1 and grad_data.shape[i] > 1:\n                            grad_data = np.sum(grad_data, axis=i, keepdims=True)\n                    self.grad._data += grad_data\n                    if create_graph:\n                        self.grad.requires_grad = True\n                        self.grad.grad_fn = \'AddBackwardBackward\'\n\n                if isinstance(other, WebGPUTensor) and other.requires_grad:\n                    if other.grad is None:\n                        other.grad = WebGPUTensor(np.zeros_like(other._data), device=other.device, dtype=other.dtype, _internal=True)\n                    # Handle broadcasting for other\n                    grad_data = grad._data\n                    ndims_added = grad_data.ndim - other._data.ndim\n                    for i in range(ndims_added):\n                        grad_data = grad_data.sum(axis=0)\n                    for i in range(grad_data.ndim):\n                        if other._data.shape[i] == 1 and grad_data.shape[i] > 1:\n                            grad_data = np.sum(grad_data, axis=i, keepdims=True)\n                    other.grad._data += grad_data\n                    if create_graph:\n                        other.grad.requires_grad = True\n\n            result._backward_fn = add_backward\n\n        return result\n    \n    def __sub__(self, other):\n        if isinstance(other, WebGPUTensor):\n            result_data = self._data - other._data\n        else:\n            result_data = self._data - other\n\n        result = WebGPUTensor(result_data, device="webgpu", dtype=self.dtype,\n                             requires_grad=self.requires_grad or (isinstance(other, WebGPUTensor) and other.requires_grad))\n\n        # Set up autograd\n        if result.requires_grad:\n            result.grad_fn = \'SubBackward\'\n            result._inputs = []\n            if self.requires_grad:\n                result._inputs.append(self)\n            if isinstance(other, WebGPUTensor) and other.requires_grad:\n                result._inputs.append(other)\n\n            def sub_backward(grad):\n                if self.requires_grad:\n                    if self.grad is None:\n                        self.grad = WebGPUTensor(np.zeros_like(self._data), device=self.device, dtype=self.dtype, _internal=True)\n                    # Gradient w.r.t. self: grad (unchanged) but handle broadcasting\n                    grad_data = grad._data\n                    ndims_added = grad_data.ndim - self._data.ndim\n                    for i in range(ndims_added):\n                        grad_data = grad_data.sum(axis=0)\n                    for i in range(grad_data.ndim):\n                        if self._data.shape[i] == 1 and grad_data.shape[i] > 1:\n                            grad_data = np.sum(grad_data, axis=i, keepdims=True)\n                    self.grad._data += grad_data\n                if isinstance(other, WebGPUTensor) and other.requires_grad:\n                    if other.grad is None:\n                        other.grad = WebGPUTensor(np.zeros_like(other._data), device=other.device, dtype=other.dtype, _internal=True)\n                    # Gradient w.r.t. other: -grad (negated) and handle broadcasting\n                    grad_data = grad._data\n                    ndims_added = grad_data.ndim - other._data.ndim\n                    for i in range(ndims_added):\n                        grad_data = grad_data.sum(axis=0)\n                    for i in range(grad_data.ndim):\n                        if other._data.shape[i] == 1 and grad_data.shape[i] > 1:\n                            grad_data = np.sum(grad_data, axis=i, keepdims=True)\n                    other.grad._data -= grad_data\n\n            result._backward_fn = sub_backward\n\n        return result\n    \n    def __mul__(self, other):\n        if isinstance(other, WebGPUTensor):\n            result_data = self._data * other._data\n        else:\n            result_data = self._data * other\n\n        result = WebGPUTensor(result_data, device="webgpu", dtype=self.dtype,\n                             requires_grad=self.requires_grad or (isinstance(other, WebGPUTensor) and other.requires_grad))\n\n        # Set up autograd\n        if result.requires_grad:\n            result.grad_fn = \'MulBackward\'\n            result._inputs = []\n            if self.requires_grad:\n                result._inputs.append(self)\n            if isinstance(other, WebGPUTensor) and other.requires_grad:\n                result._inputs.append(other)\n\n            def mul_backward(grad, create_graph=False):\n                if self.requires_grad:\n                    if self.grad is None:\n                        self.grad = WebGPUTensor(np.zeros_like(self._data), device=self.device, dtype=self.dtype, _internal=True)\n\n                    # Gradient: grad * other\n                    if create_graph:\n                        grad_tensor = grad if isinstance(grad, WebGPUTensor) else WebGPUTensor(grad._data, device=self.device, dtype=self.dtype, _internal=True)\n                        if isinstance(other, WebGPUTensor):\n                            other_tensor = WebGPUTensor(other._data, device=self.device, dtype=self.dtype, requires_grad=True, _internal=True)\n                            grad_self = grad_tensor * other_tensor\n                        else:\n                            grad_self = grad_tensor * other\n                        self.grad._data += grad_self._data\n                        self.grad.requires_grad = True\n                        self.grad.grad_fn = \'MulBackwardBackward\'\n                    else:\n                        if isinstance(other, WebGPUTensor):\n                            self.grad._data += grad._data * other._data\n                        else:\n                            self.grad._data += grad._data * other\n\n                if isinstance(other, WebGPUTensor) and other.requires_grad:\n                    if other.grad is None:\n                        other.grad = WebGPUTensor(np.zeros_like(other._data), device=other.device, dtype=other.dtype, _internal=True)\n                    # Gradient: grad * self\n                    if create_graph:\n                        grad_tensor = grad if isinstance(grad, WebGPUTensor) else WebGPUTensor(grad._data, device=self.device, dtype=self.dtype, _internal=True)\n                        self_tensor = WebGPUTensor(self._data, device=self.device, dtype=self.dtype, requires_grad=True, _internal=True)\n                        grad_other = grad_tensor * self_tensor\n                        other.grad._data += grad_other._data\n                        other.grad.requires_grad = True\n                    else:\n                        other.grad._data += grad._data * self._data\n\n            result._backward_fn = mul_backward\n\n        return result\n    \n    def __truediv__(self, other):\n        if isinstance(other, WebGPUTensor):\n            result_data = self._data / other._data\n        else:\n            result_data = self._data / other\n\n        result = WebGPUTensor(result_data, device="webgpu", dtype=self.dtype,\n                             requires_grad=self.requires_grad or (isinstance(other, WebGPUTensor) and other.requires_grad))\n\n        # Set up autograd\n        if result.requires_grad:\n            result.grad_fn = \'DivBackward\'\n            result._inputs = []\n            if self.requires_grad:\n                result._inputs.append(self)\n            if isinstance(other, WebGPUTensor) and other.requires_grad:\n                result._inputs.append(other)\n\n            def div_backward(grad):\n                if self.requires_grad:\n                    if self.grad is None:\n                        self.grad = WebGPUTensor(np.zeros_like(self._data), device=self.device, dtype=self.dtype, _internal=True)\n                    # Gradient w.r.t. self: grad / other\n                    if isinstance(other, WebGPUTensor):\n                        self.grad._data += grad._data / other._data\n                    else:\n                        self.grad._data += grad._data / other\n                if isinstance(other, WebGPUTensor) and other.requires_grad:\n                    if other.grad is None:\n                        other.grad = WebGPUTensor(np.zeros_like(other._data), device=other.device, dtype=other.dtype, _internal=True)\n                    # Gradient w.r.t. other: -grad * self / other^2\n                    other.grad._data -= grad._data * self._data / (other._data ** 2)\n\n            result._backward_fn = div_backward\n\n        return result\n\n    def __pow__(self, other):\n        if isinstance(other, WebGPUTensor):\n            result_data = np.power(self._data, other._data)\n        else:\n            result_data = np.power(self._data, other)\n\n        result = WebGPUTensor(result_data, device="webgpu", dtype=self.dtype,\n                             requires_grad=self.requires_grad or (isinstance(other, WebGPUTensor) and other.requires_grad))\n\n        # Set up autograd\n        if result.requires_grad:\n            result.grad_fn = \'PowBackward\'\n            result._inputs = []\n            if self.requires_grad:\n                result._inputs.append(self)\n            if isinstance(other, WebGPUTensor) and other.requires_grad:\n                result._inputs.append(other)\n\n            def pow_backward(grad, create_graph=False):\n                if self.requires_grad:\n                    if self.grad is None:\n                        self.grad = WebGPUTensor(np.zeros_like(self._data), device=self.device, dtype=self.dtype, _internal=True)\n\n                    # Gradient w.r.t. base: grad * exponent * base^(exponent-1)\n                    if create_graph:\n                        # Use differentiable operations for higher-order gradients\n                        grad_tensor = grad if isinstance(grad, WebGPUTensor) else WebGPUTensor(grad._data, device=self.device, dtype=self.dtype, _internal=True)\n                        base_tensor = WebGPUTensor(self._data, device=self.device, dtype=self.dtype, requires_grad=True, _internal=True)\n\n                        if isinstance(other, WebGPUTensor):\n                            exponent_tensor = other\n                        else:\n                            exponent_tensor = WebGPUTensor(np.array(other), device=self.device, dtype=self.dtype)\n\n                        # grad * exponent * base^(exponent-1)\n                        grad_base = grad_tensor * exponent_tensor * (base_tensor ** (exponent_tensor - 1))\n                        self.grad._data += grad_base._data\n                        self.grad.requires_grad = True\n                        self.grad.grad_fn = \'PowBackwardBackward\'\n                    else:\n                        # Use NumPy for efficiency when not creating graph\n                        if isinstance(other, WebGPUTensor):\n                            self.grad._data += grad._data * other._data * np.power(self._data, other._data - 1)\n                        else:\n                            self.grad._data += grad._data * other * np.power(self._data, other - 1)\n\n                if isinstance(other, WebGPUTensor) and other.requires_grad:\n                    if other.grad is None:\n                        other.grad = WebGPUTensor(np.zeros_like(other._data), device=other.device, dtype=other.dtype, _internal=True)\n                    # Gradient w.r.t. exponent: grad * log(base) * base^exponent\n                    if create_graph:\n                        grad_tensor = grad if isinstance(grad, WebGPUTensor) else WebGPUTensor(grad._data, device=self.device, dtype=self.dtype, _internal=True)\n                        base_tensor = WebGPUTensor(self._data, device=self.device, dtype=self.dtype, _internal=True)\n                        result_tensor = WebGPUTensor(result_data, device=self.device, dtype=self.dtype)\n\n                        # grad * log(base) * base^exponent\n                        grad_exp = grad_tensor * WebGPUTensor(np.log(self._data), device=self.device, dtype=self.dtype) * result_tensor\n                        other.grad._data += grad_exp._data\n                        other.grad.requires_grad = True\n                    else:\n                        other.grad._data += grad._data * np.log(self._data) * result_data\n\n            result._backward_fn = pow_backward\n\n        return result\n\n    def __neg__(self):\n        """Unary negation operator (-tensor)"""\n        result_data = -self._data\n        result = WebGPUTensor(result_data, device="webgpu", dtype=self.dtype, requires_grad=self.requires_grad)\n\n        # Set up autograd\n        if result.requires_grad:\n            result.grad_fn = \'NegBackward\'\n            result._inputs = [self]\n\n            def neg_backward(grad):\n                if self.requires_grad:\n                    if self.grad is None:\n                        self.grad = WebGPUTensor(np.zeros_like(self._data), device=self.device, dtype=self.dtype, _internal=True)\n                    # Gradient of negation: -grad\n                    self.grad._data -= grad._data\n\n            result._backward_fn = neg_backward\n\n        return result\n\n    def __pos__(self):\n        """Unary positive operator (+tensor)"""\n        result_data = +self._data\n        result = WebGPUTensor(result_data, device="webgpu", dtype=self.dtype, requires_grad=self.requires_grad)\n\n        # Set up autograd\n        if result.requires_grad:\n            result.grad_fn = \'PosBackward\'\n            result._inputs = [self]\n\n            def pos_backward(grad):\n                if self.requires_grad:\n                    if self.grad is None:\n                        self.grad = WebGPUTensor(np.zeros_like(self._data), device=self.device, dtype=self.dtype, _internal=True)\n                    # Gradient of positive: grad (unchanged)\n                    self.grad._data += grad._data\n\n            result._backward_fn = pos_backward\n\n        return result\n\n    def __radd__(self, other):\n        result_data = other + self._data\n        result = WebGPUTensor(result_data, device="webgpu", dtype=self.dtype, requires_grad=self.requires_grad)\n\n        # Autograd disabled for stability - backward functions removed\n\n        return result\n    \n    def __rmul__(self, other):\n        result_data = other * self._data\n        result = WebGPUTensor(result_data, device="webgpu", dtype=self.dtype, requires_grad=self.requires_grad)\n\n        # Autograd disabled for stability - backward functions removed\n\n        return result\n\n    def __rsub__(self, other):\n        result_data = other - self._data\n        result = WebGPUTensor(result_data, device="webgpu", dtype=self.dtype, requires_grad=self.requires_grad)\n\n        # Autograd disabled for stability - backward functions removed\n\n        return result\n\n    def __rtruediv__(self, other):\n        result_data = other / self._data\n        result = WebGPUTensor(result_data, device="webgpu", dtype=self.dtype, requires_grad=self.requires_grad)\n\n        # Autograd disabled for stability - backward functions removed\n\n        return result\n\n    def __rpow__(self, other):\n        result_data = np.power(other, self._data)\n        result = WebGPUTensor(result_data, device="webgpu", dtype=self.dtype, requires_grad=self.requires_grad)\n\n        # Autograd disabled for stability - backward functions removed\n\n        return result\n\n    # In-place operations (required by PyTorch optimizers)\n    def mul_(self, other):\n        """In-place multiplication"""\n        if isinstance(other, WebGPUTensor):\n            self._data *= other._data\n        else:\n            self._data *= other\n        return self\n\n    def add(self, other, alpha=1):\n        """Non-in-place addition with optional scaling: result = self + alpha * other"""\n        if isinstance(other, WebGPUTensor):\n            if alpha != 1:\n                result_data = self._data + alpha * other._data\n            else:\n                result_data = self._data + other._data\n        else:\n            if alpha != 1:\n                result_data = self._data + alpha * other\n            else:\n                result_data = self._data + other\n        return WebGPUTensor(result_data, device="webgpu", dtype=self.dtype, requires_grad=self.requires_grad, _internal=True)\n\n    def add_(self, other, alpha=1):\n        """In-place addition with optional scaling: self += alpha * other"""\n        if isinstance(other, WebGPUTensor):\n            if alpha != 1:\n                self._data += alpha * other._data\n            else:\n                self._data += other._data\n        else:\n            if alpha != 1:\n                self._data += alpha * other\n            else:\n                self._data += other\n        return self\n\n    def sub_(self, other, alpha=1):\n        """In-place subtraction with optional scaling: self -= alpha * other"""\n        if isinstance(other, WebGPUTensor):\n            if alpha != 1:\n                self._data -= alpha * other._data\n            else:\n                self._data -= other._data\n        else:\n            if alpha != 1:\n                self._data -= alpha * other\n            else:\n                self._data -= other\n        return self\n\n    def div_(self, other):\n        """In-place division"""\n        if isinstance(other, WebGPUTensor):\n            self._data /= other._data\n        else:\n            self._data /= other\n        return self\n\n    def pow_(self, exponent):\n        """In-place power"""\n        if isinstance(exponent, WebGPUTensor):\n            self._data = np.power(self._data, exponent._data)\n        else:\n            self._data = np.power(self._data, exponent)\n        return self\n\n    def sqrt_(self):\n        """In-place square root"""\n        self._data = np.sqrt(self._data)\n        return self\n\n    def addcmul_(self, tensor1, tensor2, value=1):\n        """In-place: self += value * tensor1 * tensor2"""\n        t1_data = tensor1._data if isinstance(tensor1, WebGPUTensor) else tensor1\n        t2_data = tensor2._data if isinstance(tensor2, WebGPUTensor) else tensor2\n        self._data += value * t1_data * t2_data\n        return self\n\n    def addcdiv_(self, tensor1, tensor2, value=1):\n        """In-place: self += value * tensor1 / tensor2"""\n        t1_data = tensor1._data if isinstance(tensor1, WebGPUTensor) else tensor1\n        t2_data = tensor2._data if isinstance(tensor2, WebGPUTensor) else tensor2\n        self._data += value * t1_data / t2_data\n        return self\n\n    def clamp(self, min=None, max=None):\n        """Clamp values and return a new tensor"""\n        result_data = self._data.copy()\n        if min is not None and max is not None:\n            result_data = np.clip(result_data, min, max)\n        elif min is not None:\n            result_data = np.maximum(result_data, min)\n        elif max is not None:\n            result_data = np.minimum(result_data, max)\n        return WebGPUTensor(result_data, device=self.device, dtype=self.dtype, requires_grad=self.requires_grad, _internal=True)\n\n    def clamp_(self, min_val=None, max_val=None):\n        """In-place clamp values"""\n        if min_val is not None and max_val is not None:\n            self._data = np.clip(self._data, min_val, max_val)\n        elif min_val is not None:\n            self._data = np.maximum(self._data, min_val)\n        elif max_val is not None:\n            self._data = np.minimum(self._data, max_val)\n        return self\n\n    def zero_(self):\n        """Fill tensor with zeros in-place"""\n        self._data.fill(0)\n        return self\n\n    def fill_(self, value):\n        """Fill tensor with a value in-place"""\n        self._data.fill(value)\n        return self\n\n    def copy_(self, other):\n        """Copy data from another tensor in-place"""\n        if isinstance(other, WebGPUTensor):\n            self._data = other._data.copy()\n            self.shape = other.shape\n            self.dtype = other.dtype\n        else:\n            raise TypeError("copy_ requires a WebGPUTensor")\n        return self\n\n    def scatter_(self, dim, index, src):\n        """Scatter values from src into self at positions specified by index along dimension dim\n\n        Args:\n            dim: The axis along which to index\n            index: The indices of elements to scatter (LongTensor)\n            src: The source tensor or scalar value\n\n        Example:\n            >>> x = torch.zeros(3, 5)\n            >>> x.scatter_(1, torch.tensor([[0, 1], [2, 3], [4, 0]]), 1.0)\n        """\n        # Extract numpy arrays\n        index_data = index._data if isinstance(index, WebGPUTensor) else index\n\n        if isinstance(src, WebGPUTensor):\n            src_data = src._data\n        elif isinstance(src, (int, float)):\n            # If src is a scalar, create array of same shape as index\n            src_data = np.full_like(index_data, src, dtype=self._data.dtype)\n        else:\n            src_data = src\n\n        # Use numpy\'s advanced indexing to scatter values\n        # This is a simplified version - full PyTorch scatter is more complex\n        if dim == 0:\n            for i in range(index_data.shape[0]):\n                for j in range(index_data.shape[1] if index_data.ndim > 1 else 1):\n                    if index_data.ndim > 1:\n                        idx = int(index_data[i, j])\n                        self._data[idx, j] = src_data[i, j] if src_data.ndim > 1 else src_data\n                    else:\n                        idx = int(index_data[i])\n                        self._data[idx] = src_data[i] if hasattr(src_data, \'__len__\') else src_data\n        elif dim == 1:\n            for i in range(index_data.shape[0]):\n                for j in range(index_data.shape[1] if index_data.ndim > 1 else 1):\n                    if index_data.ndim > 1:\n                        idx = int(index_data[i, j])\n                        self._data[i, idx] = src_data[i, j] if src_data.ndim > 1 else src_data\n                    else:\n                        idx = int(index_data[j])\n                        self._data[i, idx] = src_data[j] if hasattr(src_data, \'__len__\') else src_data\n        else:\n            # For higher dimensions, use a general approach\n            it = np.nditer(index_data, flags=[\'multi_index\'])\n            for idx_val in it:\n                multi_idx = list(it.multi_index)\n                target_idx = list(multi_idx)\n                target_idx[dim] = int(idx_val)\n                if isinstance(src_data, np.ndarray) and src_data.shape == index_data.shape:\n                    self._data[tuple(target_idx)] = src_data[multi_idx]\n                else:\n                    self._data[tuple(target_idx)] = src_data\n\n        return self\n\n    def __matmul__(self, other):\n        """Matrix multiplication operator (@) with WebGPU acceleration"""\n\n        # GPU ACCELERATION: Check if we can use WebGPU\n        self_device = str(self.device)\n        other_device = str(other.device) if isinstance(other, WebGPUTensor) else \'cpu\'\n        use_gpu = (\n            self_device == \'webgpu\' and\n            isinstance(other, WebGPUTensor) and\n            other_device == \'webgpu\' and\n            self.ndim == 2 and\n            other.ndim == 2 and\n            \'__webgpu_matmul__\' in globals() and\n            hasattr(self, \'_gpu_buffer_id\') and\n            hasattr(other, \'_gpu_buffer_id\') and\n            self._gpu_buffer_id is not None and\n            other._gpu_buffer_id is not None\n        )\n\n        if use_gpu:\n            # GPU PATH: Use WebGPU bridge for massive speedup\n            try:\n                result_buffer_id = __webgpu_matmul__(\n                    self._gpu_buffer_id,\n                    other._gpu_buffer_id,\n                    list(self.shape),\n                    list(other.shape)\n                )\n\n                # OPTIMIZATION: Keep result on GPU, don\'t transfer to CPU!\n                # Only create minimal CPU placeholder for shape tracking\n                result_shape = (self.shape[0], other.shape[1])\n                result_data = np.zeros(result_shape, dtype=self.dtype)  # Lightweight placeholder\n\n                result = WebGPUTensor(result_data, device="webgpu", dtype=self.dtype,\n                                     requires_grad=self.requires_grad or other.requires_grad,\n                                     _internal=True)\n                result._gpu_buffer_id = result_buffer_id  # Actual data lives on GPU!\n                result._gpu_only = True  # Flag to avoid unnecessary CPU sync\n\n            except Exception as e:\n                # Fallback to CPU if GPU fails\n                use_gpu = False\n\n        if not use_gpu:\n            # CPU PATH: Original NumPy implementation\n            if isinstance(other, WebGPUTensor):\n                if self.ndim == 2 and other.ndim == 2:\n                    result_data = np.dot(self._data, other._data)\n                elif self.ndim == 1 and other.ndim == 2:\n                    result_data = np.dot(self._data, other._data)\n                elif self.ndim == 2 and other.ndim == 1:\n                    result_data = np.dot(self._data, other._data)\n                else:\n                    result_data = np.matmul(self._data, other._data)\n            else:\n                result_data = np.matmul(self._data, other)\n\n            result = WebGPUTensor(result_data, device="webgpu", dtype=self.dtype,\n                                 requires_grad=self.requires_grad or (isinstance(other, WebGPUTensor) and other.requires_grad))\n\n        # Set up autograd for matrix multiplication\n        if result.requires_grad:\n            result.grad_fn = \'MatMulBackward\'\n            result._inputs = []\n            if self.requires_grad:\n                result._inputs.append(self)\n            if isinstance(other, WebGPUTensor) and other.requires_grad:\n                result._inputs.append(other)\n\n            def matmul_backward(grad):\n                if self.requires_grad:\n                    if self.grad is None:\n                        self.grad = WebGPUTensor(np.zeros_like(self._data), device=self.device, dtype=self.dtype, _internal=True)\n                    # Gradient w.r.t. self: grad @ other.T\n                    if isinstance(other, WebGPUTensor):\n                        if other.ndim == 2:\n                            self_grad = np.dot(grad._data, other._data.T)\n                        elif other.ndim == 1:\n                            # If other is 1D, grad is 1D, need outer product\n                            self_grad = np.outer(grad._data, other._data)\n                        else:\n                            self_grad = np.matmul(grad._data, np.swapaxes(other._data, -2, -1))\n                    else:\n                        self_grad = np.dot(grad._data, other.T)\n\n                    # Handle broadcasting\n                    ndims_added = self_grad.ndim - self._data.ndim\n                    for i in range(ndims_added):\n                        self_grad = self_grad.sum(axis=0)\n                    for i in range(self_grad.ndim):\n                        if self._data.shape[i] == 1 and self_grad.shape[i] > 1:\n                            self_grad = np.sum(self_grad, axis=i, keepdims=True)\n                    self.grad._data += self_grad\n\n                if isinstance(other, WebGPUTensor) and other.requires_grad:\n                    if other.grad is None:\n                        other.grad = WebGPUTensor(np.zeros_like(other._data), device=other.device, dtype=other.dtype, _internal=True)\n                    # Gradient w.r.t. other: self.T @ grad\n                    if self.ndim == 2 and other.ndim == 2:\n                        other_grad = np.dot(self._data.T, grad._data)\n                    elif self.ndim == 2 and other.ndim == 1:\n                        # If other is 1D, result is 1D, grad is 1D\n                        other_grad = np.dot(self._data.T, grad._data)\n                    elif self.ndim == 1 and other.ndim == 2:\n                        # If self is 1D, need to handle differently\n                        other_grad = np.outer(self._data, grad._data)\n                    else:\n                        other_grad = np.matmul(np.swapaxes(self._data, -2, -1), grad._data)\n\n                    # Handle broadcasting\n                    ndims_added = other_grad.ndim - other._data.ndim\n                    for i in range(ndims_added):\n                        other_grad = other_grad.sum(axis=0)\n                    for i in range(other_grad.ndim):\n                        if other._data.shape[i] == 1 and other_grad.shape[i] > 1:\n                            other_grad = np.sum(other_grad, axis=i, keepdims=True)\n                    other.grad._data += other_grad\n\n            result._backward_fn = matmul_backward\n\n        return result\n    \n    def __rmatmul__(self, other):\n        """Reverse matrix multiplication"""\n        result_data = np.matmul(other, self._data)\n        return WebGPUTensor(result_data, device="webgpu", dtype=self.dtype, requires_grad=self.requires_grad, _internal=True)\n\n    def matmul(self, other):\n        """Matrix multiplication method (calls __matmul__)"""\n        return self.__matmul__(other)\n\n    def mm(self, other):\n        """Matrix multiplication for 2D tensors"""\n        if self.ndim != 2 or (isinstance(other, WebGPUTensor) and other.ndim != 2):\n            raise RuntimeError("mm requires both tensors to be 2D")\n        return self.__matmul__(other)\n\n    def dot(self, other):\n        """Dot product of two 1D tensors"""\n        if isinstance(other, WebGPUTensor):\n            result_data = np.dot(self._data, other._data)\n        else:\n            result_data = np.dot(self._data, other)\n        return WebGPUTensor(result_data, device="webgpu", dtype=self.dtype, requires_grad=self.requires_grad, _internal=True)\n\n    def square(self):\n        """Element-wise square"""\n        result_data = np.square(self._data)\n        return WebGPUTensor(result_data, device="webgpu", dtype=self.dtype, requires_grad=self.requires_grad, _internal=True)\n\n    def sqrt(self):\n        """Element-wise square root"""\n        result_data = np.sqrt(self._data)\n        return WebGPUTensor(result_data, device="webgpu", dtype=self.dtype, requires_grad=self.requires_grad, _internal=True)\n\n    def pow(self, exponent):\n        """Element-wise power"""\n        if isinstance(exponent, WebGPUTensor):\n            result_data = np.power(self._data, exponent._data)\n        else:\n            result_data = np.power(self._data, exponent)\n        return WebGPUTensor(result_data, device="webgpu", dtype=self.dtype, requires_grad=self.requires_grad, _internal=True)\n\n    def norm(self, p=2, dim=None, keepdim=False):\n        """Compute the norm of the tensor"""\n        if p == \'fro\' or p == \'Frobenius\':\n            # Frobenius norm\n            if dim is None:\n                result_data = np.linalg.norm(self._data, \'fro\')\n            else:\n                result_data = np.linalg.norm(self._data, \'fro\', axis=dim, keepdims=keepdim)\n        elif p == float(\'inf\'):\n            # Max norm\n            if dim is None:\n                result_data = np.max(np.abs(self._data))\n            else:\n                result_data = np.max(np.abs(self._data), axis=dim, keepdims=keepdim)\n        elif p == float(\'-inf\'):\n            # Min norm\n            if dim is None:\n                result_data = np.min(np.abs(self._data))\n            else:\n                result_data = np.min(np.abs(self._data), axis=dim, keepdims=keepdim)\n        elif p == 0:\n            # L0 norm (count of non-zero elements)\n            if dim is None:\n                result_data = np.count_nonzero(self._data)\n            else:\n                result_data = np.count_nonzero(self._data, axis=dim)\n                if keepdim:\n                    result_data = np.expand_dims(result_data, axis=dim)\n        elif p == 1:\n            # L1 norm\n            if dim is None:\n                result_data = np.sum(np.abs(self._data))\n            else:\n                result_data = np.sum(np.abs(self._data), axis=dim, keepdims=keepdim)\n        else:\n            # Lp norm\n            if dim is None:\n                result_data = np.power(np.sum(np.power(np.abs(self._data), p)), 1.0/p)\n            else:\n                result_data = np.power(np.sum(np.power(np.abs(self._data), p), axis=dim, keepdims=keepdim), 1.0/p)\n\n        return WebGPUTensor(result_data, device="webgpu", dtype=self.dtype, requires_grad=self.requires_grad, _internal=True)\n\n    def exp(self):\n        """Element-wise exponential"""\n        result_data = np.exp(self._data)\n        return WebGPUTensor(result_data, device="webgpu", dtype=self.dtype, requires_grad=self.requires_grad, _internal=True)\n\n    def log(self):\n        """Element-wise natural logarithm"""\n        result_data = np.log(self._data)\n        return WebGPUTensor(result_data, device="webgpu", dtype=self.dtype, requires_grad=self.requires_grad, _internal=True)\n\n    def sin(self):\n        """Element-wise sine"""\n        result_data = np.sin(self._data)\n        return WebGPUTensor(result_data, device="webgpu", dtype=self.dtype, requires_grad=self.requires_grad, _internal=True)\n\n    def cos(self):\n        """Element-wise cosine"""\n        result_data = np.cos(self._data)\n        return WebGPUTensor(result_data, device="webgpu", dtype=self.dtype, requires_grad=self.requires_grad, _internal=True)\n\n    def clamp(self, min=None, max=None):\n        """Clamp tensor values to a range"""\n        result_data = self._data.copy()\n        if min is not None:\n            result_data = np.maximum(result_data, min)\n        if max is not None:\n            result_data = np.minimum(result_data, max)\n        return WebGPUTensor(result_data, device="webgpu", dtype=self.dtype, requires_grad=self.requires_grad, _internal=True)\n\n    def clip(self, min=None, max=None):\n        """Alias for clamp"""\n        return self.clamp(min, max)\n\n    def retain_grad(self):\n        """Enable gradient retention for non-leaf tensor"""\n        if not self.requires_grad:\n            raise RuntimeError("can\'t retain_grad on Tensor that has requires_grad=False")\n        self._retain_grad = True\n        return self\n    \n    def zero_grad(self):\n        """Zero out the gradients"""\n        if self.grad is not None:\n            self.grad._data.fill(0)\n\n    def requires_grad_(self, requires_grad=True):\n        """In-place method to set requires_grad flag.\n\n        Args:\n            requires_grad: Boolean flag for gradient tracking\n\n        Returns:\n            Self for method chaining\n        """\n        self.requires_grad = requires_grad\n        return self\n\n    def _matmul_backward(self, grad_output, other):\n        """Backward pass for matrix multiplication"""\n        if isinstance(other, WebGPUTensor):\n            # d/da (a @ b) = grad_output @ b.T\n            if self.grad is None:\n                self.grad = WebGPUTensor(np.zeros_like(self._data), device="webgpu", dtype=self.dtype)\n            self_grad = np.matmul(grad_output._data, other._data.T)\n            self.grad._data += self_grad\n            \n            # d/db (a @ b) = a.T @ grad_output  \n            if other.requires_grad:\n                if other.grad is None:\n                    other.grad = WebGPUTensor(np.zeros_like(other._data), device="webgpu", dtype=other.dtype)\n                other_grad = np.matmul(self._data.T, grad_output._data)\n                other.grad._data += other_grad\n\n# Linear algebra operations module\nclass TorchLinalg:\n    """Linear algebra operations module"""\n    \n    def __init__(self, **kwargs):\n        pass\n    \n    def det(self, input_tensor):\n        """Compute determinant"""\n        if isinstance(input_tensor, WebGPUTensor):\n            if input_tensor.ndim != 2 or input_tensor.shape[0] != input_tensor.shape[1]:\n                raise RuntimeError("linalg.det() expects a 2D square tensor")\n            det_value = np.linalg.det(input_tensor._data.reshape(input_tensor.shape))\n            return WebGPUTensor([det_value], device="webgpu", dtype=input_tensor.dtype, _internal=True)\n        else:\n            return np.linalg.det(input_tensor)\n    \n    def inv(self, input_tensor):\n        """Compute matrix inverse"""\n        if isinstance(input_tensor, WebGPUTensor):\n            if input_tensor.ndim != 2 or input_tensor.shape[0] != input_tensor.shape[1]:\n                raise RuntimeError("linalg.inv() expects a 2D square tensor")\n            inv_data = np.linalg.inv(input_tensor._data.reshape(input_tensor.shape))\n            return WebGPUTensor(inv_data, device="webgpu", dtype=input_tensor.dtype, _internal=True)\n        else:\n            return np.linalg.inv(input_tensor)\n    \n    def norm(self, input_tensor, ord=None, dim=None, keepdim=False):\n        """Compute matrix or vector norm"""\n        if isinstance(input_tensor, WebGPUTensor):\n            if dim is None:\n                norm_value = np.linalg.norm(input_tensor._data, ord=ord)\n                return WebGPUTensor([norm_value], device="webgpu", dtype=input_tensor.dtype, _internal=True)\n            else:\n                norm_data = np.linalg.norm(input_tensor._data.reshape(input_tensor.shape), ord=ord, axis=dim, keepdims=keepdim)\n                return WebGPUTensor(norm_data, device="webgpu", dtype=input_tensor.dtype, _internal=True)\n        else:\n            return np.linalg.norm(input_tensor, ord=ord, axis=dim, keepdims=keepdim)\n    \n    def eig(self, input_tensor):\n        """Compute eigenvalues and eigenvectors"""\n        if isinstance(input_tensor, WebGPUTensor):\n            if input_tensor.ndim != 2 or input_tensor.shape[0] != input_tensor.shape[1]:\n                raise RuntimeError("linalg.eig() expects a 2D square tensor")\n            eigenvalues, eigenvectors = np.linalg.eig(input_tensor._data.reshape(input_tensor.shape))\n            return (\n                WebGPUTensor(eigenvalues, device="webgpu", dtype=input_tensor.dtype, _internal=True),\n                WebGPUTensor(eigenvectors, device="webgpu", dtype=input_tensor.dtype, _internal=True)\n            )\n        else:\n            return np.linalg.eig(input_tensor)\n    \n    def svd(self, input_tensor, full_matrices=True):\n        """Compute singular value decomposition"""\n        if isinstance(input_tensor, WebGPUTensor):\n            U, S, Vh = np.linalg.svd(input_tensor._data.reshape(input_tensor.shape), full_matrices=full_matrices)\n            return (\n                WebGPUTensor(U, device="webgpu", dtype=input_tensor.dtype, _internal=True),\n                WebGPUTensor(S, device="webgpu", dtype=input_tensor.dtype, _internal=True),\n                WebGPUTensor(Vh, device="webgpu", dtype=input_tensor.dtype, _internal=True)\n            )\n        else:\n            return np.linalg.svd(input_tensor, full_matrices=full_matrices)\n\n# Neural network functional operations\nclass TorchNNFunctional:\n    @staticmethod\n    def relu(input_tensor):\n        if isinstance(input_tensor, WebGPUTensor):\n            result_data = np.maximum(input_tensor._data, 0)\n            return WebGPUTensor(result_data, device="webgpu", dtype=input_tensor.dtype, _internal=True)\n        else:\n            return np.maximum(input_tensor, 0)\n\n    @staticmethod\n    def sigmoid(input_tensor):\n        if isinstance(input_tensor, WebGPUTensor):\n            result_data = 1 / (1 + np.exp(-input_tensor._data))\n            return WebGPUTensor(result_data, device="webgpu", dtype=input_tensor.dtype, _internal=True)\n        else:\n            return 1 / (1 + np.exp(-input_tensor))\n\n    @staticmethod\n    def softmax(input_tensor, dim=-1):\n        """Apply softmax function"""\n        if isinstance(input_tensor, WebGPUTensor):\n            # Subtract max for numerical stability\n            x = input_tensor._data\n            x_max = np.max(x, axis=dim, keepdims=True)\n            exp_x = np.exp(x - x_max)\n            result_data = exp_x / np.sum(exp_x, axis=dim, keepdims=True)\n            return WebGPUTensor(result_data, device="webgpu", dtype=input_tensor.dtype, _internal=True)\n        else:\n            x_max = np.max(input_tensor, axis=dim, keepdims=True)\n            exp_x = np.exp(input_tensor - x_max)\n            return exp_x / np.sum(exp_x, axis=dim, keepdims=True)\n\n    @staticmethod\n    def log_softmax(input_tensor, dim=-1):\n        """Apply log softmax function"""\n        if isinstance(input_tensor, WebGPUTensor):\n            # Numerically stable log softmax\n            x = input_tensor._data\n            x_max = np.max(x, axis=dim, keepdims=True)\n            log_sum_exp = np.log(np.sum(np.exp(x - x_max), axis=dim, keepdims=True))\n            result_data = x - x_max - log_sum_exp\n            return WebGPUTensor(result_data, device="webgpu", dtype=input_tensor.dtype, _internal=True)\n        else:\n            x_max = np.max(input_tensor, axis=dim, keepdims=True)\n            log_sum_exp = np.log(np.sum(np.exp(input_tensor - x_max), axis=dim, keepdims=True))\n            return input_tensor - x_max - log_sum_exp\n\n    @staticmethod\n    def tanh(input_tensor):\n        """Apply tanh activation"""\n        if isinstance(input_tensor, WebGPUTensor):\n            result_data = np.tanh(input_tensor._data)\n            return WebGPUTensor(result_data, device="webgpu", dtype=input_tensor.dtype, _internal=True)\n        else:\n            return np.tanh(input_tensor)\n\n    @staticmethod\n    def leaky_relu(input_tensor, negative_slope=0.01):\n        """Apply leaky ReLU activation"""\n        if isinstance(input_tensor, WebGPUTensor):\n            result_data = np.where(input_tensor._data > 0, input_tensor._data, input_tensor._data * negative_slope)\n            return WebGPUTensor(result_data, device="webgpu", dtype=input_tensor.dtype, _internal=True)\n        else:\n            return np.where(input_tensor > 0, input_tensor, input_tensor * negative_slope)\n\n    @staticmethod\n    def gelu(input_tensor):\n        """Apply GELU activation"""\n        if isinstance(input_tensor, WebGPUTensor):\n            x = input_tensor._data\n            result_data = 0.5 * x * (1 + np.tanh(np.sqrt(2 / np.pi) * (x + 0.044715 * x**3)))\n            return WebGPUTensor(result_data, device="webgpu", dtype=input_tensor.dtype, _internal=True)\n        else:\n            return 0.5 * input_tensor * (1 + np.tanh(np.sqrt(2 / np.pi) * (input_tensor + 0.044715 * input_tensor**3)))\n\n    @staticmethod\n    def mse_loss(input_tensor, target, reduction=\'mean\'):\n        """Mean Squared Error loss"""\n        if isinstance(input_tensor, WebGPUTensor):\n            inp = input_tensor._data\n            tgt = target._data if isinstance(target, WebGPUTensor) else target\n            squared_diff = (inp - tgt) ** 2\n\n            if reduction == \'mean\':\n                result = np.mean(squared_diff)\n            elif reduction == \'sum\':\n                result = np.sum(squared_diff)\n            elif reduction == \'none\':\n                result = squared_diff\n            else:\n                raise ValueError(f"Invalid reduction mode: {reduction}")\n\n            loss_tensor = WebGPUTensor([result] if np.isscalar(result) else result, device="webgpu", dtype=input_tensor.dtype,\n                                      requires_grad=(input_tensor.requires_grad or (isinstance(target, WebGPUTensor) and target.requires_grad)))\n\n            # Set up backward function for MSE loss\n            if input_tensor.requires_grad or (isinstance(target, WebGPUTensor) and target.requires_grad):\n                def mse_backward(grad_output):\n                    # Gradient of MSE: 2 * (input - target) / N\n                    diff = inp - tgt\n                    if reduction == \'mean\':\n                        grad_input = 2.0 * diff / diff.size\n                    elif reduction == \'sum\':\n                        grad_input = 2.0 * diff\n                    else:  # reduction == \'none\'\n                        grad_input = 2.0 * diff\n\n                    # Multiply by upstream gradient\n                    if isinstance(grad_output._data, np.ndarray):\n                        grad_input = grad_input * grad_output._data\n                    else:\n                        grad_input = grad_input * grad_output._data\n\n                    # Accumulate gradient to input tensor\n                    if input_tensor.requires_grad:\n                        if input_tensor.grad is None:\n                            input_tensor.grad = WebGPUTensor(grad_input, device="webgpu", dtype=input_tensor.dtype, _internal=True)\n                        else:\n                            input_tensor.grad._data += grad_input\n\n                loss_tensor._backward_fn = mse_backward\n                loss_tensor._inputs = [input_tensor]\n\n            return loss_tensor\n        else:\n            squared_diff = (input_tensor - target) ** 2\n\n            if reduction == \'mean\':\n                return np.mean(squared_diff)\n            elif reduction == \'sum\':\n                return np.sum(squared_diff)\n            elif reduction == \'none\':\n                return squared_diff\n            else:\n                raise ValueError(f"Invalid reduction mode: {reduction}")\n\n    @staticmethod\n    def cross_entropy(input_tensor, target, weight=None, reduction=\'mean\'):\n        """Cross entropy loss (combines log_softmax and nll_loss)"""\n        # Apply log_softmax to input\n        log_probs = TorchNNFunctional.log_softmax(input_tensor, dim=-1)\n\n        if isinstance(log_probs, WebGPUTensor):\n            log_probs_data = log_probs._data\n            target_data = target._data if isinstance(target, WebGPUTensor) else target\n\n            # Handle both 1D and 2D inputs\n            if log_probs_data.ndim == 1:\n                # Single sample\n                loss = -log_probs_data[int(target_data)]\n                if weight is not None:\n                    weight_data = weight._data if isinstance(weight, WebGPUTensor) else weight\n                    loss = loss * weight_data[int(target_data)]\n            else:\n                # Batch of samples\n                batch_size = log_probs_data.shape[0]\n                target_indices = target_data.astype(int) if hasattr(target_data, \'astype\') else int(target_data)\n\n                if np.isscalar(target_indices):\n                    loss = -log_probs_data[0, target_indices]\n                    if weight is not None:\n                        weight_data = weight._data if isinstance(weight, WebGPUTensor) else weight\n                        loss = loss * weight_data[target_indices]\n                else:\n                    # Gather losses for each sample\n                    losses = np.array([log_probs_data[i, target_indices[i]] for i in range(batch_size)])\n                    loss = -losses\n\n                    if weight is not None:\n                        weight_data = weight._data if isinstance(weight, WebGPUTensor) else weight\n                        weight_gathered = np.array([weight_data[target_indices[i]] for i in range(batch_size)])\n                        loss = loss * weight_gathered\n\n            if reduction == \'mean\':\n                result = np.mean(loss)\n            elif reduction == \'sum\':\n                result = np.sum(loss)\n            elif reduction == \'none\':\n                result = loss\n            else:\n                raise ValueError(f"Invalid reduction mode: {reduction}")\n\n            loss_tensor = WebGPUTensor([result] if np.isscalar(result) else result, device="webgpu", dtype=log_probs.dtype,\n                                      requires_grad=input_tensor.requires_grad)\n\n            # Set up backward function for cross entropy loss\n            if input_tensor.requires_grad:\n                def cross_entropy_backward(grad_output):\n                    # Gradient: softmax(input) - one_hot(target)\n                    # First compute softmax\n                    if input_tensor._data.ndim == 1:\n                        max_val = np.max(input_tensor._data)\n                        exp_vals = np.exp(input_tensor._data - max_val)\n                        softmax = exp_vals / np.sum(exp_vals)\n\n                        # Create one-hot encoding\n                        one_hot = np.zeros_like(softmax)\n                        one_hot[int(target_data)] = 1.0\n\n                        grad_input = softmax - one_hot\n\n                        # Apply weight if provided\n                        if weight is not None:\n                            weight_data = weight._data if isinstance(weight, WebGPUTensor) else weight\n                            grad_input = grad_input * weight_data[int(target_data)]\n                    else:\n                        # Batch processing\n                        max_vals = np.max(input_tensor._data, axis=-1, keepdims=True)\n                        exp_vals = np.exp(input_tensor._data - max_vals)\n                        softmax = exp_vals / np.sum(exp_vals, axis=-1, keepdims=True)\n\n                        # Create one-hot encoding\n                        batch_size, num_classes = input_tensor._data.shape\n                        one_hot = np.zeros_like(softmax)\n                        target_indices_int = target_data.astype(int) if hasattr(target_data, \'astype\') else int(target_data)\n                        if np.isscalar(target_indices_int):\n                            one_hot[0, target_indices_int] = 1.0\n                        else:\n                            one_hot[np.arange(batch_size), target_indices_int] = 1.0\n\n                        grad_input = softmax - one_hot\n\n                        # Apply weight if provided\n                        if weight is not None:\n                            weight_data = weight._data if isinstance(weight, WebGPUTensor) else weight\n                            weight_gathered = np.array([weight_data[target_indices_int[i]] for i in range(batch_size)])\n                            grad_input = grad_input * weight_gathered[:, np.newaxis]\n\n                    # Apply reduction factor\n                    if reduction == \'mean\':\n                        grad_input = grad_input / (grad_input.shape[0] if grad_input.ndim > 1 else 1)\n\n                    # Multiply by upstream gradient\n                    if isinstance(grad_output._data, np.ndarray):\n                        grad_input = grad_input * grad_output._data\n                    else:\n                        grad_input = grad_input * float(grad_output._data)\n\n                    # Accumulate gradient to input tensor\n                    if input_tensor.grad is None:\n                        input_tensor.grad = WebGPUTensor(grad_input, device="webgpu", dtype=input_tensor.dtype, _internal=True)\n                    else:\n                        input_tensor.grad._data += grad_input\n\n                loss_tensor._backward_fn = cross_entropy_backward\n                loss_tensor._inputs = [input_tensor]\n\n            return loss_tensor\n        else:\n            # NumPy path\n            if log_probs.ndim == 1:\n                loss = -log_probs[int(target)]\n            else:\n                batch_size = log_probs.shape[0]\n                target_indices = target.astype(int) if hasattr(target, \'astype\') else int(target)\n\n                if np.isscalar(target_indices):\n                    loss = -log_probs[0, target_indices]\n                else:\n                    losses = np.array([log_probs[i, target_indices[i]] for i in range(batch_size)])\n                    loss = -losses\n\n            if reduction == \'mean\':\n                return np.mean(loss)\n            elif reduction == \'sum\':\n                return np.sum(loss)\n            elif reduction == \'none\':\n                return loss\n            else:\n                raise ValueError(f"Invalid reduction mode: {reduction}")\n\n    @staticmethod\n    def nll_loss(input_tensor, target, weight=None, reduction=\'mean\'):\n        """Negative Log Likelihood loss\n\n        Args:\n            input_tensor: log-probabilities, shape (N, C) or (C,)\n            target: class indices, shape (N,) or scalar\n            weight: optional class weights, shape (C,)\n            reduction: \'mean\', \'sum\', or \'none\'\n        """\n        if isinstance(input_tensor, WebGPUTensor):\n            log_probs_data = input_tensor._data\n            target_data = target._data if isinstance(target, WebGPUTensor) else target\n\n            # Handle both 1D and 2D inputs\n            if log_probs_data.ndim == 1:\n                # Single sample\n                loss = -log_probs_data[int(target_data)]\n                if weight is not None:\n                    weight_data = weight._data if isinstance(weight, WebGPUTensor) else weight\n                    loss = loss * weight_data[int(target_data)]\n            else:\n                # Batch of samples\n                batch_size = log_probs_data.shape[0]\n                target_indices = target_data.astype(int) if hasattr(target_data, \'astype\') else int(target_data)\n\n                if np.isscalar(target_indices):\n                    loss = -log_probs_data[0, target_indices]\n                    if weight is not None:\n                        weight_data = weight._data if isinstance(weight, WebGPUTensor) else weight\n                        loss = loss * weight_data[target_indices]\n                else:\n                    # Gather losses for each sample\n                    losses = np.array([log_probs_data[i, target_indices[i]] for i in range(batch_size)])\n                    loss = -losses\n\n                    if weight is not None:\n                        weight_data = weight._data if isinstance(weight, WebGPUTensor) else weight\n                        weight_gathered = np.array([weight_data[target_indices[i]] for i in range(batch_size)])\n                        loss = loss * weight_gathered\n\n            if reduction == \'mean\':\n                result = np.mean(loss)\n            elif reduction == \'sum\':\n                result = np.sum(loss)\n            elif reduction == \'none\':\n                result = loss\n            else:\n                raise ValueError(f"Invalid reduction mode: {reduction}")\n\n            loss_tensor = WebGPUTensor([result] if np.isscalar(result) else result, device="webgpu", dtype=input_tensor.dtype,\n                                      requires_grad=input_tensor.requires_grad)\n\n            # Set up backward function for NLL loss\n            if input_tensor.requires_grad:\n                def nll_backward(grad_output):\n                    # Gradient: -1 at the target indices (with optional weighting)\n                    grad_input = np.zeros_like(log_probs_data)\n\n                    if log_probs_data.ndim == 1:\n                        grad_input[int(target_data)] = -1.0\n                        if weight is not None:\n                            weight_data = weight._data if isinstance(weight, WebGPUTensor) else weight\n                            grad_input[int(target_data)] *= weight_data[int(target_data)]\n                    else:\n                        batch_size = log_probs_data.shape[0]\n                        target_indices = target_data.astype(int) if hasattr(target_data, \'astype\') else int(target_data)\n\n                        if np.isscalar(target_indices):\n                            grad_input[0, target_indices] = -1.0\n                            if weight is not None:\n                                weight_data = weight._data if isinstance(weight, WebGPUTensor) else weight\n                                grad_input[0, target_indices] *= weight_data[target_indices]\n                        else:\n                            for i in range(batch_size):\n                                grad_input[i, target_indices[i]] = -1.0\n                                if weight is not None:\n                                    weight_data = weight._data if isinstance(weight, WebGPUTensor) else weight\n                                    grad_input[i, target_indices[i]] *= weight_data[target_indices[i]]\n\n                    # Apply reduction factor\n                    if reduction == \'mean\':\n                        grad_input = grad_input / (batch_size if log_probs_data.ndim > 1 else 1)\n\n                    # Multiply by upstream gradient\n                    if isinstance(grad_output._data, np.ndarray):\n                        grad_input = grad_input * grad_output._data\n                    else:\n                        grad_input = grad_input * float(grad_output._data)\n\n                    # Accumulate gradient to input tensor\n                    if input_tensor.grad is None:\n                        input_tensor.grad = WebGPUTensor(grad_input, device="webgpu", dtype=input_tensor.dtype, _internal=True)\n                    else:\n                        input_tensor.grad._data += grad_input\n\n                loss_tensor._backward_fn = nll_backward\n                loss_tensor._inputs = [input_tensor]\n\n            return loss_tensor\n        else:\n            # NumPy path\n            log_probs = input_tensor\n            if log_probs.ndim == 1:\n                loss = -log_probs[int(target)]\n                if weight is not None:\n                    loss = loss * weight[int(target)]\n            else:\n                batch_size = log_probs.shape[0]\n                target_indices = target.astype(int) if hasattr(target, \'astype\') else int(target)\n\n                if np.isscalar(target_indices):\n                    loss = -log_probs[0, target_indices]\n                    if weight is not None:\n                        loss = loss * weight[target_indices]\n                else:\n                    losses = np.array([log_probs[i, target_indices[i]] for i in range(batch_size)])\n                    loss = -losses\n                    if weight is not None:\n                        weight_gathered = np.array([weight[target_indices[i]] for i in range(batch_size)])\n                        loss = loss * weight_gathered\n\n            if reduction == \'mean\':\n                return np.mean(loss)\n            elif reduction == \'sum\':\n                return np.sum(loss)\n            elif reduction == \'none\':\n                return loss\n            else:\n                raise ValueError(f"Invalid reduction mode: {reduction}")\n\n    @staticmethod\n    def binary_cross_entropy(input_tensor, target, weight=None, reduction=\'mean\'):\n        """Binary Cross Entropy loss\n\n        Args:\n            input_tensor: predictions (must be in [0, 1])\n            target: target values (0 or 1)\n            weight: optional element-wise weights\n            reduction: \'mean\', \'sum\', or \'none\'\n        """\n        if isinstance(input_tensor, WebGPUTensor):\n            inp = input_tensor._data\n            tgt = target._data if isinstance(target, WebGPUTensor) else target\n\n            # Clamp to avoid log(0)\n            inp = np.clip(inp, 1e-7, 1 - 1e-7)\n\n            # BCE formula: -[y*log(x) + (1-y)*log(1-x)]\n            loss = -(tgt * np.log(inp) + (1 - tgt) * np.log(1 - inp))\n\n            if weight is not None:\n                weight_data = weight._data if isinstance(weight, WebGPUTensor) else weight\n                loss = loss * weight_data\n\n            if reduction == \'mean\':\n                result = np.mean(loss)\n            elif reduction == \'sum\':\n                result = np.sum(loss)\n            elif reduction == \'none\':\n                result = loss\n            else:\n                raise ValueError(f"Invalid reduction mode: {reduction}")\n\n            return WebGPUTensor([result] if np.isscalar(result) else result, device="webgpu", dtype=input_tensor.dtype)\n        else:\n            inp = np.clip(input_tensor, 1e-7, 1 - 1e-7)\n            loss = -(target * np.log(inp) + (1 - target) * np.log(1 - inp))\n\n            if weight is not None:\n                loss = loss * weight\n\n            if reduction == \'mean\':\n                return np.mean(loss)\n            elif reduction == \'sum\':\n                return np.sum(loss)\n            elif reduction == \'none\':\n                return loss\n            else:\n                raise ValueError(f"Invalid reduction mode: {reduction}")\n\n    @staticmethod\n    def binary_cross_entropy_with_logits(input_tensor, target, weight=None, reduction=\'mean\'):\n        """Binary Cross Entropy with Logits loss (more numerically stable)\n\n        Args:\n            input_tensor: raw logits (before sigmoid)\n            target: target values (0 or 1)\n            weight: optional element-wise weights\n            reduction: \'mean\', \'sum\', or \'none\'\n        """\n        if isinstance(input_tensor, WebGPUTensor):\n            inp = input_tensor._data\n            tgt = target._data if isinstance(target, WebGPUTensor) else target\n\n            # Numerically stable formula: max(x,0) - x*y + log(1 + exp(-|x|))\n            max_val = np.maximum(inp, 0)\n            loss = max_val - inp * tgt + np.log(1 + np.exp(-np.abs(inp)))\n\n            if weight is not None:\n                weight_data = weight._data if isinstance(weight, WebGPUTensor) else weight\n                loss = loss * weight_data\n\n            if reduction == \'mean\':\n                result = np.mean(loss)\n            elif reduction == \'sum\':\n                result = np.sum(loss)\n            elif reduction == \'none\':\n                result = loss\n            else:\n                raise ValueError(f"Invalid reduction mode: {reduction}")\n\n            return WebGPUTensor([result] if np.isscalar(result) else result, device="webgpu", dtype=input_tensor.dtype)\n        else:\n            max_val = np.maximum(input_tensor, 0)\n            loss = max_val - input_tensor * target + np.log(1 + np.exp(-np.abs(input_tensor)))\n\n            if weight is not None:\n                loss = loss * weight\n\n            if reduction == \'mean\':\n                return np.mean(loss)\n            elif reduction == \'sum\':\n                return np.sum(loss)\n            elif reduction == \'none\':\n                return loss\n            else:\n                raise ValueError(f"Invalid reduction mode: {reduction}")\n\n    @staticmethod\n    def l1_loss(input_tensor, target, reduction=\'mean\'):\n        """L1 Loss (Mean Absolute Error)\n\n        Args:\n            input_tensor: predictions\n            target: target values\n            reduction: \'mean\', \'sum\', or \'none\'\n        """\n        if isinstance(input_tensor, WebGPUTensor):\n            inp = input_tensor._data\n            tgt = target._data if isinstance(target, WebGPUTensor) else target\n            loss = np.abs(inp - tgt)\n\n            if reduction == \'mean\':\n                result = np.mean(loss)\n            elif reduction == \'sum\':\n                result = np.sum(loss)\n            elif reduction == \'none\':\n                result = loss\n            else:\n                raise ValueError(f"Invalid reduction mode: {reduction}")\n\n            return WebGPUTensor([result] if np.isscalar(result) else result, device="webgpu", dtype=input_tensor.dtype)\n        else:\n            loss = np.abs(input_tensor - target)\n\n            if reduction == \'mean\':\n                return np.mean(loss)\n            elif reduction == \'sum\':\n                return np.sum(loss)\n            elif reduction == \'none\':\n                return loss\n            else:\n                raise ValueError(f"Invalid reduction mode: {reduction}")\n\n    @staticmethod\n    def smooth_l1_loss(input_tensor, target, beta=1.0, reduction=\'mean\'):\n        """Smooth L1 Loss (Huber Loss)\n\n        Args:\n            input_tensor: predictions\n            target: target values\n            beta: threshold for switching between L1 and L2\n            reduction: \'mean\', \'sum\', or \'none\'\n        """\n        if isinstance(input_tensor, WebGPUTensor):\n            inp = input_tensor._data\n            tgt = target._data if isinstance(target, WebGPUTensor) else target\n            diff = np.abs(inp - tgt)\n\n            # Smooth L1: 0.5 * diff^2 / beta if |diff| < beta, else |diff| - 0.5 * beta\n            loss = np.where(diff < beta, 0.5 * diff ** 2 / beta, diff - 0.5 * beta)\n\n            if reduction == \'mean\':\n                result = np.mean(loss)\n            elif reduction == \'sum\':\n                result = np.sum(loss)\n            elif reduction == \'none\':\n                result = loss\n            else:\n                raise ValueError(f"Invalid reduction mode: {reduction}")\n\n            return WebGPUTensor([result] if np.isscalar(result) else result, device="webgpu", dtype=input_tensor.dtype)\n        else:\n            diff = np.abs(input_tensor - target)\n            loss = np.where(diff < beta, 0.5 * diff ** 2 / beta, diff - 0.5 * beta)\n\n            if reduction == \'mean\':\n                return np.mean(loss)\n            elif reduction == \'sum\':\n                return np.sum(loss)\n            elif reduction == \'none\':\n                return loss\n            else:\n                raise ValueError(f"Invalid reduction mode: {reduction}")\n\n    @staticmethod\n    def kl_div(input_tensor, target, reduction=\'mean\'):\n        """KL Divergence loss\n\n        Args:\n            input_tensor: log probabilities\n            target: target probabilities\n            reduction: \'mean\', \'sum\', \'batchmean\', or \'none\'\n        """\n        if isinstance(input_tensor, WebGPUTensor):\n            inp = input_tensor._data  # log probabilities\n            tgt = target._data if isinstance(target, WebGPUTensor) else target  # probabilities\n\n            # KL(P||Q) = sum(P * (log(P) - log(Q)))\n            # Since input is already log(Q), we have: sum(P * (log(P) - input))\n            loss = tgt * (np.log(np.clip(tgt, 1e-10, None)) - inp)\n\n            if reduction == \'mean\':\n                result = np.mean(loss)\n            elif reduction == \'sum\':\n                result = np.sum(loss)\n            elif reduction == \'batchmean\':\n                # Average over batch dimension\n                result = np.sum(loss) / (loss.shape[0] if loss.ndim > 1 else 1)\n            elif reduction == \'none\':\n                result = loss\n            else:\n                raise ValueError(f"Invalid reduction mode: {reduction}")\n\n            return WebGPUTensor([result] if np.isscalar(result) else result, device="webgpu", dtype=input_tensor.dtype)\n        else:\n            loss = target * (np.log(np.clip(target, 1e-10, None)) - input_tensor)\n\n            if reduction == \'mean\':\n                return np.mean(loss)\n            elif reduction == \'sum\':\n                return np.sum(loss)\n            elif reduction == \'batchmean\':\n                return np.sum(loss) / (loss.shape[0] if loss.ndim > 1 else 1)\n            elif reduction == \'none\':\n                return loss\n            else:\n                raise ValueError(f"Invalid reduction mode: {reduction}")\n\n    @staticmethod\n    def cosine_embedding_loss(input1, input2, target, margin=0.0, reduction=\'mean\'):\n        """Cosine Embedding Loss\n\n        Args:\n            input1: first input tensor\n            input2: second input tensor\n            target: 1 for similar pairs, -1 for dissimilar pairs\n            margin: margin for dissimilar pairs\n            reduction: \'mean\', \'sum\', or \'none\'\n        """\n        if isinstance(input1, WebGPUTensor):\n            inp1 = input1._data\n            inp2 = input2._data if isinstance(input2, WebGPUTensor) else input2\n            tgt = target._data if isinstance(target, WebGPUTensor) else target\n\n            # Compute cosine similarity\n            dot_product = np.sum(inp1 * inp2, axis=-1)\n            norm1 = np.sqrt(np.sum(inp1 ** 2, axis=-1))\n            norm2 = np.sqrt(np.sum(inp2 ** 2, axis=-1))\n            cos_sim = dot_product / (norm1 * norm2 + 1e-8)\n\n            # Loss: 1 - cos_sim if target=1, max(0, cos_sim - margin) if target=-1\n            loss = np.where(tgt == 1, 1 - cos_sim, np.maximum(0, cos_sim - margin))\n\n            if reduction == \'mean\':\n                result = np.mean(loss)\n            elif reduction == \'sum\':\n                result = np.sum(loss)\n            elif reduction == \'none\':\n                result = loss\n            else:\n                raise ValueError(f"Invalid reduction mode: {reduction}")\n\n            return WebGPUTensor([result] if np.isscalar(result) else result, device="webgpu", dtype=input1.dtype)\n        else:\n            dot_product = np.sum(input1 * input2, axis=-1)\n            norm1 = np.sqrt(np.sum(input1 ** 2, axis=-1))\n            norm2 = np.sqrt(np.sum(input2 ** 2, axis=-1))\n            cos_sim = dot_product / (norm1 * norm2 + 1e-8)\n\n            loss = np.where(target == 1, 1 - cos_sim, np.maximum(0, cos_sim - margin))\n\n            if reduction == \'mean\':\n                return np.mean(loss)\n            elif reduction == \'sum\':\n                return np.sum(loss)\n            elif reduction == \'none\':\n                return loss\n            else:\n                raise ValueError(f"Invalid reduction mode: {reduction}")\n\n# Parameter wrapper for tensors\nclass TorchNNParameter:\n    """A kind of Tensor that is to be considered a module parameter.\n\n    Parameters are Tensor subclasses that have a very special property when used with\n    Module s - when they\'re assigned as Module attributes they are automatically added\n    to the list of its parameters, and will appear in parameters() iterator.\n    """\n    def __init__(self, data=None, requires_grad=True, **kwargs):\n        if data is None:\n            raise ValueError("Parameter data cannot be None")\n\n        # If data is already a tensor, use it; otherwise create a tensor\n        if isinstance(data, WebGPUTensor):\n            self.data = data\n            # Override requires_grad if specified\n            if hasattr(self.data, \'requires_grad\'):\n                self.data.requires_grad = requires_grad\n        else:\n            # Convert to tensor\n            import torch as torch_module\n            self.data = torch_module.tensor(data, requires_grad=requires_grad)\n\n        # Mark this as a parameter\n        self.is_parameter = True\n        self.requires_grad = requires_grad\n\n    def __repr__(self):\n        return f"Parameter containing:\\n{self.data.__repr__()}"\n\n    # Note: No __hash__ or __eq__ override - uses default identity-based\n    # This allows parameters to be used as dict keys in optimizer state\n\n    def __getattr__(self, name):\n        # Delegate attribute access to the underlying tensor\n        if name in [\'data\', \'is_parameter\', \'requires_grad\']:\n            return object.__getattribute__(self, name)\n        return getattr(self.data, name)\n\n    @property\n    def shape(self):\n        return self.data.shape\n\n    @property\n    def dtype(self):\n        return self.data.dtype\n\n    @property\n    def device(self):\n        return self.data.device\n\n    @property\n    def grad(self):\n        return getattr(self.data, \'grad\', None)\n\n    @grad.setter\n    def grad(self, value):\n        self.data.grad = value\n\n    def backward(self, gradient=None):\n        """Backward pass for parameter"""\n        if hasattr(self.data, \'backward\'):\n            self.data.backward(gradient)\n\n    def zero_grad(self):\n        """Zero out the gradient"""\n        if hasattr(self.data, \'grad\') and self.data.grad is not None:\n            self.data.grad = None\n\n    def numpy(self):\n        """Convert to numpy array"""\n        return self.data.numpy() if hasattr(self.data, \'numpy\') else self.data._data\n\n    def tolist(self):\n        """Convert to Python list"""\n        return self.data.tolist() if hasattr(self.data, \'tolist\') else self.data._data.tolist()\n\n    def item(self):\n        """Get scalar value"""\n        return self.data.item() if hasattr(self.data, \'item\') else self.data._data.item()\n\n    def to(self, device):\n        """Move parameter to device"""\n        if hasattr(self.data, \'to\'):\n            self.data = self.data.to(device)\n        return self\n\n    def clone(self):\n        """Clone the parameter"""\n        cloned_data = self.data.clone() if hasattr(self.data, \'clone\') else self.data\n        return TorchNNParameter(cloned_data, requires_grad=self.requires_grad)\n\n    def detach(self):\n        """Detach from computation graph"""\n        if hasattr(self.data, \'detach\'):\n            return self.data.detach()\n        return self.data\n\n# Neural network modules\nclass TorchNNModule:\n    def __init__(self, **kwargs):\n        self._parameters = {}\n        self._modules = {}\n        self._buffers = {}\n        self._non_persistent_buffers_set = set()\n        self._backward_hooks = {}\n        self._backward_pre_hooks = {}\n        self._forward_hooks = {}\n        self._forward_pre_hooks = {}\n        self._state_dict_hooks = {}\n        self._load_state_dict_pre_hooks = {}\n        self.training = True\n        \n    def parameters(self):\n        params = []\n        debug_id = getattr(self, \'_debug_id\', \'UNKNOWN\')\n        class_name = self.__class__.__name__\n        for param in self._parameters.values():\n            params.append(param)\n        for module_name, module in self._modules.items():\n            if hasattr(module, \'parameters\'):\n                subparams = module.parameters()\n                params.extend(subparams)\n        return params\n\n    def named_parameters(self, prefix=\'\'):\n        """Returns an iterator over module parameters, yielding (name, parameter) tuples.\n\n        Args:\n            prefix: Prefix to prepend to all parameter names\n\n        Yields:\n            (str, WebGPUTensor): Tuples of parameter name and parameter tensor\n        """\n        # Yield parameters from this module\n        for name, param in self._parameters.items():\n            if param is not None:\n                full_name = prefix + name if prefix else name\n                yield (full_name, param)\n\n        # Recursively yield parameters from submodules\n        for module_name, module in self._modules.items():\n            if module is not None and hasattr(module, \'named_parameters\'):\n                submodule_prefix = prefix + module_name + \'.\' if prefix else module_name + \'.\'\n                for name, param in module.named_parameters(prefix=submodule_prefix):\n                    yield (name, param)\n\n    def modules(self):\n        """Returns an iterator over all modules in the network.\n\n        Yields:\n            TorchNNModule: Module in the network (including self and all descendants)\n        """\n        # Yield self first\n        yield self\n\n        # Recursively yield all submodules\n        for name, module in self._modules.items():\n            if module is not None:\n                if hasattr(module, \'modules\'):\n                    # If it\'s a TorchNNModule, recursively get its modules\n                    for submodule in module.modules():\n                        yield submodule\n                else:\n                    # If it\'s a simple module without modules() method, just yield it\n                    yield module\n\n    def __setattr__(self, name, value):\n        """Override setattr to automatically register modules and parameters"""\n        # Check if the value is a TorchNNModule (submodule)\n        if isinstance(value, TorchNNModule):\n            if hasattr(self, \'_modules\'):\n                self._modules[name] = value\n\n        # Check if the value is a WebGPUTensor with requires_grad (parameter)\n        elif isinstance(value, WebGPUTensor) and getattr(value, \'requires_grad\', False):\n            if hasattr(self, \'_parameters\'):\n                self._parameters[name] = value\n\n        # Default setattr behavior\n        object.__setattr__(self, name, value)\n\n    def __call__(self, *args, **kwargs):\n        # Call forward pre-hooks\n        for hook in self._forward_pre_hooks.values():\n            hook(self, args)\n\n        # Call forward method\n        result = self.forward(*args, **kwargs)\n\n        # Call forward hooks\n        for hook in self._forward_hooks.values():\n            hook_result = hook(self, args, result)\n            if hook_result is not None:\n                result = hook_result\n\n        return result\n\n    def forward(self, x):\n        raise NotImplementedError\n\n    def register_forward_hook(self, hook):\n        """Register a forward hook on the module.\n\n        The hook will be called every time after forward() has computed an output.\n        It should have the following signature:\n            hook(module, input, output) -> None or modified output\n\n        Args:\n            hook: A function that takes (module, input, output) as arguments\n\n        Returns:\n            A handle that can be used to remove the hook by calling handle.remove()\n        """\n        handle_id = len(self._forward_hooks)\n        self._forward_hooks[handle_id] = hook\n\n        # Create a handle for removing the hook\n        class HookHandle:\n            def __init__(self, hooks_dict, hook_id, **kwargs):\n                self.hooks_dict = hooks_dict\n                self.hook_id = hook_id\n\n            def remove(self):\n                if self.hook_id in self.hooks_dict:\n                    del self.hooks_dict[self.hook_id]\n\n        return HookHandle(self._forward_hooks, handle_id)\n\n    def to(self, device):\n        """Move module to specified device"""\n        # Convert device string to device object if needed\n        if isinstance(device, str):\n            if device == \'cuda\':\n                device = \'webgpu\'  # Map CUDA to WebGPU\n            target_device = device\n        else:\n            target_device = device.type if hasattr(device, \'type\') else str(device)\n\n        # Move all parameters to the new device\n        for param in self.parameters():\n            # CRITICAL: Actually allocate GPU buffers, not just metadata!\n            if target_device == \'webgpu\' and \'__webgpu_allocate__\' in globals():\n                # Allocate GPU buffer for this parameter\n                param.device = WebGPUDevice(target_device)\n                if not hasattr(param, \'_gpu_buffer_id\') or param._gpu_buffer_id is None:\n                    try:\n                        param._gpu_buffer_id = __webgpu_allocate__(\n                            param._data.tolist(),\n                            list(param.shape),\n                            param.dtype\n                        )\n                    except Exception as e:\n                        pass  # Failed to allocate GPU buffer\n            else:\n                param.device = target_device\n\n        # Recursively move submodules\n        for module in self._modules.values():\n            if hasattr(module, \'to\'):\n                module.to(target_device)\n\n        return self\n\n    def cpu(self):\n        """Move module to CPU"""\n        return self.to(\'cpu\')\n\n    def cuda(self):\n        """Move module to WebGPU (CUDA equivalent)"""\n        return self.to(\'webgpu\')\n\n    def train(self, mode=True):\n        """Set the module in training mode"""\n        self.training = mode\n        # Recursively set training mode for all submodules\n        for module in self._modules.values():\n            if hasattr(module, \'train\'):\n                module.train(mode)\n        return self\n\n    def eval(self):\n        """Set the module in evaluation mode"""\n        return self.train(False)\n\n    def state_dict(self, destination=None, prefix=\'\'):\n        """Returns a dictionary containing all parameters and buffers.\n\n        Args:\n            destination: Optional dict to store state into\n            prefix: Prefix for parameter names (used for nested modules)\n\n        Returns:\n            Dictionary mapping parameter names to their tensor data\n        """\n        if destination is None:\n            destination = {}\n\n        # Add parameters from this module\n        for name, param in self._parameters.items():\n            if param is not None:\n                key = prefix + name\n                # Store as numpy array for serialization\n                destination[key] = param._data.copy()\n\n        # Add buffers from this module\n        for name, buf in self._buffers.items():\n            if buf is not None and name not in self._non_persistent_buffers_set:\n                key = prefix + name\n                destination[key] = buf._data.copy() if hasattr(buf, \'_data\') else buf.copy()\n\n        # Recursively add state from submodules\n        for name, module in self._modules.items():\n            if module is not None and hasattr(module, \'state_dict\'):\n                module.state_dict(destination, prefix + name + \'.\')\n\n        return destination\n\n    def load_state_dict(self, state_dict, strict=True):\n        """Loads parameters and buffers from state_dict.\n\n        Args:\n            state_dict: Dictionary containing parameters and buffers\n            strict: If True, requires exact match of keys. If False, allows partial loading.\n\n        Returns:\n            NamedTuple with missing_keys and unexpected_keys lists\n        """\n        missing_keys = []\n        unexpected_keys = list(state_dict.keys())\n\n        # Helper function to load state for a module with prefix\n        def load_module_state(module, prefix=\'\'):\n            # Load parameters\n            for name, param in module._parameters.items():\n                if param is not None:\n                    key = prefix + name\n                    if key in state_dict:\n                        # Update parameter data\n                        param._data = state_dict[key].copy()\n                        if key in unexpected_keys:\n                            unexpected_keys.remove(key)\n                    elif strict:\n                        missing_keys.append(key)\n\n            # Load buffers\n            for name, buf in module._buffers.items():\n                if buf is not None and name not in module._non_persistent_buffers_set:\n                    key = prefix + name\n                    if key in state_dict:\n                        if hasattr(buf, \'_data\'):\n                            buf._data = state_dict[key].copy()\n                        else:\n                            module._buffers[name] = state_dict[key].copy()\n                        if key in unexpected_keys:\n                            unexpected_keys.remove(key)\n                    elif strict:\n                        missing_keys.append(key)\n\n            # Recursively load submodules\n            for name, submodule in module._modules.items():\n                if submodule is not None:\n                    load_module_state(submodule, prefix + name + \'.\')\n\n        # Load state starting from this module\n        load_module_state(self, \'\')\n\n        # Return information about missing and unexpected keys\n        class LoadResult:\n            def __init__(self, missing, unexpected, **kwargs):\n                self.missing_keys = missing\n                self.unexpected_keys = unexpected\n\n        if strict and (missing_keys or unexpected_keys):\n            error_msgs = []\n            if missing_keys:\n                error_msgs.append(f"Missing keys in state_dict: {missing_keys}")\n            if unexpected_keys:\n                error_msgs.append(f"Unexpected keys in state_dict: {unexpected_keys}")\n            raise RuntimeError("Error(s) loading state_dict: " + " ".join(error_msgs))\n\n        return LoadResult(missing_keys, unexpected_keys)\n\nclass TorchNNLinear(TorchNNModule):\n    def __init__(self, in_features, out_features, bias=True, **kwargs):\n        import random\n        self._debug_id = random.randint(1000, 9999)\n        self._parameters = {}\n        self._modules = {}\n        self._buffers = {}\n        self._non_persistent_buffers_set = set()\n        self._backward_hooks = {}\n        self._backward_pre_hooks = {}\n        self._forward_hooks = {}\n        self._forward_pre_hooks = {}\n        self._state_dict_hooks = {}\n        self._load_state_dict_pre_hooks = {}\n        self.training = True\n        self.in_features = in_features\n        self.out_features = out_features\n\n        weight_data = np.random.randn(out_features, in_features) * np.sqrt(2.0 / in_features)\n        self.weight = WebGPUTensor(weight_data, requires_grad=True)\n        self._parameters[\'weight\'] = self.weight\n\n        if bias:\n            bias_data = np.zeros(out_features)\n            self.bias = WebGPUTensor(bias_data, requires_grad=True)\n            self._parameters[\'bias\'] = self.bias\n        else:\n            self.bias = None\n\n        # Cache for transposed weight GPU buffer (avoid re-uploading every forward pass)\n        self._weight_t_gpu_buffer_id = None\n        self._weight_t_data = None\n\n    def forward(self, x):\n        if isinstance(x, WebGPUTensor):\n            # Linear transformation: y = xW^T + b\n            # GPU ACCELERATED with cached transpose: Only upload W^T once, reuse for all forward passes\n\n            # Check if we can use GPU path\n            weight_on_gpu = hasattr(self.weight, \'_gpu_buffer_id\') and self.weight._gpu_buffer_id is not None\n            input_on_gpu = hasattr(x, \'_gpu_buffer_id\') and x._gpu_buffer_id is not None\n\n            if weight_on_gpu and input_on_gpu and \'__webgpu_allocate__\' in globals():\n                # GPU path with cached transpose\n                # Check if we need to create/update cached transpose\n                if self._weight_t_gpu_buffer_id is None:\n                    # First time: create and upload transposed weight\n                    weight_t_data = self.weight._data.T\n                    self._weight_t_data = weight_t_data\n                    self._weight_t_gpu_buffer_id = __webgpu_allocate__(\n                        weight_t_data.tolist(),\n                        list(weight_t_data.shape),\n                        self.weight.dtype\n                    )\n\n                # Create temporary WebGPUTensor for transposed weight\n                weight_t = WebGPUTensor(self._weight_t_data, device="webgpu", dtype=self.weight.dtype, _internal=True)\n                weight_t._gpu_buffer_id = self._weight_t_gpu_buffer_id\n\n                # GPU matmul: x @ W^T\n                result = x @ weight_t\n\n                if self.bias is not None:\n                    # Add bias (CPU for now)\n                    result_data = result._data + self.bias._data\n                    result = WebGPUTensor(result_data, device="webgpu", dtype=x.dtype,\n                                        requires_grad=result.requires_grad, _internal=True)\n            else:\n                # Fallback: CPU path\n                result_data = np.dot(x._data, self.weight._data.T)\n                if self.bias is not None:\n                    result_data = result_data + self.bias._data\n                result = WebGPUTensor(result_data, device="webgpu", dtype=x.dtype,\n                                    requires_grad=(x.requires_grad or self.weight.requires_grad or\n                                                 (self.bias is not None and self.bias.requires_grad)), _internal=True)\n\n            # Set up backward function for linear layer\n            def linear_backward(grad_output):\n\n                if x.requires_grad:\n                    # Gradient w.r.t input: grad_output @ weight\n                    if x.grad is None:\n                        x.grad = WebGPUTensor(np.zeros_like(x._data), device="webgpu", dtype=x.dtype)\n                    x.grad._data += np.dot(grad_output._data, self.weight._data)\n\n                if self.weight.requires_grad:\n                    # Gradient w.r.t weight: x^T @ grad_output\n                    if self.weight.grad is None:\n                        self.weight.grad = WebGPUTensor(np.zeros_like(self.weight._data), device="webgpu", dtype=self.weight.dtype)\n                    weight_grad = np.dot(grad_output._data.T, x._data)\n                    self.weight.grad._data += weight_grad\n\n                if self.bias is not None and self.bias.requires_grad:\n                    # Gradient w.r.t bias: sum(grad_output, axis=0)\n                    if self.bias.grad is None:\n                        self.bias.grad = WebGPUTensor(np.zeros_like(self.bias._data), device="webgpu", dtype=self.bias.dtype)\n                    bias_grad = np.sum(grad_output._data, axis=0)\n                    self.bias.grad._data += bias_grad\n\n            result._backward_fn = linear_backward\n            result._inputs = [x, self.weight] + ([self.bias] if self.bias else [])\n\n            return result\n        else:\n            raise TypeError("Input must be WebGPUTensor")\n\nclass TorchNNReLU(TorchNNModule):\n    def __init__(self, **kwargs):\n        self._parameters = {}\n        self._modules = {}\n        self._buffers = {}\n        self._non_persistent_buffers_set = set()\n        self._backward_hooks = {}\n        self._backward_pre_hooks = {}\n        self._forward_hooks = {}\n        self._forward_pre_hooks = {}\n        self._state_dict_hooks = {}\n        self._load_state_dict_pre_hooks = {}\n        self.training = True\n\n    def forward(self, x):\n        if isinstance(x, WebGPUTensor):\n            result_data = np.maximum(x._data, 0)\n            result = WebGPUTensor(result_data, device="webgpu", dtype=x.dtype, requires_grad=x.requires_grad, _internal=True)\n\n            # Set up backward function for ReLU\n            if x.requires_grad:\n                def relu_backward(grad_output):\n                    # Gradient: 1 if x > 0, else 0\n                    grad_input = grad_output._data * (x._data > 0)\n                    if x.grad is None:\n                        x.grad = WebGPUTensor(np.zeros_like(x._data), device="webgpu", dtype=x.dtype, _internal=True)\n                    x.grad._data += grad_input\n\n                result._backward_fn = relu_backward\n                result._inputs = [x]\n\n            return result\n        else:\n            return np.maximum(x, 0)\n\nclass TorchNNSigmoid(TorchNNModule):\n    """Sigmoid activation layer"""\n    def __init__(self, **kwargs):\n        self._parameters = {}\n        self._modules = {}\n        self._buffers = {}\n        self._non_persistent_buffers_set = set()\n        self._backward_hooks = {}\n        self._backward_pre_hooks = {}\n        self._forward_hooks = {}\n        self._forward_pre_hooks = {}\n        self._state_dict_hooks = {}\n        self._load_state_dict_pre_hooks = {}\n        self.training = True\n\n    def forward(self, x):\n        """Apply sigmoid: Ïƒ(x) = 1 / (1 + exp(-x))"""\n        if isinstance(x, WebGPUTensor):\n            result_data = 1 / (1 + np.exp(-x._data))\n            result = WebGPUTensor(result_data, device="webgpu", dtype=x.dtype, requires_grad=x.requires_grad)\n\n            # Set up backward function for autograd\n            if x.requires_grad:\n                def sigmoid_backward(grad_output):\n                    # Gradient: Ïƒ\'(x) = Ïƒ(x) * (1 - Ïƒ(x))\n                    sigmoid_val = result_data\n                    grad_input = grad_output._data * sigmoid_val * (1 - sigmoid_val)\n                    grad_tensor = WebGPUTensor(grad_input, device="webgpu", dtype=x.dtype, _internal=True)\n                    x.backward(grad_tensor)\n\n                result._backward_fn = sigmoid_backward\n                result._inputs = [x]\n\n            return result\n        else:\n            return 1 / (1 + np.exp(-x))\n\nclass TorchNNTanh(TorchNNModule):\n    """Tanh activation layer"""\n    def __init__(self, **kwargs):\n        self._parameters = {}\n        self._modules = {}\n        self._buffers = {}\n        self._non_persistent_buffers_set = set()\n        self._backward_hooks = {}\n        self._backward_pre_hooks = {}\n        self._forward_hooks = {}\n        self._forward_pre_hooks = {}\n        self._state_dict_hooks = {}\n        self._load_state_dict_pre_hooks = {}\n        self.training = True\n\n    def forward(self, x):\n        """Apply tanh: tanh(x) = (exp(x) - exp(-x)) / (exp(x) + exp(-x))"""\n        if isinstance(x, WebGPUTensor):\n            result_data = np.tanh(x._data)\n            result = WebGPUTensor(result_data, device="webgpu", dtype=x.dtype, requires_grad=x.requires_grad)\n\n            # Set up backward function for autograd\n            if x.requires_grad:\n                def tanh_backward(grad_output):\n                    # Gradient: tanh\'(x) = 1 - tanhÂ²(x)\n                    tanh_val = result_data\n                    grad_input = grad_output._data * (1 - tanh_val ** 2)\n                    grad_tensor = WebGPUTensor(grad_input, device="webgpu", dtype=x.dtype, _internal=True)\n                    x.backward(grad_tensor)\n\n                result._backward_fn = tanh_backward\n                result._inputs = [x]\n\n            return result\n        else:\n            return np.tanh(x)\n\nclass TorchNNLeakyReLU(TorchNNModule):\n    """Leaky ReLU activation layer\n\n    LeakyReLU(x) = max(0, x) + negative_slope * min(0, x)\n    """\n    def __init__(self, negative_slope=0.01, inplace=False, **kwargs):\n        self._parameters = {}\n        self._modules = {}\n        self._buffers = {}\n        self._non_persistent_buffers_set = set()\n        self._backward_hooks = {}\n        self._backward_pre_hooks = {}\n        self._forward_hooks = {}\n        self._forward_pre_hooks = {}\n        self._state_dict_hooks = {}\n        self._load_state_dict_pre_hooks = {}\n        self.training = True\n        self.negative_slope = negative_slope\n        self.inplace = inplace\n\n    def forward(self, x):\n        """Apply Leaky ReLU"""\n        if isinstance(x, WebGPUTensor):\n            result_data = np.where(x._data > 0, x._data, self.negative_slope * x._data)\n            result = WebGPUTensor(result_data, device="webgpu", dtype=x.dtype, requires_grad=x.requires_grad)\n\n            # Set up backward function for autograd\n            if x.requires_grad:\n                def leaky_relu_backward(grad_output):\n                    # Gradient: 1 if x > 0, negative_slope otherwise\n                    grad_input = np.where(x._data > 0, grad_output._data, self.negative_slope * grad_output._data)\n                    grad_tensor = WebGPUTensor(grad_input, device="webgpu", dtype=x.dtype, _internal=True)\n                    x.backward(grad_tensor)\n\n                result._backward_fn = leaky_relu_backward\n                result._inputs = [x]\n\n            return result\n        else:\n            return np.where(x > 0, x, self.negative_slope * x)\n\nclass TorchNNGELU(TorchNNModule):\n    """Gaussian Error Linear Units (GELU) activation\n\n    GELU(x) = x * Î¦(x) where Î¦(x) is the Gaussian CDF\n    Approximation: GELU(x) â‰ˆ 0.5 * x * (1 + tanh(âˆš(2/Ï€) * (x + 0.044715 * xÂ³)))\n    """\n    def __init__(self, approximate=\'none\', **kwargs):\n        self._parameters = {}\n        self._modules = {}\n        self._buffers = {}\n        self._non_persistent_buffers_set = set()\n        self._backward_hooks = {}\n        self._backward_pre_hooks = {}\n        self._forward_hooks = {}\n        self._forward_pre_hooks = {}\n        self._state_dict_hooks = {}\n        self._load_state_dict_pre_hooks = {}\n        self.training = True\n        self.approximate = approximate\n\n    def forward(self, x):\n        """Apply GELU activation"""\n        if isinstance(x, WebGPUTensor):\n            if self.approximate == \'tanh\':\n                # Fast approximation using tanh\n                # GELU(x) â‰ˆ 0.5 * x * (1 + tanh(âˆš(2/Ï€) * (x + 0.044715 * xÂ³)))\n                sqrt_2_over_pi = np.sqrt(2.0 / np.pi)\n                inner = sqrt_2_over_pi * (x._data + 0.044715 * x._data ** 3)\n                result_data = 0.5 * x._data * (1.0 + np.tanh(inner))\n            else:\n                # Accurate version using erf (error function)\n                # GELU(x) = 0.5 * x * (1 + erf(x / âˆš2))\n                try:\n                    from scipy.special import erf\n                    result_data = 0.5 * x._data * (1.0 + erf(x._data / np.sqrt(2.0)))\n                except ImportError:\n                    # Fallback to tanh approximation if scipy not available\n                    sqrt_2_over_pi = np.sqrt(2.0 / np.pi)\n                    inner = sqrt_2_over_pi * (x._data + 0.044715 * x._data ** 3)\n                    result_data = 0.5 * x._data * (1.0 + np.tanh(inner))\n\n            result = WebGPUTensor(result_data, device="webgpu", dtype=x.dtype, requires_grad=x.requires_grad)\n\n            # Set up backward function for autograd\n            if x.requires_grad:\n                def gelu_backward(grad_output):\n                    # Simplified gradient (using tanh approximation)\n                    sqrt_2_over_pi = np.sqrt(2.0 / np.pi)\n                    x_cubed = x._data ** 3\n                    inner = sqrt_2_over_pi * (x._data + 0.044715 * x_cubed)\n                    tanh_inner = np.tanh(inner)\n                    sech_squared = 1 - tanh_inner ** 2\n\n                    grad_input = grad_output._data * (\n                        0.5 * (1.0 + tanh_inner) +\n                        0.5 * x._data * sech_squared * sqrt_2_over_pi * (1 + 3 * 0.044715 * x._data ** 2)\n                    )\n                    grad_tensor = WebGPUTensor(grad_input, device="webgpu", dtype=x.dtype, _internal=True)\n                    x.backward(grad_tensor)\n\n                result._backward_fn = gelu_backward\n                result._inputs = [x]\n\n            return result\n        else:\n            # NumPy fallback\n            sqrt_2_over_pi = np.sqrt(2.0 / np.pi)\n            inner = sqrt_2_over_pi * (x + 0.044715 * x ** 3)\n            return 0.5 * x * (1.0 + np.tanh(inner))\n\nclass TorchNNSiLU(TorchNNModule):\n    """Sigmoid-Weighted Linear Unit (SiLU) / Swish activation\n\n    SiLU(x) = x * sigmoid(x) = x / (1 + exp(-x))\n    Also known as Swish activation\n    """\n    def __init__(self, **kwargs):\n        self._parameters = {}\n        self._modules = {}\n        self._buffers = {}\n        self._non_persistent_buffers_set = set()\n        self._backward_hooks = {}\n        self._backward_pre_hooks = {}\n        self._forward_hooks = {}\n        self._forward_pre_hooks = {}\n        self._state_dict_hooks = {}\n        self._load_state_dict_pre_hooks = {}\n        self.training = True\n\n    def forward(self, x):\n        """Apply SiLU/Swish: x * sigmoid(x)"""\n        if isinstance(x, WebGPUTensor):\n            sigmoid_x = 1.0 / (1.0 + np.exp(-x._data))\n            result_data = x._data * sigmoid_x\n            result = WebGPUTensor(result_data, device="webgpu", dtype=x.dtype, requires_grad=x.requires_grad)\n\n            # Set up backward function for autograd\n            if x.requires_grad:\n                def silu_backward(grad_output):\n                    # Gradient: sigmoid(x) + x * sigmoid(x) * (1 - sigmoid(x))\n                    # Simplifies to: sigmoid(x) * (1 + x * (1 - sigmoid(x)))\n                    grad_input = grad_output._data * (sigmoid_x + x._data * sigmoid_x * (1 - sigmoid_x))\n                    grad_tensor = WebGPUTensor(grad_input, device="webgpu", dtype=x.dtype, _internal=True)\n                    x.backward(grad_tensor)\n\n                result._backward_fn = silu_backward\n                result._inputs = [x]\n\n            return result\n        else:\n            sigmoid_x = 1.0 / (1.0 + np.exp(-x))\n            return x * sigmoid_x\n\nclass TorchNNDropout(TorchNNModule):\n    """Dropout layer for regularization"""\n    def __init__(self, p=0.5, inplace=False, **kwargs):\n        self._parameters = {}\n        self._modules = {}\n        self._buffers = {}\n        self._non_persistent_buffers_set = set()\n        self._backward_hooks = {}\n        self._backward_pre_hooks = {}\n        self._forward_hooks = {}\n        self._forward_pre_hooks = {}\n        self._state_dict_hooks = {}\n        self._load_state_dict_pre_hooks = {}\n        self.training = True\n        self.p = p  # Dropout probability\n        self.inplace = inplace\n\n    def forward(self, x):\n        """Apply dropout: randomly zero elements during training"""\n        if isinstance(x, WebGPUTensor):\n            # During evaluation, dropout is a no-op\n            if not self.training:\n                return x\n\n            # During training, randomly drop elements\n            if self.p == 0:\n                return x\n\n            # Generate dropout mask\n            keep_prob = 1 - self.p\n            mask = np.random.binomial(1, keep_prob, size=x.shape) / keep_prob\n\n            # Apply mask and scale\n            result_data = x._data * mask\n            result = WebGPUTensor(result_data, device="webgpu", dtype=x.dtype, requires_grad=x.requires_grad)\n\n            # Set up backward function for autograd\n            if x.requires_grad:\n                def dropout_backward(grad_output):\n                    # Gradient flows through the same mask\n                    grad_input = grad_output._data * mask\n                    grad_tensor = WebGPUTensor(grad_input, device="webgpu", dtype=x.dtype, _internal=True)\n                    x.backward(grad_tensor)\n\n                result._backward_fn = dropout_backward\n                result._inputs = [x]\n\n            return result\n        else:\n            # NumPy fallback\n            if not self.training or self.p == 0:\n                return x\n            keep_prob = 1 - self.p\n            mask = np.random.binomial(1, keep_prob, size=x.shape) / keep_prob\n            return x * mask\n\nclass TorchNNBatchNorm2d(TorchNNModule):\n    """Batch Normalization for 2D spatial data (4D input: N x C x H x W)"""\n    def __init__(self, num_features, eps=1e-5, momentum=0.1, affine=True, track_running_stats=True, **kwargs):\n        self._parameters = {}\n        self._modules = {}\n        self._buffers = {}\n        self._non_persistent_buffers_set = set()\n        self._backward_hooks = {}\n        self._backward_pre_hooks = {}\n        self._forward_hooks = {}\n        self._forward_pre_hooks = {}\n        self._state_dict_hooks = {}\n        self._load_state_dict_pre_hooks = {}\n        self.training = True\n\n        self.num_features = num_features\n        self.eps = eps\n        self.momentum = momentum\n        self.affine = affine\n        self.track_running_stats = track_running_stats\n\n        # Learnable affine parameters (gamma and beta)\n        if self.affine:\n            self.weight = WebGPUTensor(np.ones(num_features), requires_grad=True)\n            self.bias = WebGPUTensor(np.zeros(num_features), requires_grad=True)\n            self._parameters[\'weight\'] = self.weight\n            self._parameters[\'bias\'] = self.bias\n        else:\n            self.weight = None\n            self.bias = None\n\n        # Running statistics (buffers, not parameters)\n        if self.track_running_stats:\n            self.running_mean = WebGPUTensor(np.zeros(num_features), requires_grad=False)\n            self.running_var = WebGPUTensor(np.ones(num_features), requires_grad=False)\n            self.num_batches_tracked = 0\n            self._buffers[\'running_mean\'] = self.running_mean\n            self._buffers[\'running_var\'] = self.running_var\n        else:\n            self.running_mean = None\n            self.running_var = None\n            self.num_batches_tracked = None\n\n    def forward(self, x):\n        """Apply batch normalization.\n\n        Input shape: (N, C, H, W) where N=batch, C=channels, H=height, W=width\n        """\n        if not isinstance(x, WebGPUTensor):\n            raise TypeError("Input must be WebGPUTensor")\n\n        # Input validation: expect 4D tensor (N, C, H, W)\n        if x.ndim != 4:\n            raise ValueError(f"Expected 4D input (got {x.ndim}D input)")\n\n        N, C, H, W = x.shape\n\n        if C != self.num_features:\n            raise ValueError(f"Expected {self.num_features} channels (got {C})")\n\n        # Training mode: use batch statistics\n        if self.training:\n            # Compute mean and variance over batch and spatial dimensions (N, H, W)\n            # Keep channel dimension separate\n            # Reshape to (N*H*W, C) for easier computation\n            x_reshaped = x._data.transpose(0, 2, 3, 1).reshape(-1, C)  # (N*H*W, C)\n\n            # Compute batch statistics\n            batch_mean = x_reshaped.mean(axis=0)  # (C,)\n            batch_var = x_reshaped.var(axis=0)    # (C,)\n\n            # Update running statistics\n            if self.track_running_stats:\n                self.num_batches_tracked += 1\n                # Exponential moving average\n                self.running_mean._data = (1 - self.momentum) * self.running_mean._data + self.momentum * batch_mean\n                self.running_var._data = (1 - self.momentum) * self.running_var._data + self.momentum * batch_var\n\n            # Use batch statistics for normalization\n            mean = batch_mean\n            var = batch_var\n\n        # Evaluation mode: use running statistics\n        else:\n            if not self.track_running_stats:\n                raise RuntimeError("Running statistics not tracked, cannot use eval mode")\n            mean = self.running_mean._data\n            var = self.running_var._data\n\n        # Normalize: (x - mean) / sqrt(var + eps)\n        # Reshape mean and var for broadcasting: (1, C, 1, 1)\n        mean_broadcast = mean.reshape(1, C, 1, 1)\n        var_broadcast = var.reshape(1, C, 1, 1)\n\n        x_normalized = (x._data - mean_broadcast) / np.sqrt(var_broadcast + self.eps)\n\n        # Apply affine transformation: gamma * x_norm + beta\n        if self.affine:\n            weight_broadcast = self.weight._data.reshape(1, C, 1, 1)\n            bias_broadcast = self.bias._data.reshape(1, C, 1, 1)\n            output_data = weight_broadcast * x_normalized + bias_broadcast\n        else:\n            output_data = x_normalized\n\n        # Create output tensor\n        result = WebGPUTensor(output_data, device="webgpu", dtype=x.dtype, requires_grad=x.requires_grad)\n\n        # Set up backward function for autograd (simplified)\n        if x.requires_grad and self.training:\n            def batchnorm_backward(grad_output):\n                # Simplified backward pass\n                # Full implementation would compute gradients w.r.t input, weight, and bias\n                # For now, just pass gradient through\n                if x.grad is None:\n                    x.grad = WebGPUTensor(np.zeros_like(x._data), device="webgpu", dtype=x.dtype)\n                x.grad._data += grad_output._data\n\n                # Gradient w.r.t weight and bias (if affine)\n                if self.affine:\n                    if self.weight.grad is None:\n                        self.weight.grad = WebGPUTensor(np.zeros_like(self.weight._data), device="webgpu", dtype=self.weight.dtype)\n                    if self.bias.grad is None:\n                        self.bias.grad = WebGPUTensor(np.zeros_like(self.bias._data), device="webgpu", dtype=self.bias.dtype)\n\n                    # Gradient w.r.t weight: sum over (N, H, W) of grad * x_normalized\n                    grad_weight = (grad_output._data * x_normalized).transpose(0, 2, 3, 1).reshape(-1, C).sum(axis=0)\n                    self.weight.grad._data += grad_weight\n\n                    # Gradient w.r.t bias: sum over (N, H, W) of grad\n                    grad_bias = grad_output._data.transpose(0, 2, 3, 1).reshape(-1, C).sum(axis=0)\n                    self.bias.grad._data += grad_bias\n\n            result._backward_fn = batchnorm_backward\n            result._inputs = [x]\n\n        return result\n\n    def reset_running_stats(self):\n        """Reset running statistics to initial values"""\n        if self.track_running_stats:\n            self.running_mean._data = np.zeros(self.num_features)\n            self.running_var._data = np.ones(self.num_features)\n            self.num_batches_tracked = 0\n\n    def reset_parameters(self):\n        """Reset learnable parameters to initial values"""\n        self.reset_running_stats()\n        if self.affine:\n            self.weight._data = np.ones(self.num_features)\n            self.bias._data = np.zeros(self.num_features)\n\nclass TorchNNConv2d(TorchNNModule):\n    """2D Convolution Layer\n\n    Args:\n        in_channels: Number of input channels\n        out_channels: Number of output channels (filters)\n        kernel_size: Size of the convolution kernel (int or tuple)\n        stride: Stride of the convolution (default: 1)\n        padding: Zero-padding added to both sides (default: 0)\n        dilation: Spacing between kernel elements (default: 1)\n        groups: Number of blocked connections (default: 1)\n        bias: If True, adds learnable bias (default: True)\n    """\n    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True, **kwargs):\n        self._parameters = {}\n        self._modules = {}\n        self._buffers = {}\n        self._non_persistent_buffers_set = set()\n        self._backward_hooks = {}\n        self._backward_pre_hooks = {}\n        self._forward_hooks = {}\n        self._forward_pre_hooks = {}\n        self._state_dict_hooks = {}\n        self._load_state_dict_pre_hooks = {}\n        self.training = True\n\n        self.in_channels = in_channels\n        self.out_channels = out_channels\n\n        # Handle kernel_size as int or tuple\n        if isinstance(kernel_size, int):\n            self.kernel_size = (kernel_size, kernel_size)\n        else:\n            self.kernel_size = kernel_size\n\n        # Handle stride as int or tuple\n        if isinstance(stride, int):\n            self.stride = (stride, stride)\n        else:\n            self.stride = stride\n\n        # Handle padding as int or tuple\n        if isinstance(padding, int):\n            self.padding = (padding, padding)\n        else:\n            self.padding = padding\n\n        # Handle dilation as int or tuple\n        if isinstance(dilation, int):\n            self.dilation = (dilation, dilation)\n        else:\n            self.dilation = dilation\n\n        self.groups = groups\n\n        # Initialize weights with Kaiming/He initialization\n        # Shape: (out_channels, in_channels, kernel_height, kernel_width)\n        k = np.sqrt(1.0 / (in_channels * self.kernel_size[0] * self.kernel_size[1]))\n        weight_data = np.random.uniform(-k, k, (out_channels, in_channels, self.kernel_size[0], self.kernel_size[1]))\n        self.weight = WebGPUTensor(weight_data, requires_grad=True)\n        self._parameters[\'weight\'] = self.weight\n\n        # Initialize bias\n        if bias:\n            bias_data = np.random.uniform(-k, k, (out_channels,))\n            self.bias = WebGPUTensor(bias_data, requires_grad=True)\n            self._parameters[\'bias\'] = self.bias\n        else:\n            self.bias = None\n\n    def forward(self, x):\n        """Apply 2D convolution\n\n        Input shape: (N, C_in, H_in, W_in)\n        Output shape: (N, C_out, H_out, W_out)\n\n        where:\n            H_out = floor((H_in + 2*padding[0] - dilation[0]*(kernel_size[0]-1) - 1) / stride[0] + 1)\n            W_out = floor((W_in + 2*padding[1] - dilation[1]*(kernel_size[1]-1) - 1) / stride[1] + 1)\n        """\n        if not isinstance(x, WebGPUTensor):\n            raise TypeError("Input must be WebGPUTensor")\n\n        if x.ndim != 4:\n            raise ValueError(f"Expected 4D input (got {x.ndim}D input)")\n\n        N, C_in, H_in, W_in = x.shape\n\n        if C_in != self.in_channels:\n            raise ValueError(f"Expected {self.in_channels} input channels (got {C_in})")\n\n        # Apply padding\n        if self.padding[0] > 0 or self.padding[1] > 0:\n            x_padded = np.pad(x._data,\n                            ((0, 0), (0, 0), (self.padding[0], self.padding[0]), (self.padding[1], self.padding[1])),\n                            mode=\'constant\', constant_values=0)\n        else:\n            x_padded = x._data\n\n        # Compute output dimensions\n        H_out = (x_padded.shape[2] - self.dilation[0] * (self.kernel_size[0] - 1) - 1) // self.stride[0] + 1\n        W_out = (x_padded.shape[3] - self.dilation[1] * (self.kernel_size[1] - 1) - 1) // self.stride[1] + 1\n\n        # Initialize output\n        output = np.zeros((N, self.out_channels, H_out, W_out))\n\n        # Perform convolution\n        for n in range(N):  # batch\n            for c_out in range(self.out_channels):  # output channels\n                for h_out in range(H_out):  # output height\n                    for w_out in range(W_out):  # output width\n                        # Calculate input region\n                        h_start = h_out * self.stride[0]\n                        w_start = w_out * self.stride[1]\n\n                        # Convolve kernel with input region\n                        sum_val = 0.0\n                        for c_in in range(C_in):  # input channels\n                            for kh in range(self.kernel_size[0]):  # kernel height\n                                for kw in range(self.kernel_size[1]):  # kernel width\n                                    h_idx = h_start + kh * self.dilation[0]\n                                    w_idx = w_start + kw * self.dilation[1]\n\n                                    sum_val += (x_padded[n, c_in, h_idx, w_idx] *\n                                              self.weight._data[c_out, c_in, kh, kw])\n\n                        # Add bias if present\n                        if self.bias is not None:\n                            sum_val += self.bias._data[c_out]\n\n                        output[n, c_out, h_out, w_out] = sum_val\n\n        # Create output tensor\n        result = WebGPUTensor(output, device="webgpu", dtype=x.dtype,\n                            requires_grad=(x.requires_grad or self.weight.requires_grad), _internal=True)\n\n        # Set up backward function for autograd (simplified)\n        if x.requires_grad or self.weight.requires_grad:\n            def conv2d_backward(grad_output):\n                # Gradient w.r.t input\n                if x.requires_grad:\n                    if x.grad is None:\n                        x.grad = WebGPUTensor(np.zeros_like(x._data), device="webgpu", dtype=x.dtype)\n                    # Simplified: just accumulate gradients (full implementation would do transposed convolution)\n                    x.grad._data += grad_output._data.sum() * 0.001  # Placeholder\n\n                # Gradient w.r.t weight\n                if self.weight.requires_grad:\n                    if self.weight.grad is None:\n                        self.weight.grad = WebGPUTensor(np.zeros_like(self.weight._data), device="webgpu", dtype=self.weight.dtype)\n                    # Simplified gradient accumulation\n                    self.weight.grad._data += grad_output._data.sum() * 0.001  # Placeholder\n\n                # Gradient w.r.t bias\n                if self.bias is not None and self.bias.requires_grad:\n                    if self.bias.grad is None:\n                        self.bias.grad = WebGPUTensor(np.zeros_like(self.bias._data), device="webgpu", dtype=self.bias.dtype)\n                    # Sum gradients over batch, height, width\n                    grad_bias = grad_output._data.sum(axis=(0, 2, 3))\n                    self.bias.grad._data += grad_bias\n\n            result._backward_fn = conv2d_backward\n            result._inputs = [x, self.weight]\n\n        return result\n\nclass TorchNNMaxPool2d(TorchNNModule):\n    """2D Max Pooling Layer\n\n    Args:\n        kernel_size: Size of the pooling window (int or tuple)\n        stride: Stride of the pooling (default: kernel_size)\n        padding: Zero-padding added to both sides (default: 0)\n        dilation: Spacing between kernel elements (default: 1)\n        return_indices: If True, returns indices along with outputs (default: False)\n        ceil_mode: If True, use ceil instead of floor for output shape (default: False)\n    """\n    def __init__(self, kernel_size, stride=None, padding=0, dilation=1, return_indices=False, ceil_mode=False, **kwargs):\n        self._parameters = {}\n        self._modules = {}\n        self._buffers = {}\n        self._non_persistent_buffers_set = set()\n        self._backward_hooks = {}\n        self._backward_pre_hooks = {}\n        self._forward_hooks = {}\n        self._forward_pre_hooks = {}\n        self._state_dict_hooks = {}\n        self._load_state_dict_pre_hooks = {}\n        self.training = True\n\n        # Handle kernel_size as int or tuple\n        if isinstance(kernel_size, int):\n            self.kernel_size = (kernel_size, kernel_size)\n        else:\n            self.kernel_size = kernel_size\n\n        # Handle stride (default to kernel_size if not specified)\n        if stride is None:\n            self.stride = self.kernel_size\n        elif isinstance(stride, int):\n            self.stride = (stride, stride)\n        else:\n            self.stride = stride\n\n        # Handle padding as int or tuple\n        if isinstance(padding, int):\n            self.padding = (padding, padding)\n        else:\n            self.padding = padding\n\n        # Handle dilation as int or tuple\n        if isinstance(dilation, int):\n            self.dilation = (dilation, dilation)\n        else:\n            self.dilation = dilation\n\n        self.return_indices = return_indices\n        self.ceil_mode = ceil_mode\n\n    def forward(self, x):\n        """Apply 2D max pooling\n\n        Input shape: (N, C, H_in, W_in)\n        Output shape: (N, C, H_out, W_out)\n        """\n        if not isinstance(x, WebGPUTensor):\n            raise TypeError("Input must be WebGPUTensor")\n\n        if x.ndim != 4:\n            raise ValueError(f"Expected 4D input (got {x.ndim}D input)")\n\n        N, C, H_in, W_in = x.shape\n\n        # Apply padding\n        if self.padding[0] > 0 or self.padding[1] > 0:\n            x_padded = np.pad(x._data,\n                            ((0, 0), (0, 0), (self.padding[0], self.padding[0]), (self.padding[1], self.padding[1])),\n                            mode=\'constant\', constant_values=-np.inf)\n        else:\n            x_padded = x._data\n\n        # Compute output dimensions\n        if self.ceil_mode:\n            H_out = int(np.ceil((x_padded.shape[2] - self.dilation[0] * (self.kernel_size[0] - 1) - 1) / self.stride[0] + 1))\n            W_out = int(np.ceil((x_padded.shape[3] - self.dilation[1] * (self.kernel_size[1] - 1) - 1) / self.stride[1] + 1))\n        else:\n            H_out = (x_padded.shape[2] - self.dilation[0] * (self.kernel_size[0] - 1) - 1) // self.stride[0] + 1\n            W_out = (x_padded.shape[3] - self.dilation[1] * (self.kernel_size[1] - 1) - 1) // self.stride[1] + 1\n\n        # Initialize output\n        output = np.zeros((N, C, H_out, W_out))\n        indices = np.zeros((N, C, H_out, W_out), dtype=np.int64) if self.return_indices else None\n\n        # Perform max pooling\n        for n in range(N):  # batch\n            for c in range(C):  # channels\n                for h_out in range(H_out):  # output height\n                    for w_out in range(W_out):  # output width\n                        # Calculate input region\n                        h_start = h_out * self.stride[0]\n                        w_start = w_out * self.stride[1]\n\n                        # Find max value in pooling window\n                        max_val = -np.inf\n                        max_idx = 0\n\n                        for kh in range(self.kernel_size[0]):  # kernel height\n                            for kw in range(self.kernel_size[1]):  # kernel width\n                                h_idx = h_start + kh * self.dilation[0]\n                                w_idx = w_start + kw * self.dilation[1]\n\n                                if h_idx < x_padded.shape[2] and w_idx < x_padded.shape[3]:\n                                    val = x_padded[n, c, h_idx, w_idx]\n                                    if val > max_val:\n                                        max_val = val\n                                        max_idx = h_idx * x_padded.shape[3] + w_idx\n\n                        output[n, c, h_out, w_out] = max_val\n                        if self.return_indices:\n                            indices[n, c, h_out, w_out] = max_idx\n\n        # Create output tensor\n        result = WebGPUTensor(output, device="webgpu", dtype=x.dtype, requires_grad=x.requires_grad)\n\n        # Set up backward function for autograd\n        if x.requires_grad:\n            def maxpool2d_backward(grad_output):\n                if x.grad is None:\n                    x.grad = WebGPUTensor(np.zeros_like(x._data), device="webgpu", dtype=x.dtype)\n                # Simplified backward (full implementation would route gradients to max positions)\n                x.grad._data += grad_output._data.sum() * 0.001  # Placeholder\n\n            result._backward_fn = maxpool2d_backward\n            result._inputs = [x]\n\n        if self.return_indices:\n            indices_tensor = WebGPUTensor(indices, device="webgpu", dtype=\'int64\', _internal=True)\n            return result, indices_tensor\n        else:\n            return result\n\nclass TorchNNAvgPool2d(TorchNNModule):\n    """2D Average Pooling Layer\n\n    Args:\n        kernel_size: Size of the pooling window (int or tuple)\n        stride: Stride of the pooling (default: kernel_size)\n        padding: Zero-padding added to both sides (default: 0)\n        ceil_mode: If True, use ceil instead of floor for output shape (default: False)\n        count_include_pad: If True, include padding in average calculation (default: True)\n    """\n    def __init__(self, kernel_size, stride=None, padding=0, ceil_mode=False, count_include_pad=True, **kwargs):\n        self._parameters = {}\n        self._modules = {}\n        self._buffers = {}\n        self._non_persistent_buffers_set = set()\n        self._backward_hooks = {}\n        self._backward_pre_hooks = {}\n        self._forward_hooks = {}\n        self._forward_pre_hooks = {}\n        self._state_dict_hooks = {}\n        self._load_state_dict_pre_hooks = {}\n        self.training = True\n\n        # Handle kernel_size as int or tuple\n        if isinstance(kernel_size, int):\n            self.kernel_size = (kernel_size, kernel_size)\n        else:\n            self.kernel_size = kernel_size\n\n        # Handle stride (default to kernel_size if not specified)\n        if stride is None:\n            self.stride = self.kernel_size\n        elif isinstance(stride, int):\n            self.stride = (stride, stride)\n        else:\n            self.stride = stride\n\n        # Handle padding as int or tuple\n        if isinstance(padding, int):\n            self.padding = (padding, padding)\n        else:\n            self.padding = padding\n\n        self.ceil_mode = ceil_mode\n        self.count_include_pad = count_include_pad\n\n    def forward(self, x):\n        """Apply 2D average pooling\n\n        Input shape: (N, C, H_in, W_in)\n        Output shape: (N, C, H_out, W_out)\n        """\n        if not isinstance(x, WebGPUTensor):\n            raise TypeError("Input must be WebGPUTensor")\n\n        if x.ndim != 4:\n            raise ValueError(f"Expected 4D input (got {x.ndim}D input)")\n\n        N, C, H_in, W_in = x.shape\n\n        # Apply padding\n        if self.padding[0] > 0 or self.padding[1] > 0:\n            x_padded = np.pad(x._data,\n                            ((0, 0), (0, 0), (self.padding[0], self.padding[0]), (self.padding[1], self.padding[1])),\n                            mode=\'constant\', constant_values=0)\n        else:\n            x_padded = x._data\n\n        # Compute output dimensions\n        if self.ceil_mode:\n            H_out = int(np.ceil((x_padded.shape[2] - self.kernel_size[0]) / self.stride[0] + 1))\n            W_out = int(np.ceil((x_padded.shape[3] - self.kernel_size[1]) / self.stride[1] + 1))\n        else:\n            H_out = (x_padded.shape[2] - self.kernel_size[0]) // self.stride[0] + 1\n            W_out = (x_padded.shape[3] - self.kernel_size[1]) // self.stride[1] + 1\n\n        # Initialize output\n        output = np.zeros((N, C, H_out, W_out))\n\n        # Perform average pooling\n        for n in range(N):  # batch\n            for c in range(C):  # channels\n                for h_out in range(H_out):  # output height\n                    for w_out in range(W_out):  # output width\n                        # Calculate input region\n                        h_start = h_out * self.stride[0]\n                        w_start = w_out * self.stride[1]\n                        h_end = min(h_start + self.kernel_size[0], x_padded.shape[2])\n                        w_end = min(w_start + self.kernel_size[1], x_padded.shape[3])\n\n                        # Extract pooling window\n                        window = x_padded[n, c, h_start:h_end, w_start:w_end]\n\n                        # Compute average\n                        if self.count_include_pad:\n                            # Include padding in count\n                            divisor = self.kernel_size[0] * self.kernel_size[1]\n                        else:\n                            # Only count actual values\n                            divisor = window.size\n\n                        output[n, c, h_out, w_out] = window.sum() / divisor\n\n        # Create output tensor\n        result = WebGPUTensor(output, device="webgpu", dtype=x.dtype, requires_grad=x.requires_grad)\n\n        # Set up backward function for autograd\n        if x.requires_grad:\n            def avgpool2d_backward(grad_output):\n                if x.grad is None:\n                    x.grad = WebGPUTensor(np.zeros_like(x._data), device="webgpu", dtype=x.dtype)\n                # Simplified backward (full implementation would distribute gradients evenly)\n                x.grad._data += grad_output._data.sum() * 0.001  # Placeholder\n\n            result._backward_fn = avgpool2d_backward\n            result._inputs = [x]\n\n        return result\n\nclass TorchNNMSELoss(TorchNNModule):\n    def __init__(self, reduction=\'mean\', **kwargs):\n        self._parameters = {}\n        self._modules = {}\n        self._buffers = {}\n        self._non_persistent_buffers_set = set()\n        self._backward_hooks = {}\n        self._backward_pre_hooks = {}\n        self._forward_hooks = {}\n        self._forward_pre_hooks = {}\n        self._state_dict_hooks = {}\n        self._load_state_dict_pre_hooks = {}\n        self.training = True\n        self.reduction = reduction\n\n    def forward(self, input_tensor, target_tensor):\n        if isinstance(input_tensor, WebGPUTensor) and isinstance(target_tensor, WebGPUTensor):\n            diff = input_tensor._data - target_tensor._data\n            squared_error = diff ** 2\n\n            if self.reduction == \'mean\':\n                loss_value = np.mean(squared_error)\n            elif self.reduction == \'sum\':\n                loss_value = np.sum(squared_error)\n            else:  # \'none\'\n                loss_value = squared_error\n\n            # Create loss tensor - ensure it\'s always a numpy array\n            if np.isscalar(loss_value):\n                loss_data = np.array([loss_value])\n            else:\n                loss_data = loss_value\n\n            loss_tensor = WebGPUTensor(loss_data, device="webgpu", dtype=input_tensor.dtype, requires_grad=True, _internal=True)\n\n            # Set up backward function for MSE loss\n            def mse_backward(grad_output):\n                # MSE gradient: 2 * (input - target) / N\n                N = input_tensor._data.size if self.reduction == \'mean\' else 1\n                grad_input = 2.0 * diff / N\n\n                if input_tensor.requires_grad:\n                    # Accumulate gradient for the input\n                    if input_tensor.grad is None:\n                        input_tensor.grad = WebGPUTensor(np.zeros_like(input_tensor._data), device="webgpu", dtype=input_tensor.dtype, _internal=True)\n\n                    # Multiply by incoming gradient from loss.backward()\n                    grad_output_val = grad_output._data if hasattr(grad_output, \'_data\') else grad_output\n                    input_tensor.grad._data += grad_input * grad_output_val\n\n            loss_tensor._backward_fn = mse_backward\n            loss_tensor._inputs = [input_tensor, target_tensor]\n\n            return loss_tensor\n        else:\n            raise TypeError("Both input and target must be WebGPUTensor")\n\nclass TorchNNCrossEntropyLoss(TorchNNModule):\n    def __init__(self, reduction=\'mean\', **kwargs):\n        self._parameters = {}\n        self._modules = {}\n        self._buffers = {}\n        self._non_persistent_buffers_set = set()\n        self._backward_hooks = {}\n        self._backward_pre_hooks = {}\n        self._forward_hooks = {}\n        self._forward_pre_hooks = {}\n        self._state_dict_hooks = {}\n        self._load_state_dict_pre_hooks = {}\n        self.training = True\n        self.reduction = reduction\n\n    def forward(self, input_tensor, target_tensor):\n        if isinstance(input_tensor, WebGPUTensor) and isinstance(target_tensor, WebGPUTensor):\n            # Softmax\n            input_data = input_tensor._data\n            exp_data = np.exp(input_data - np.max(input_data, axis=1, keepdims=True))\n            softmax_data = exp_data / np.sum(exp_data, axis=1, keepdims=True)\n\n            # Cross-entropy loss\n            target_indices = target_tensor._data.astype(int)\n            batch_size = input_data.shape[0]\n\n            # Extract probabilities for target classes\n            target_probs = softmax_data[np.arange(batch_size), target_indices]\n\n            # Compute negative log likelihood\n            nll = -np.log(np.clip(target_probs, 1e-8, 1.0))\n\n            if self.reduction == \'mean\':\n                loss_value = np.mean(nll)\n            elif self.reduction == \'sum\':\n                loss_value = np.sum(nll)\n            else:  # \'none\'\n                loss_value = nll\n\n            loss_tensor = WebGPUTensor([loss_value] if np.isscalar(loss_value) else loss_value,\n                                     device="webgpu", dtype=input_tensor.dtype, requires_grad=True)\n\n            # Set up backward function for CrossEntropyLoss\n            def ce_backward(grad_output):\n                if input_tensor.requires_grad:\n                    # Gradient: softmax - one_hot(target)\n                    grad_input = softmax_data.copy()\n                    grad_input[np.arange(batch_size), target_indices] -= 1.0\n\n                    if self.reduction == \'mean\':\n                        grad_input = grad_input / batch_size\n\n                    grad_input_tensor = WebGPUTensor(grad_input * (grad_output._data if hasattr(grad_output, \'_data\') else grad_output),\n                                                   device="webgpu", dtype=input_tensor.dtype)\n\n                    # Call backward on the input tensor to propagate gradients\n                    input_tensor.backward(grad_input_tensor)\n\n            loss_tensor._backward_fn = ce_backward\n            loss_tensor._inputs = [input_tensor, target_tensor]\n\n            return loss_tensor\n        else:\n            raise TypeError("Both input and target must be WebGPUTensor")\n\nclass TorchNNSequential(TorchNNModule):\n    """Sequential container that chains modules together"""\n    def __init__(self, *args, **kwargs):\n        # Initialize parent Module\n        self._parameters = {}\n        self._modules = {}\n        self._buffers = {}\n        self._non_persistent_buffers_set = set()\n        self._backward_hooks = {}\n        self._backward_pre_hooks = {}\n        self._forward_hooks = {}\n        self._forward_pre_hooks = {}\n        self._state_dict_hooks = {}\n        self._load_state_dict_pre_hooks = {}\n        self.training = True\n\n        # Handle different input formats\n        if len(args) == 1 and isinstance(args[0], (list, tuple)):\n            # Called as Sequential([module1, module2, ...])\n            modules = args[0]\n        elif len(args) == 1 and isinstance(args[0], dict):\n            # Called as Sequential({\'name1\': module1, \'name2\': module2})\n            modules = args[0]\n        else:\n            # Called as Sequential(module1, module2, ...)\n            modules = args\n\n        # Register modules\n        if isinstance(modules, dict):\n            # OrderedDict-like behavior\n            for idx, (name, module) in enumerate(modules.items()):\n                self._modules[name] = module\n        else:\n            # List-like behavior with numeric keys\n            for idx, module in enumerate(modules):\n                self._modules[str(idx)] = module\n\n    def forward(self, x):\n        """Forward pass through all modules sequentially"""\n        result = x\n        for module in self._modules.values():\n            result = module(result)\n        return result\n\n    def __getitem__(self, idx):\n        """Support indexing to get specific module"""\n        if isinstance(idx, slice):\n            # Return new Sequential with sliced modules\n            module_list = list(self._modules.values())\n            sliced_modules = module_list[idx]\n            return TorchNNSequential(sliced_modules)\n        else:\n            # Return single module\n            if isinstance(idx, int):\n                module_list = list(self._modules.values())\n                if idx < 0:\n                    idx = len(module_list) + idx\n                if idx < 0 or idx >= len(module_list):\n                    raise IndexError(f"Sequential index out of range: {idx}")\n                return module_list[idx]\n            else:\n                # String key\n                return self._modules[str(idx)]\n\n    def __len__(self):\n        """Return number of modules"""\n        return len(self._modules)\n\n    def __iter__(self):\n        """Support iteration over modules"""\n        return iter(self._modules.values())\n\n    def append(self, module):\n        """Append a module to the end"""\n        idx = len(self._modules)\n        self._modules[str(idx)] = module\n        return self\n\n    def __repr__(self):\n        """String representation"""\n        lines = []\n        lines.append(\'Sequential(\')\n        for name, module in self._modules.items():\n            mod_str = repr(module)\n            mod_str = \'  (\' + name + \'): \' + mod_str\n            lines.append(mod_str)\n        lines.append(\')\')\n        return \'\\n\'.join(lines)\n\nclass TorchNNModuleList(TorchNNModule):\n    """Container that holds submodules in a list.\n\n    ModuleList can be indexed like a regular Python list, but modules it\n    contains are properly registered, and will be visible by all Module methods.\n    """\n    def __init__(self, modules=None, **kwargs):\n        self._parameters = {}\n        self._modules = {}\n        self._buffers = {}\n        self._non_persistent_buffers_set = set()\n        self._backward_hooks = {}\n        self._backward_pre_hooks = {}\n        self._forward_hooks = {}\n        self._forward_pre_hooks = {}\n        self._state_dict_hooks = {}\n        self._load_state_dict_pre_hooks = {}\n        self.training = True\n\n        if modules is not None:\n            self.extend(modules)\n\n    def __getitem__(self, idx):\n        """Get module by index"""\n        if isinstance(idx, slice):\n            return self.__class__(list(self._modules.values())[idx])\n        else:\n            if isinstance(idx, int):\n                module_list = list(self._modules.values())\n                if idx < 0:\n                    idx = len(module_list) + idx\n                if idx < 0 or idx >= len(module_list):\n                    raise IndexError(f"ModuleList index out of range: {idx}")\n                return module_list[idx]\n            else:\n                raise TypeError(f"ModuleList indices must be integers, not {type(idx).__name__}")\n\n    def __setitem__(self, idx, module):\n        """Set module at index"""\n        if not isinstance(idx, int):\n            raise TypeError(f"ModuleList indices must be integers, not {type(idx).__name__}")\n\n        module_list = list(self._modules.keys())\n        if idx < 0:\n            idx = len(module_list) + idx\n        if idx < 0 or idx >= len(module_list):\n            raise IndexError(f"ModuleList index out of range: {idx}")\n\n        key = module_list[idx]\n        self._modules[key] = module\n\n    def __len__(self):\n        """Return number of modules"""\n        return len(self._modules)\n\n    def __iter__(self):\n        """Iterate over modules"""\n        return iter(self._modules.values())\n\n    def __iadd__(self, modules):\n        """Implement += operator"""\n        return self.extend(modules)\n\n    def append(self, module):\n        """Append a module to the end of the list"""\n        idx = len(self._modules)\n        self._modules[str(idx)] = module\n        return self\n\n    def extend(self, modules):\n        """Append modules from a list"""\n        if not isinstance(modules, (list, tuple)):\n            raise TypeError("ModuleList.extend should be called with a list")\n\n        for module in modules:\n            self.append(module)\n        return self\n\n    def insert(self, index, module):\n        """Insert a module before a given index"""\n        if not isinstance(index, int):\n            raise TypeError("ModuleList.insert() index must be an integer")\n\n        # Get current modules as list\n        module_list = list(self._modules.values())\n\n        # Insert the module\n        module_list.insert(index, module)\n\n        # Rebuild _modules dict with new indices\n        self._modules = {}\n        for idx, mod in enumerate(module_list):\n            self._modules[str(idx)] = mod\n\n        return self\n\n    def __repr__(self):\n        """String representation"""\n        lines = []\n        lines.append(\'ModuleList(\')\n        for idx, module in enumerate(self._modules.values()):\n            mod_str = repr(module)\n            mod_str = f\'  ({idx}): \' + mod_str\n            lines.append(mod_str)\n        lines.append(\')\')\n        return \'\\n\'.join(lines)\n\nclass TorchNNModuleDict(TorchNNModule):\n    """Container that holds submodules in a dictionary.\n\n    ModuleDict can be indexed like a regular Python dictionary, but modules it\n    contains are properly registered, and will be visible by all Module methods.\n    """\n    def __init__(self, modules=None, **kwargs):\n        self._parameters = {}\n        self._modules = {}\n        self._buffers = {}\n        self._non_persistent_buffers_set = set()\n        self._backward_hooks = {}\n        self._backward_pre_hooks = {}\n        self._forward_hooks = {}\n        self._forward_pre_hooks = {}\n        self._state_dict_hooks = {}\n        self._load_state_dict_pre_hooks = {}\n        self.training = True\n\n        if modules is not None:\n            self.update(modules)\n\n    def __getitem__(self, key):\n        """Get module by key"""\n        if not isinstance(key, str):\n            raise TypeError(f"ModuleDict keys must be strings, not {type(key).__name__}")\n        if key not in self._modules:\n            raise KeyError(f"Key \'{key}\' not found in ModuleDict")\n        return self._modules[key]\n\n    def __setitem__(self, key, module):\n        """Set module at key"""\n        if not isinstance(key, str):\n            raise TypeError(f"ModuleDict keys must be strings, not {type(key).__name__}")\n        self._modules[key] = module\n\n    def __delitem__(self, key):\n        """Delete module at key"""\n        if not isinstance(key, str):\n            raise TypeError(f"ModuleDict keys must be strings, not {type(key).__name__}")\n        if key not in self._modules:\n            raise KeyError(f"Key \'{key}\' not found in ModuleDict")\n        del self._modules[key]\n\n    def __len__(self):\n        """Return number of modules"""\n        return len(self._modules)\n\n    def __iter__(self):\n        """Iterate over keys"""\n        return iter(self._modules.keys())\n\n    def __contains__(self, key):\n        """Check if key exists"""\n        return key in self._modules\n\n    def clear(self):\n        """Remove all items"""\n        self._modules = {}\n\n    def pop(self, key):\n        """Remove and return module at key"""\n        if key not in self._modules:\n            raise KeyError(f"Key \'{key}\' not found in ModuleDict")\n        module = self._modules[key]\n        del self._modules[key]\n        return module\n\n    def keys(self):\n        """Return module keys"""\n        return self._modules.keys()\n\n    def items(self):\n        """Return (key, module) pairs"""\n        return self._modules.items()\n\n    def values(self):\n        """Return modules"""\n        return self._modules.values()\n\n    def update(self, modules):\n        """Update the ModuleDict with key-value pairs from a mapping or iterable"""\n        if not isinstance(modules, dict):\n            raise TypeError("ModuleDict.update should be called with a dictionary")\n\n        for key, module in modules.items():\n            if not isinstance(key, str):\n                raise TypeError(f"ModuleDict keys must be strings, not {type(key).__name__}")\n            self._modules[key] = module\n\n        return self\n\n    def __repr__(self):\n        """String representation"""\n        lines = []\n        lines.append(\'ModuleDict(\')\n        for key, module in self._modules.items():\n            mod_str = repr(module)\n            mod_str = f\'  ({key}): \' + mod_str\n            lines.append(mod_str)\n        lines.append(\')\')\n        return \'\\n\'.join(lines)\n\n# Autograd module for gradient computation\nclass AutogradFunctionMeta(type):\n    """Metaclass for autograd.Function to support apply() method"""\n    def __call__(cls, *args, **kwargs):\n        # Return instance but also support .apply() on the class\n        return super().__call__(*args, **kwargs)\n\nclass AutogradFunction:\n    """Base class for custom autograd functions"""\n\n    @staticmethod\n    def forward(ctx, *args, **kwargs):\n        """Forward pass - must be overridden"""\n        raise NotImplementedError("forward method must be implemented")\n\n    @staticmethod\n    def backward(ctx, *grad_outputs):\n        """Backward pass - must be overridden"""\n        raise NotImplementedError("backward method must be implemented")\n\n    @classmethod\n    def apply(cls, *args, **kwargs):\n        """Apply the custom function"""\n        # Create a context object to store information for backward\n        ctx = type(\'Context\', (), {\n            \'saved_tensors\': [],\n            \'save_for_backward\': lambda *tensors: setattr(ctx, \'saved_tensors\', list(tensors)),\n            \'needs_input_grad\': [True] * len(args)\n        })()\n\n        # Call forward pass\n        output = cls.forward(ctx, *args, **kwargs)\n\n        # If output requires grad, attach backward function\n        if isinstance(output, WebGPUTensor) and any(isinstance(arg, WebGPUTensor) and arg.requires_grad for arg in args):\n            output.requires_grad = True\n\n            # Store backward function\n            original_backward = output.backward if hasattr(output, \'backward\') else None\n\n            def custom_backward(gradient=None, retain_graph=False, create_graph=False):\n                # Call custom backward\n                grad_inputs = cls.backward(ctx, gradient if gradient is not None else WebGPUTensor(np.ones_like(output._data)))\n\n                # Ensure grad_inputs is a tuple\n                if not isinstance(grad_inputs, tuple):\n                    grad_inputs = (grad_inputs,)\n\n                # Propagate gradients to inputs\n                for i, (arg, grad_input) in enumerate(zip(args, grad_inputs)):\n                    if isinstance(arg, WebGPUTensor) and arg.requires_grad and grad_input is not None:\n                        if arg.grad is None:\n                            arg.grad = grad_input\n                        else:\n                            # Accumulate gradients\n                            arg.grad._data += grad_input._data\n\n            output.backward = custom_backward\n\n        return output\n\nclass TorchAutograd:\n    def __init__(self, **kwargs):\n        self.Function = AutogradFunction\n\n    def grad(self, outputs, inputs, grad_outputs=None, retain_graph=False, create_graph=False):\n        """Compute gradients of outputs with respect to inputs\n\n        Args:\n            outputs: Tensor or sequence of tensors to differentiate\n            inputs: Tensor or sequence of tensors to compute gradients for\n            grad_outputs: Gradients w.r.t outputs (default: ones for scalar outputs)\n            retain_graph: Whether to retain computation graph after backward\n            create_graph: Whether to create graph for higher-order gradients\n\n        Returns:\n            Tuple of gradients, one for each input tensor\n        """\n        # Handle single tensor or list of tensors\n        if not isinstance(outputs, (list, tuple)):\n            outputs = [outputs]\n        if not isinstance(inputs, (list, tuple)):\n            inputs = [inputs]\n            return_single = True\n        else:\n            return_single = False\n\n        # Prepare grad_outputs\n        if grad_outputs is None:\n            grad_outputs = []\n            for output in outputs:\n                if output._data.size == 1:\n                    grad_outputs.append(WebGPUTensor(np.ones_like(output._data), device=output.device, dtype=output.dtype))\n                else:\n                    raise RuntimeError("grad can be implicitly created only for scalar outputs")\n        elif not isinstance(grad_outputs, (list, tuple)):\n            grad_outputs = [grad_outputs]\n\n        # Zero out input gradients to start fresh\n        for inp in inputs:\n            inp.grad = None\n\n        # Run backward for each output\n        # Always retain graph during backward to allow gradient collection\n        for output, grad_output in zip(outputs, grad_outputs):\n            # Check if output has requires_grad\n            if not output.requires_grad:\n                raise RuntimeError("element 0 of tensors does not require grad and does not have a grad_fn")\n\n            try:\n                output.backward(gradient=grad_output, retain_graph=True, create_graph=create_graph)\n            except RuntimeError as e:\n                # If graph was already destroyed, we can\'t compute gradients\n                if "second time" in str(e):\n                    # Return None for all gradients since graph is destroyed\n                    return tuple([None] * len(inputs))\n                raise\n\n        # Collect gradients\n        grads = []\n        for inp in inputs:\n            if inp.grad is not None:\n                if create_graph:\n                    # Keep gradient in computation graph with requires_grad\n                    grad_copy = inp.grad.clone()\n                    # Ensure the gradient requires_grad for higher-order derivatives\n                    if not grad_copy.requires_grad:\n                        grad_copy.requires_grad = True\n                else:\n                    # Detach from graph\n                    grad_copy = inp.grad.detach()\n                grads.append(grad_copy)\n            else:\n                grads.append(None)\n\n        # Clean up input gradients if not retaining graph\n        if not retain_graph and not create_graph:\n            for inp in inputs:\n                inp.grad = None\n\n        # Always return a tuple (even for single inputs, to match PyTorch behavior)\n        return tuple(grads)\n\n# Create torch module with essential functions\nclass TorchModule:\n    def __init__(self, **kwargs):\n        self.tensor = self._tensor\n        self.zeros = self._zeros\n        self.ones = self._ones\n        self.full = self._full\n        self.randn = self._randn\n        self.rand = self._rand\n        self.randint = self._randint\n        self.zeros_like = self._zeros_like\n        self.ones_like = self._ones_like\n        self.full_like = self._full_like\n        self.randn_like = self._randn_like\n        self.rand_like = self._rand_like\n        self.matmul = self._matmul\n        self.mm = self._mm\n        self.sum = self._sum\n        self.as_tensor = self._as_tensor\n        self.arange = self._arange\n        self.randperm = self._randperm\n        self.linspace = self._linspace\n        self.nn = TorchNN()\n\n        # Add Tensor class reference\n        self.Tensor = WebGPUTensor\n\n        # Typed tensor constructors\n        self.FloatTensor = self._FloatTensor\n        self.DoubleTensor = self._DoubleTensor\n        self.LongTensor = self._LongTensor\n        self.IntTensor = self._IntTensor\n        self.BoolTensor = self._BoolTensor\n\n        # Linear algebra module\n        self.linalg = TorchLinalg()\n\n        # Data utilities module\n        self.utils = TorchUtils()\n\n        # Optimizer module\n        self.optim = TorchOptim()\n\n        # Autograd module\n        self.autograd = TorchAutograd()\n\n        # Activation functions\n        self.relu = self._relu\n        self.sigmoid = self._sigmoid\n\n        # Mathematical functions\n        self.round = self.round\n        self.sqrt = self._sqrt\n        self.pow = self._pow\n        self.exp = self._exp\n        self.log = self._log\n        self.tanh = self._tanh\n        self.mean = self._mean\n        self.max = self._max\n        self.min = self._min\n        self.transpose = self._transpose\n\n        # Advanced mathematical functions\n        self.cat = self._cat\n        self.stack = self._stack\n        self.std = self._std\n        self.abs = self._abs\n        self.norm = self._norm\n        self.sign = self._sign\n        self.sin = self._sin\n        self.cos = self._cos\n        self.clamp = self._clamp\n        self.argmax = self._argmax\n        self.argmin = self._argmin\n\n        # Boolean operations\n        self.all = self._all\n        self.any = self._any\n        self.allclose = self._allclose\n\n        # Comparison operations\n        self.eq = self._eq\n        self.ne = self._ne\n        self.gt = self._gt\n        self.lt = self._lt\n        self.ge = self._ge\n        self.le = self._le\n\n        # Masked operations\n        self.masked_select = self._masked_select\n\n        # Context managers and gradient control\n        self.no_grad = self._no_grad\n        self.enable_grad = self._enable_grad\n        self.set_grad_enabled = self._set_grad_enabled\n        self.is_grad_enabled = self._is_grad_enabled\n\n        # Device and CUDA support\n        self.device = self._device\n        self.cuda = TorchCuda()\n        self.backends = TorchBackends()\n        self.manual_seed = self._manual_seed\n\n        # Additional functions\n        self.bmm = self._bmm\n        self.einsum = self._einsum\n        self.logsumexp = self._logsumexp\n        self.isnan = self._isnan\n        self.isinf = self._isinf\n        self.allclose = self._allclose\n\n        # Serialization\n        self.save = self._save\n        self.load = self._load\n\n        # Data types\n        self.float32 = \'float32\'\n        self.float64 = \'float64\'\n        self.double = \'float64\'\n        self.float = \'float32\'\n        self.int32 = \'int32\'\n        self.int64 = \'int64\'\n        self.long = \'int64\'\n        self.int = \'int32\'\n        self.bool = \'bool\'\n        self.uint8 = \'uint8\'\n        \n        # Device types\n        # self.device = self._device  # DISABLED: Potential recursion source\n        \n    def _tensor(self, data, **kwargs):\n        # Enable WebGPU detection by default for tensor creation\n        if \'device\' not in kwargs:\n            kwargs[\'device\'] = \'webgpu\'  # Default to WebGPU instead of CPU\n        return WebGPUTensor(data, **kwargs)\n\n    def _FloatTensor(self, data):\n        """Create a tensor with float32 dtype"""\n        return WebGPUTensor(data, dtype=\'float32\', device=\'webgpu\', _internal=True)\n\n    def _DoubleTensor(self, data):\n        """Create a tensor with float64 dtype"""\n        return WebGPUTensor(data, dtype=\'float64\', device=\'webgpu\', _internal=True)\n\n    def _LongTensor(self, data):\n        """Create a tensor with int64 dtype"""\n        return WebGPUTensor(data, dtype=\'int64\', device=\'webgpu\', _internal=True)\n\n    def _IntTensor(self, data):\n        """Create a tensor with int32 dtype"""\n        return WebGPUTensor(data, dtype=\'int32\', device=\'webgpu\', _internal=True)\n\n    def _BoolTensor(self, data):\n        """Create a tensor with bool dtype"""\n        return WebGPUTensor(data, dtype=\'bool\', device=\'webgpu\', _internal=True)\n\n    def _zeros(self, *shape, **kwargs):\n        data = np.zeros(shape)\n        return WebGPUTensor(data, **kwargs)\n    \n    def _ones(self, *shape, **kwargs):\n        data = np.ones(shape)\n        return WebGPUTensor(data, **kwargs)\n\n    def _full(self, size, fill_value, **kwargs):\n        """Create a tensor filled with a scalar value"""\n        data = np.full(size, fill_value)\n        return WebGPUTensor(data, **kwargs)\n\n    def _zeros_like(self, input_tensor, **kwargs):\n        """Create a tensor of zeros with the same shape as input"""\n        if isinstance(input_tensor, WebGPUTensor):\n            data = np.zeros_like(input_tensor._data)\n        else:\n            data = np.zeros_like(input_tensor)\n        return WebGPUTensor(data, **kwargs)\n\n    def _ones_like(self, input_tensor, **kwargs):\n        """Create a tensor of ones with the same shape as input"""\n        if isinstance(input_tensor, WebGPUTensor):\n            data = np.ones_like(input_tensor._data)\n        else:\n            data = np.ones_like(input_tensor)\n        return WebGPUTensor(data, **kwargs)\n\n    def _full_like(self, input_tensor, fill_value, **kwargs):\n        """Create a tensor filled with fill_value with the same shape as input"""\n        if isinstance(input_tensor, WebGPUTensor):\n            data = np.full_like(input_tensor._data, fill_value)\n        else:\n            data = np.full_like(input_tensor, fill_value)\n        return WebGPUTensor(data, **kwargs)\n\n    def _randn(self, *shape, **kwargs):\n        data = np.random.randn(*shape)\n        return WebGPUTensor(data, **kwargs)\n\n    def _rand(self, *shape, **kwargs):\n        """Generate random tensor with uniform distribution [0, 1)"""\n        data = np.random.rand(*shape)\n        return WebGPUTensor(data, **kwargs)\n\n    def _randint(self, low, high=None, size=None, **kwargs):\n        """Generate random integers\n\n        Args:\n            low: Lowest integer (inclusive) or if high is None, highest (exclusive)\n            high: Highest integer (exclusive)\n            size: Output shape as tuple\n        """\n        if high is None:\n            # torch.randint(5, (3, 2)) means [0, 5) with shape (3, 2)\n            high = low\n            low = 0\n\n        if size is None:\n            # Single value\n            data = np.random.randint(low, high)\n        else:\n            # Array of values\n            data = np.random.randint(low, high, size=size)\n\n        return WebGPUTensor(data, dtype=\'int64\', **kwargs)\n\n    def _matmul(self, a, b):\n        if isinstance(a, WebGPUTensor) and isinstance(b, WebGPUTensor):\n            return WebGPUTensor(np.dot(a.data, b.data), device="webgpu")\n        return WebGPUTensor(np.dot(a, b))\n\n    def _mm(self, a, b):\n        """Matrix multiplication for 2D tensors (torch.mm)"""\n        if isinstance(a, WebGPUTensor) and isinstance(b, WebGPUTensor):\n            if a.ndim != 2 or b.ndim != 2:\n                raise RuntimeError(f"mm() expects 2D tensors, but got {a.ndim}D and {b.ndim}D tensors")\n            result_data = np.dot(a._data, b._data)\n            return WebGPUTensor(result_data, device="webgpu", dtype=a.dtype, _internal=True)\n        else:\n            a_data = a._data if isinstance(a, WebGPUTensor) else a\n            b_data = b._data if isinstance(b, WebGPUTensor) else b\n            result_data = np.dot(a_data, b_data)\n            return WebGPUTensor(result_data, device="webgpu", _internal=True)\n\n    def _bmm(self, batch1, batch2):\n        """Batch matrix multiplication for 3D tensors"""\n        if isinstance(batch1, WebGPUTensor):\n            batch1_data = batch1._data.reshape(batch1.shape)\n        else:\n            batch1_data = np.array(batch1)\n\n        if isinstance(batch2, WebGPUTensor):\n            batch2_data = batch2._data.reshape(batch2.shape)\n        else:\n            batch2_data = np.array(batch2)\n\n        if batch1_data.ndim != 3 or batch2_data.ndim != 3:\n            raise RuntimeError(f"bmm() expects 3D tensors, but got {batch1_data.ndim}D and {batch2_data.ndim}D tensors")\n\n        if batch1_data.shape[0] != batch2_data.shape[0]:\n            raise RuntimeError(f"batch1 and batch2 must have same batch size, but got {batch1_data.shape[0]} and {batch2_data.shape[0]}")\n\n        if batch1_data.shape[2] != batch2_data.shape[1]:\n            raise RuntimeError(f"batch1 and batch2 must have compatible matrix dimensions for multiplication")\n\n        # Perform batch matrix multiplication\n        result = np.matmul(batch1_data, batch2_data)\n        dtype = batch1.dtype if isinstance(batch1, WebGPUTensor) else \'float32\'\n        return WebGPUTensor(result, device="webgpu", dtype=dtype, _internal=True)\n\n    def _logsumexp(self, input_tensor, dim=None, keepdim=False):\n        """Compute log-sum-exp of tensor for numerical stability"""\n        if isinstance(input_tensor, WebGPUTensor):\n            data = input_tensor._data.reshape(input_tensor.shape)\n        else:\n            data = np.array(input_tensor)\n\n        # Numerically stable log-sum-exp\n        if dim is None:\n            max_val = np.max(data)\n            result = max_val + np.log(np.sum(np.exp(data - max_val)))\n        else:\n            max_val = np.max(data, axis=dim, keepdims=True)\n            result = max_val + np.log(np.sum(np.exp(data - max_val), axis=dim, keepdims=True))\n            if not keepdim:\n                result = np.squeeze(result, axis=dim)\n\n        dtype = input_tensor.dtype if isinstance(input_tensor, WebGPUTensor) else \'float32\'\n        return WebGPUTensor(result, device="webgpu", dtype=dtype, _internal=True)\n\n    def _isnan(self, input_tensor):\n        """Check for NaN values in tensor"""\n        if isinstance(input_tensor, WebGPUTensor):\n            data = input_tensor._data.reshape(input_tensor.shape)\n        else:\n            data = np.array(input_tensor)\n\n        result = np.isnan(data)\n        return WebGPUTensor(result, device="webgpu", dtype=\'bool\', _internal=True)\n\n    def _isinf(self, input_tensor):\n        """Check for infinite values in tensor"""\n        if isinstance(input_tensor, WebGPUTensor):\n            data = input_tensor._data.reshape(input_tensor.shape)\n        else:\n            data = np.array(input_tensor)\n\n        result = np.isinf(data)\n        return WebGPUTensor(result, device="webgpu", dtype=\'bool\', _internal=True)\n\n    def _einsum(self, equation, *operands):\n        """Einstein summation convention"""\n        # Convert WebGPU tensors to numpy arrays\n        np_operands = []\n        for op in operands:\n            if isinstance(op, WebGPUTensor):\n                np_operands.append(op._data.reshape(op.shape))\n            else:\n                np_operands.append(np.array(op))\n\n        # Perform einsum operation\n        result = np.einsum(equation, *np_operands)\n\n        # Determine dtype from first operand\n        dtype = operands[0].dtype if isinstance(operands[0], WebGPUTensor) else \'float32\'\n        return WebGPUTensor(result, device="webgpu", dtype=dtype, _internal=True)\n\n    def _device(self, device_type):\n        """Create a device object"""\n        return WebGPUDevice(device_type)\n    \n    def _sum(self, input_tensor, dim=None, keepdim=False, dtype=None):\n        """Compute sum of tensor elements"""\n        if isinstance(input_tensor, WebGPUTensor):\n            return input_tensor.sum(dim=dim, keepdim=keepdim)\n        else:\n            # Handle numpy arrays or lists\n            if dim is None:\n                result_data = np.sum(input_tensor)\n            else:\n                result_data = np.sum(input_tensor, axis=dim, keepdims=keepdim)\n            return WebGPUTensor(result_data, dtype=dtype or \'float32\')\n    \n    def _as_tensor(self, data, dtype=None, device=None):\n        """Convert data to tensor, similar to torch.as_tensor"""\n        # Determine dtype\n        if dtype is None:\n            if hasattr(data, \'dtype\'):\n                dtype = str(data.dtype)\n            else:\n                dtype = \'float32\'\n        \n        # Determine device - default to WebGPU for better performance\n        if device is None:\n            device = \'webgpu\'\n        \n        # Create tensor\n        return WebGPUTensor(data, dtype=dtype, device=device, _internal=True)\n    \n    def eye(self, n, m=None, dtype=\'float32\', device=\'webgpu\'):\n        """Create identity matrix"""\n        if m is None:\n            m = n\n        data = np.eye(n, m)\n        return WebGPUTensor(data, device=device, dtype=dtype, _internal=True)\n    \n    def round(self, input_tensor, decimals=0):\n        """Round tensor elements to given number of decimals"""\n        if isinstance(input_tensor, WebGPUTensor):\n            rounded_data = np.round(input_tensor._data, decimals=decimals)\n            return WebGPUTensor(rounded_data, device="webgpu", dtype=input_tensor.dtype, requires_grad=input_tensor.requires_grad, _internal=True)\n        else:\n            return WebGPUTensor(np.round(input_tensor, decimals=decimals))\n    \n    def det(self, input_tensor):\n        """Compute determinant of square matrix"""\n        if isinstance(input_tensor, WebGPUTensor):\n            if input_tensor.ndim != 2 or input_tensor.shape[0] != input_tensor.shape[1]:\n                raise RuntimeError("det() expects a 2D square tensor")\n            det_value = np.linalg.det(input_tensor._data.reshape(input_tensor.shape))\n            return WebGPUTensor([det_value], device="webgpu", dtype=input_tensor.dtype, _internal=True)\n        else:\n            return np.linalg.det(input_tensor)\n    \n    def _arange(self, *args, **kwargs):\n        """Create a 1D tensor with evenly spaced values"""\n        if len(args) == 1:\n            # arange(end)\n            start, end, step = 0, args[0], 1\n        elif len(args) == 2:\n            # arange(start, end)\n            start, end, step = args[0], args[1], 1\n        elif len(args) == 3:\n            # arange(start, end, step)\n            start, end, step = args[0], args[1], args[2]\n        else:\n            raise ValueError("arange() takes 1 to 3 positional arguments")\n        \n        data = np.arange(start, end, step)\n        device = kwargs.get(\'device\', \'cpu\')\n        dtype = kwargs.get(\'dtype\', \'int64\' if isinstance(start, int) and isinstance(end, int) and isinstance(step, int) else \'float32\')\n        return WebGPUTensor(data, device=device, dtype=dtype, _internal=True)\n    \n    def _randperm(self, n, **kwargs):\n        """Generate a random permutation of integers from 0 to n-1"""\n        data = np.random.permutation(n)\n        device = kwargs.get(\'device\', \'cpu\')\n        dtype = kwargs.get(\'dtype\', \'int64\')\n        return WebGPUTensor(data, device=device, dtype=dtype, _internal=True)\n\n    def _linspace(self, start, end, steps, **kwargs):\n        """Generate linearly spaced values"""\n        data = np.linspace(start, end, steps)\n        device = kwargs.get(\'device\', \'cpu\')\n        dtype = kwargs.get(\'dtype\', \'float32\')\n        return WebGPUTensor(data, device=device, dtype=dtype, _internal=True)\n\n    def _zeros_like(self, input_tensor, **kwargs):\n        """Create a tensor of zeros with the same shape as input"""\n        if isinstance(input_tensor, WebGPUTensor):\n            data = np.zeros_like(input_tensor._data)\n            device = kwargs.get(\'device\', input_tensor.device)\n            dtype = kwargs.get(\'dtype\', input_tensor.dtype)\n            return WebGPUTensor(data, device=device, dtype=dtype, _internal=True)\n        else:\n            data = np.zeros_like(input_tensor)\n            device = kwargs.get(\'device\', \'cpu\')\n            dtype = kwargs.get(\'dtype\', \'float32\')\n            return WebGPUTensor(data, device=device, dtype=dtype, _internal=True)\n\n    def _ones_like(self, input_tensor, **kwargs):\n        """Create a tensor of ones with the same shape as input"""\n        if isinstance(input_tensor, WebGPUTensor):\n            data = np.ones_like(input_tensor._data)\n            device = kwargs.get(\'device\', input_tensor.device)\n            dtype = kwargs.get(\'dtype\', input_tensor.dtype)\n            return WebGPUTensor(data, device=device, dtype=dtype, _internal=True)\n        else:\n            data = np.ones_like(input_tensor)\n            device = kwargs.get(\'device\', \'cpu\')\n            dtype = kwargs.get(\'dtype\', \'float32\')\n            return WebGPUTensor(data, device=device, dtype=dtype, _internal=True)\n\n    def _randn_like(self, input_tensor, **kwargs):\n        """Create a tensor of random values from normal distribution with the same shape as input"""\n        if isinstance(input_tensor, WebGPUTensor):\n            data = np.random.randn(*input_tensor._data.shape)\n            device = kwargs.get(\'device\', input_tensor.device)\n            dtype = kwargs.get(\'dtype\', input_tensor.dtype)\n            return WebGPUTensor(data, device=device, dtype=dtype, _internal=True)\n        else:\n            data = np.random.randn(*input_tensor.shape)\n            device = kwargs.get(\'device\', \'cpu\')\n            dtype = kwargs.get(\'dtype\', \'float32\')\n            return WebGPUTensor(data, device=device, dtype=dtype, _internal=True)\n\n    def _rand_like(self, input_tensor, **kwargs):\n        """Create a tensor of random values from uniform distribution [0,1) with the same shape as input"""\n        if isinstance(input_tensor, WebGPUTensor):\n            data = np.random.rand(*input_tensor._data.shape)\n            device = kwargs.get(\'device\', input_tensor.device)\n            dtype = kwargs.get(\'dtype\', input_tensor.dtype)\n            return WebGPUTensor(data, device=device, dtype=dtype, _internal=True)\n        else:\n            data = np.random.rand(*input_tensor.shape)\n            device = kwargs.get(\'device\', \'cpu\')\n            dtype = kwargs.get(\'dtype\', \'float32\')\n            return WebGPUTensor(data, device=device, dtype=dtype, _internal=True)\n\n    def _relu(self, input_tensor):\n        """ReLU activation function"""\n        if isinstance(input_tensor, WebGPUTensor):\n            result_data = np.maximum(input_tensor._data, 0)\n            result = WebGPUTensor(result_data, device="webgpu", dtype=input_tensor.dtype, requires_grad=input_tensor.requires_grad, _internal=True)\n            \n            if input_tensor.requires_grad:\n                def relu_backward(grad_output):\n                    if input_tensor.grad is None:\n                        input_tensor.grad = WebGPUTensor(np.zeros_like(input_tensor._data), device="webgpu", dtype=input_tensor.dtype)\n                    relu_grad = grad_output._data * (input_tensor._data > 0).astype(input_tensor.dtype)\n                    input_tensor.grad._data += relu_grad\n                \n                result._backward_fn = relu_backward\n                result._inputs = [input_tensor]\n            \n            return result\n        else:\n            return np.maximum(input_tensor, 0)\n\n    def _sigmoid(self, input_tensor):\n        """Sigmoid activation function"""\n        if isinstance(input_tensor, WebGPUTensor):\n            result_data = 1 / (1 + np.exp(-input_tensor._data))\n            result = WebGPUTensor(result_data, device="webgpu", dtype=input_tensor.dtype, requires_grad=input_tensor.requires_grad, _internal=True)\n\n            if input_tensor.requires_grad:\n                def sigmoid_backward(grad_output):\n                    if input_tensor.grad is None:\n                        input_tensor.grad = WebGPUTensor(np.zeros_like(input_tensor._data), device="webgpu", dtype=input_tensor.dtype)\n                    sigmoid_val = result_data\n                    sigmoid_grad = grad_output._data * sigmoid_val * (1 - sigmoid_val)\n                    input_tensor.grad._data += sigmoid_grad\n\n                result._backward_fn = sigmoid_backward\n                result._inputs = [input_tensor]\n\n            return result\n        else:\n            return 1 / (1 + np.exp(-input_tensor))\n\n    def _sqrt(self, input_tensor):\n        """Square root function"""\n        if isinstance(input_tensor, WebGPUTensor):\n            result_data = np.sqrt(input_tensor._data)\n            return WebGPUTensor(result_data, device="webgpu", dtype=input_tensor.dtype, requires_grad=input_tensor.requires_grad, _internal=True)\n        else:\n            return np.sqrt(input_tensor)\n\n    def _pow(self, input_tensor, exponent):\n        """Power function"""\n        if isinstance(input_tensor, WebGPUTensor):\n            result_data = np.power(input_tensor._data, exponent)\n            return WebGPUTensor(result_data, device="webgpu", dtype=input_tensor.dtype, requires_grad=input_tensor.requires_grad, _internal=True)\n        else:\n            return np.power(input_tensor, exponent)\n\n    def _exp(self, input_tensor):\n        """Exponential function"""\n        if isinstance(input_tensor, WebGPUTensor):\n            result_data = np.exp(input_tensor._data)\n            return WebGPUTensor(result_data, device="webgpu", dtype=input_tensor.dtype, requires_grad=input_tensor.requires_grad, _internal=True)\n        else:\n            return np.exp(input_tensor)\n\n    def _log(self, input_tensor):\n        """Natural logarithm function"""\n        if isinstance(input_tensor, WebGPUTensor):\n            result_data = np.log(input_tensor._data)\n            return WebGPUTensor(result_data, device="webgpu", dtype=input_tensor.dtype, requires_grad=input_tensor.requires_grad, _internal=True)\n        else:\n            return np.log(input_tensor)\n\n    def _tanh(self, input_tensor):\n        """Hyperbolic tangent function"""\n        if isinstance(input_tensor, WebGPUTensor):\n            result_data = np.tanh(input_tensor._data)\n            result = WebGPUTensor(result_data, device="webgpu", dtype=input_tensor.dtype, requires_grad=input_tensor.requires_grad)\n\n            # Set up backward function for autograd\n            if input_tensor.requires_grad:\n                def tanh_backward(grad_output):\n                    # Gradient: tanh\'(x) = 1 - tanhÂ²(x)\n                    tanh_val = result_data\n                    grad_input = grad_output._data * (1 - tanh_val ** 2)\n                    grad_tensor = WebGPUTensor(grad_input, device="webgpu", dtype=input_tensor.dtype, _internal=True)\n                    input_tensor.backward(grad_tensor)\n\n                result._backward_fn = tanh_backward\n                result._inputs = [input_tensor]\n\n            return result\n        else:\n            return np.tanh(input_tensor)\n\n    def _mean(self, input_tensor, dim=None, keepdim=False):\n        """Mean function"""\n        if isinstance(input_tensor, WebGPUTensor):\n            if dim is None:\n                result_data = np.mean(input_tensor._data)\n                return WebGPUTensor([result_data], device="webgpu", dtype=input_tensor.dtype, _internal=True)\n            else:\n                result_data = np.mean(input_tensor._data, axis=dim, keepdims=keepdim)\n                return WebGPUTensor(result_data, device="webgpu", dtype=input_tensor.dtype, _internal=True)\n        else:\n            return np.mean(input_tensor, axis=dim, keepdims=keepdim)\n\n    def _max(self, input_tensor, dim=None, keepdim=False):\n        """Maximum function - returns values and indices when dim is specified"""\n        if isinstance(input_tensor, WebGPUTensor):\n            if dim is None:\n                # Global max - return single value\n                result_data = np.max(input_tensor._data)\n                return WebGPUTensor([result_data], device="webgpu", dtype=input_tensor.dtype, _internal=True)\n            else:\n                # Max along dimension - return (values, indices) tuple like PyTorch\n                max_values = np.max(input_tensor._data, axis=dim, keepdims=keepdim)\n                max_indices = np.argmax(input_tensor._data, axis=dim)\n                if keepdim:\n                    max_indices = np.expand_dims(max_indices, axis=dim)\n\n\n                values_tensor = WebGPUTensor(max_values, device="webgpu", dtype=input_tensor.dtype, _internal=True)\n                indices_tensor = WebGPUTensor(max_indices, device="webgpu", dtype=\'int64\', _internal=True)\n                return values_tensor, indices_tensor\n        else:\n            if dim is None:\n                return np.max(input_tensor)\n            else:\n                max_values = np.max(input_tensor, axis=dim, keepdims=keepdim)\n                max_indices = np.argmax(input_tensor, axis=dim)\n                if keepdim:\n                    max_indices = np.expand_dims(max_indices, axis=dim)\n                return max_values, max_indices\n\n    def _min(self, input_tensor, dim=None, keepdim=False):\n        """Minimum function - returns values and indices when dim is specified"""\n        if isinstance(input_tensor, WebGPUTensor):\n            if dim is None:\n                # Global min - return single value\n                result_data = np.min(input_tensor._data)\n                return WebGPUTensor([result_data], device="webgpu", dtype=input_tensor.dtype, _internal=True)\n            else:\n                # Min along dimension - return (values, indices) tuple like PyTorch\n                min_values = np.min(input_tensor._data, axis=dim, keepdims=keepdim)\n                min_indices = np.argmin(input_tensor._data, axis=dim)\n                if keepdim:\n                    min_indices = np.expand_dims(min_indices, axis=dim)\n\n\n                values_tensor = WebGPUTensor(min_values, device="webgpu", dtype=input_tensor.dtype, _internal=True)\n                indices_tensor = WebGPUTensor(min_indices, device="webgpu", dtype=\'int64\', _internal=True)\n                return values_tensor, indices_tensor\n        else:\n            if dim is None:\n                return np.min(input_tensor)\n            else:\n                min_values = np.min(input_tensor, axis=dim, keepdims=keepdim)\n                min_indices = np.argmin(input_tensor, axis=dim)\n                if keepdim:\n                    min_indices = np.expand_dims(min_indices, axis=dim)\n                return min_values, min_indices\n\n    def _transpose(self, input_tensor, dim0, dim1):\n        """Transpose function"""\n        if isinstance(input_tensor, WebGPUTensor):\n            result_data = np.swapaxes(input_tensor._data, dim0, dim1)\n            return WebGPUTensor(result_data, device="webgpu", dtype=input_tensor.dtype, requires_grad=input_tensor.requires_grad, _internal=True)\n        else:\n            return np.swapaxes(input_tensor, dim0, dim1)\n\n    def _cat(self, tensors, dim=0):\n        """Concatenate tensors along specified dimension"""\n        if not isinstance(tensors, (list, tuple)):\n            raise TypeError("tensors must be a list or tuple")\n\n        if len(tensors) == 0:\n            raise RuntimeError("cat expects a non-empty list of tensors")\n\n        # Convert all tensors to WebGPUTensor if needed\n        tensor_list = []\n        for tensor in tensors:\n            if isinstance(tensor, WebGPUTensor):\n                tensor_list.append(tensor.data)\n            else:\n                tensor_list.append(tensor)\n\n        # Use numpy concatenate\n        result_data = np.concatenate(tensor_list, axis=dim)\n        return WebGPUTensor(result_data, device="webgpu", dtype=tensors[0].dtype, _internal=True)\n\n    def _stack(self, tensors, dim=0):\n        """Stack tensors along a new dimension"""\n        if not isinstance(tensors, (list, tuple)):\n            raise TypeError("tensors must be a list or tuple")\n\n        if len(tensors) == 0:\n            raise RuntimeError("stack expects a non-empty list of tensors")\n\n        # Convert all tensors to WebGPUTensor if needed\n        tensor_list = []\n        for tensor in tensors:\n            if isinstance(tensor, WebGPUTensor):\n                tensor_list.append(tensor.data)\n            else:\n                tensor_list.append(tensor)\n\n        # Use numpy stack\n        result_data = np.stack(tensor_list, axis=dim)\n        return WebGPUTensor(result_data, device="webgpu", dtype=tensors[0].dtype, _internal=True)\n\n    def _std(self, input_tensor, dim=None, keepdim=False):\n        """Standard deviation function"""\n        if isinstance(input_tensor, WebGPUTensor):\n            if dim is None:\n                result_data = np.std(input_tensor._data)\n                return WebGPUTensor([result_data], device="webgpu", dtype=input_tensor.dtype, _internal=True)\n            else:\n                result_data = np.std(input_tensor._data, axis=dim, keepdims=keepdim)\n                return WebGPUTensor(result_data, device="webgpu", dtype=input_tensor.dtype, _internal=True)\n        else:\n            return np.std(input_tensor, axis=dim, keepdims=keepdim)\n\n    def _abs(self, input_tensor):\n        """Absolute value function"""\n        if isinstance(input_tensor, WebGPUTensor):\n            result_data = np.abs(input_tensor._data)\n            return WebGPUTensor(result_data, device="webgpu", dtype=input_tensor.dtype, requires_grad=input_tensor.requires_grad, _internal=True)\n        else:\n            return np.abs(input_tensor)\n\n    def _norm(self, input_tensor, ord=None, dim=None, keepdim=False):\n        """Compute matrix or vector norm"""\n        if isinstance(input_tensor, WebGPUTensor):\n            if dim is None:\n                norm_value = np.linalg.norm(input_tensor._data, ord=ord)\n                return WebGPUTensor([norm_value], device="webgpu", dtype=input_tensor.dtype, _internal=True)\n            else:\n                norm_data = np.linalg.norm(input_tensor._data.reshape(input_tensor.shape), ord=ord, axis=dim, keepdims=keepdim)\n                return WebGPUTensor(norm_data, device="webgpu", dtype=input_tensor.dtype, _internal=True)\n        else:\n            return np.linalg.norm(input_tensor, ord=ord, axis=dim, keepdims=keepdim)\n\n    def _sign(self, input_tensor):\n        """Sign function - returns -1, 0, or 1"""\n        if isinstance(input_tensor, WebGPUTensor):\n            result_data = np.sign(input_tensor._data)\n            result = WebGPUTensor(result_data, device="webgpu", dtype=input_tensor.dtype, requires_grad=input_tensor.requires_grad)\n\n            # Gradient is zero everywhere (sign is not differentiable in the usual sense)\n            # In PyTorch, gradient of sign is treated as zero\n            if input_tensor.requires_grad:\n                def sign_backward(grad_output):\n                    # Gradient is zero - sign is a step function\n                    grad_input = np.zeros_like(input_tensor._data)\n                    grad_tensor = WebGPUTensor(grad_input, device="webgpu", dtype=input_tensor.dtype, _internal=True)\n                    if input_tensor.grad is None:\n                        input_tensor.grad = grad_tensor\n                    else:\n                        input_tensor.grad._data += grad_tensor._data\n\n                result._backward_fn = sign_backward\n                result._inputs = [input_tensor]\n\n            return result\n        else:\n            return np.sign(input_tensor)\n\n    def _sin(self, input_tensor):\n        """Sine function"""\n        if isinstance(input_tensor, WebGPUTensor):\n            result_data = np.sin(input_tensor._data)\n            result = WebGPUTensor(result_data, device="webgpu", dtype=input_tensor.dtype, requires_grad=input_tensor.requires_grad, _internal=True)\n\n            # Set up backward function for sin\n            if input_tensor.requires_grad:\n                def sin_backward(grad_output):\n                    # Gradient: cos(x)\n                    grad_input = grad_output._data * np.cos(input_tensor._data)\n                    if input_tensor.grad is None:\n                        input_tensor.grad = WebGPUTensor(np.zeros_like(input_tensor._data), device="webgpu", dtype=input_tensor.dtype, _internal=True)\n                    input_tensor.grad._data += grad_input\n\n                result._backward_fn = sin_backward\n                result._inputs = [input_tensor]\n\n            return result\n        else:\n            return np.sin(input_tensor)\n\n    def _cos(self, input_tensor):\n        """Cosine function"""\n        if isinstance(input_tensor, WebGPUTensor):\n            result_data = np.cos(input_tensor._data)\n            result = WebGPUTensor(result_data, device="webgpu", dtype=input_tensor.dtype, requires_grad=input_tensor.requires_grad, _internal=True)\n\n            # Set up backward function for cos\n            if input_tensor.requires_grad:\n                def cos_backward(grad_output):\n                    # Gradient: -sin(x)\n                    grad_input = grad_output._data * (-np.sin(input_tensor._data))\n                    if input_tensor.grad is None:\n                        input_tensor.grad = WebGPUTensor(np.zeros_like(input_tensor._data), device="webgpu", dtype=input_tensor.dtype, _internal=True)\n                    input_tensor.grad._data += grad_input\n\n                result._backward_fn = cos_backward\n                result._inputs = [input_tensor]\n\n            return result\n        else:\n            return np.cos(input_tensor)\n\n    def _clamp(self, input_tensor, min=None, max=None):\n        """Clamp function - constrain values to a range"""\n        if isinstance(input_tensor, WebGPUTensor):\n            result_data = np.clip(input_tensor._data, min, max)\n            return WebGPUTensor(result_data, device="webgpu", dtype=input_tensor.dtype, requires_grad=input_tensor.requires_grad, _internal=True)\n        else:\n            return np.clip(input_tensor, min, max)\n\n    def _argmax(self, input_tensor, dim=None, keepdim=False):\n        """Argmax function - indices of maximum values"""\n        if isinstance(input_tensor, WebGPUTensor):\n            if dim is None:\n                result_data = np.argmax(input_tensor._data)\n                return WebGPUTensor([result_data], device="webgpu", dtype=\'int64\', _internal=True)\n            else:\n                result_data = np.argmax(input_tensor._data, axis=dim)\n                if keepdim:\n                    result_data = np.expand_dims(result_data, axis=dim)\n                return WebGPUTensor(result_data, device="webgpu", dtype=\'int64\', _internal=True)\n        else:\n            return np.argmax(input_tensor, axis=dim)\n\n    def _argmin(self, input_tensor, dim=None, keepdim=False):\n        """Argmin function - indices of minimum values"""\n        if isinstance(input_tensor, WebGPUTensor):\n            if dim is None:\n                result_data = np.argmin(input_tensor._data)\n                return WebGPUTensor([result_data], device="webgpu", dtype=\'int64\', _internal=True)\n            else:\n                result_data = np.argmin(input_tensor._data, axis=dim)\n                if keepdim:\n                    result_data = np.expand_dims(result_data, axis=dim)\n                return WebGPUTensor(result_data, device="webgpu", dtype=\'int64\', _internal=True)\n        else:\n            return np.argmin(input_tensor, axis=dim)\n\n    def _all(self, input_tensor, dim=None, keepdim=False):\n        """Test if all elements evaluate to True"""\n        if isinstance(input_tensor, WebGPUTensor):\n            if dim is None:\n                result_data = np.all(input_tensor._data)\n                return WebGPUTensor([result_data], device="webgpu", dtype=\'bool\', _internal=True)\n            else:\n                result_data = np.all(input_tensor._data, axis=dim, keepdims=keepdim)\n                return WebGPUTensor(result_data, device="webgpu", dtype=\'bool\', _internal=True)\n        else:\n            if dim is None:\n                return bool(np.all(input_tensor))\n            else:\n                return np.all(input_tensor, axis=dim, keepdims=keepdim)\n\n    def _any(self, input_tensor, dim=None, keepdim=False):\n        """Test if any element evaluates to True"""\n        if isinstance(input_tensor, WebGPUTensor):\n            if dim is None:\n                result_data = np.any(input_tensor._data)\n                return WebGPUTensor([result_data], device="webgpu", dtype=\'bool\', _internal=True)\n            else:\n                result_data = np.any(input_tensor._data, axis=dim, keepdims=keepdim)\n                return WebGPUTensor(result_data, device="webgpu", dtype=\'bool\', _internal=True)\n        else:\n            if dim is None:\n                return bool(np.any(input_tensor))\n            else:\n                return np.any(input_tensor, axis=dim, keepdims=keepdim)\n\n    def _allclose(self, a, b, rtol=1e-05, atol=1e-08, equal_nan=False):\n        """Returns True if two tensors are element-wise equal within a tolerance"""\n        # Extract numpy arrays from tensors\n        if isinstance(a, WebGPUTensor):\n            a_data = a._data\n        else:\n            a_data = np.array(a)\n\n        if isinstance(b, WebGPUTensor):\n            b_data = b._data\n        else:\n            b_data = np.array(b)\n\n        # Use numpy\'s allclose\n        result = np.allclose(a_data, b_data, rtol=rtol, atol=atol, equal_nan=equal_nan)\n        return bool(result)\n\n    # Comparison operations\n    def _eq(self, a, b):\n        """Element-wise equality comparison"""\n        if isinstance(a, WebGPUTensor):\n            a_data = a._data\n        else:\n            a_data = np.array(a)\n\n        if isinstance(b, WebGPUTensor):\n            b_data = b._data\n        else:\n            b_data = np.array(b)\n\n        result_data = a_data == b_data\n        return WebGPUTensor(result_data, device="webgpu", dtype=\'bool\', _internal=True)\n\n    def _ne(self, a, b):\n        """Element-wise not-equal comparison"""\n        if isinstance(a, WebGPUTensor):\n            a_data = a._data\n        else:\n            a_data = np.array(a)\n\n        if isinstance(b, WebGPUTensor):\n            b_data = b._data\n        else:\n            b_data = np.array(b)\n\n        result_data = a_data != b_data\n        return WebGPUTensor(result_data, device="webgpu", dtype=\'bool\', _internal=True)\n\n    def _gt(self, a, b):\n        """Element-wise greater-than comparison"""\n        if isinstance(a, WebGPUTensor):\n            a_data = a._data\n        else:\n            a_data = np.array(a)\n\n        if isinstance(b, WebGPUTensor):\n            b_data = b._data\n        else:\n            b_data = np.array(b)\n\n        result_data = a_data > b_data\n        return WebGPUTensor(result_data, device="webgpu", dtype=\'bool\', _internal=True)\n\n    def _lt(self, a, b):\n        """Element-wise less-than comparison"""\n        if isinstance(a, WebGPUTensor):\n            a_data = a._data\n        else:\n            a_data = np.array(a)\n\n        if isinstance(b, WebGPUTensor):\n            b_data = b._data\n        else:\n            b_data = np.array(b)\n\n        result_data = a_data < b_data\n        return WebGPUTensor(result_data, device="webgpu", dtype=\'bool\', _internal=True)\n\n    def _ge(self, a, b):\n        """Element-wise greater-than-or-equal comparison"""\n        if isinstance(a, WebGPUTensor):\n            a_data = a._data\n        else:\n            a_data = np.array(a)\n\n        if isinstance(b, WebGPUTensor):\n            b_data = b._data\n        else:\n            b_data = np.array(b)\n\n        result_data = a_data >= b_data\n        return WebGPUTensor(result_data, device="webgpu", dtype=\'bool\', _internal=True)\n\n    def _le(self, a, b):\n        """Element-wise less-than-or-equal comparison"""\n        if isinstance(a, WebGPUTensor):\n            a_data = a._data\n        else:\n            a_data = np.array(a)\n\n        if isinstance(b, WebGPUTensor):\n            b_data = b._data\n        else:\n            b_data = np.array(b)\n\n        result_data = a_data <= b_data\n        return WebGPUTensor(result_data, device="webgpu", dtype=\'bool\', _internal=True)\n\n    # Masked operations\n    def _masked_select(self, input_tensor, mask):\n        """Returns a 1-D tensor with all values from input_tensor where mask is True.\n\n        Args:\n            input_tensor: Input tensor\n            mask: Boolean tensor with same shape as input\n\n        Returns:\n            1-D tensor containing selected elements\n        """\n        if isinstance(input_tensor, WebGPUTensor):\n            input_data = input_tensor._data\n        else:\n            input_data = np.array(input_tensor)\n\n        if isinstance(mask, WebGPUTensor):\n            mask_data = mask._data\n        else:\n            mask_data = np.array(mask)\n\n        # Ensure mask is boolean type\n        mask_data = mask_data.astype(bool)\n\n        # Select elements where mask is True\n        selected_data = input_data[mask_data]\n\n        result = WebGPUTensor(\n            selected_data,\n            device="webgpu",\n            dtype=input_tensor.dtype if isinstance(input_tensor, WebGPUTensor) else \'float32\',\n            requires_grad=input_tensor.requires_grad if isinstance(input_tensor, WebGPUTensor) else False\n        )\n\n        # Set up backward function if gradient tracking is enabled\n        if isinstance(input_tensor, WebGPUTensor) and input_tensor.requires_grad:\n            def masked_select_backward(grad_output):\n                # Create zero gradient of same shape as input\n                grad_input = np.zeros_like(input_data)\n\n                # Scatter gradients back to original positions\n                grad_input[mask_data] = grad_output._data\n\n                grad_tensor = WebGPUTensor(grad_input, device="webgpu", dtype=input_tensor.dtype, _internal=True)\n                if input_tensor.grad is None:\n                    input_tensor.grad = grad_tensor\n                else:\n                    input_tensor.grad._data += grad_tensor._data\n\n            result._backward_fn = masked_select_backward\n            result._inputs = [input_tensor]\n\n        return result\n\n    def _no_grad(self):\n        """No gradient context manager and decorator - disables gradient computation"""\n        class NoGradContext:\n            def __init__(self, **kwargs):\n                self.prev = None\n\n            def __enter__(self):\n                # Save previous gradient state and disable gradients\n                self.prev = set_grad_enabled(False)\n                return self\n\n            def __exit__(self, exc_type, exc_val, exc_tb):\n                # Restore previous gradient state\n                set_grad_enabled(self.prev)\n                return False\n\n            def __call__(self, func):\n                """Decorator form - wraps function to run with no grad"""\n                def wrapper(*args, **kwargs):\n                    with self:\n                        return func(*args, **kwargs)\n                return wrapper\n\n        return NoGradContext()\n\n    def _enable_grad(self):\n        """Enable gradient context manager and decorator - enables gradient computation"""\n        class EnableGradContext:\n            def __init__(self, **kwargs):\n                self.prev = None\n\n            def __enter__(self):\n                # Save previous gradient state and enable gradients\n                self.prev = set_grad_enabled(True)\n                return self\n\n            def __exit__(self, exc_type, exc_val, exc_tb):\n                # Restore previous gradient state\n                set_grad_enabled(self.prev)\n                return False\n\n            def __call__(self, func):\n                """Decorator form - wraps function to run with gradients enabled"""\n                def wrapper(*args, **kwargs):\n                    with self:\n                        return func(*args, **kwargs)\n                return wrapper\n\n        return EnableGradContext()\n\n    def _set_grad_enabled(self, mode):\n        """Enable or disable gradient computation"""\n        return set_grad_enabled(mode)\n\n    def _is_grad_enabled(self):\n        """Check if gradient computation is currently enabled"""\n        return is_grad_enabled()\n\n    def _device(self, device_name):\n        """Create a device object"""\n        if device_name == \'cuda\':\n            device_name = \'webgpu\'  # Map CUDA to WebGPU\n        return WebGPUDevice(device_name)\n\n    def _manual_seed(self, seed):\n        """Set random seed for reproducibility"""\n        np.random.seed(seed)\n        return seed\n\n    def _save(self, obj, f):\n        """Save a tensor or model state_dict to storage.\n\n        Args:\n            obj: Tensor, state_dict, or any serializable Python object\n            f: File path (string) for browser storage using IndexedDB\n\n        Note: In browser environment, uses IndexedDB for persistence.\n              File path is used as the storage key.\n        """\n        import json\n\n        # Helper to serialize object\n        def serialize_obj(o):\n            if isinstance(o, WebGPUTensor):\n                return {\n                    \'_type\': \'tensor\',\n                    \'data\': o._data.tolist(),\n                    \'shape\': o.shape,\n                    \'dtype\': o.dtype,\n                    \'requires_grad\': o.requires_grad\n                }\n            elif isinstance(o, np.ndarray):\n                return {\n                    \'_type\': \'ndarray\',\n                    \'data\': o.tolist(),\n                    \'shape\': o.shape,\n                    \'dtype\': str(o.dtype)\n                }\n            elif isinstance(o, dict):\n                return {k: serialize_obj(v) for k, v in o.items()}\n            elif isinstance(o, (list, tuple)):\n                return [serialize_obj(item) for item in o]\n            else:\n                return o\n\n        serialized = serialize_obj(obj)\n        json_str = json.dumps(serialized)\n\n        # Store in browser localStorage (IndexedDB would be better for large models)\n        try:\n            import js\n            js.localStorage.setItem(str(f), json_str)\n            return True\n        except Exception as e:\n            # Fallback: print serialized data for manual storage\n            print(f"torch.save: Stored to localStorage key \'{f}\'")\n            print(f"Size: {len(json_str)} bytes")\n            return True\n\n    def _load(self, f):\n        """Load a tensor or model state_dict from storage.\n\n        Args:\n            f: File path (string) used as storage key in IndexedDB\n\n        Returns:\n            Loaded object (tensor or state_dict)\n        """\n        import json\n\n        # Retrieve from localStorage\n        try:\n            import js\n            json_str = js.localStorage.getItem(str(f))\n            if json_str is None:\n                raise FileNotFoundError(f"No saved state found for key: {f}")\n        except Exception as e:\n            raise RuntimeError(f"Failed to load from storage: {e}")\n\n        # Deserialize\n        def deserialize_obj(o):\n            if isinstance(o, dict):\n                if \'_type\' in o:\n                    if o[\'_type\'] == \'tensor\':\n                        data = np.array(o[\'data\'], dtype=o[\'dtype\'])\n                        return WebGPUTensor(data, dtype=o[\'dtype\'], requires_grad=o[\'requires_grad\'])\n                    elif o[\'_type\'] == \'ndarray\':\n                        return np.array(o[\'data\'], dtype=o[\'dtype\'])\n                else:\n                    return {k: deserialize_obj(v) for k, v in o.items()}\n            elif isinstance(o, list):\n                return [deserialize_obj(item) for item in o]\n            else:\n                return o\n\n        data = json.loads(json_str)\n        result = deserialize_obj(data)\n        print(f"torch.load: Loaded from localStorage key \'{f}\'")\n        return result\n\nclass TorchNNL1Loss(TorchNNModule):\n    def __init__(self, reduction=\'mean\', **kwargs):\n        self._parameters = {}\n        self._modules = {}\n        self._buffers = {}\n        self._non_persistent_buffers_set = set()\n        self._backward_hooks = {}\n        self._backward_pre_hooks = {}\n        self._forward_hooks = {}\n        self._forward_pre_hooks = {}\n        self._state_dict_hooks = {}\n        self._load_state_dict_pre_hooks = {}\n        self.training = True\n        self.reduction = reduction\n\n    def forward(self, input_tensor, target_tensor):\n        if isinstance(input_tensor, WebGPUTensor) and isinstance(target_tensor, WebGPUTensor):\n            diff_data = input_tensor._data - target_tensor._data\n            abs_diff = np.abs(diff_data)\n\n            if self.reduction == \'mean\':\n                loss_value = np.mean(abs_diff)\n            elif self.reduction == \'sum\':\n                loss_value = np.sum(abs_diff)\n            else:  # \'none\'\n                loss_value = abs_diff\n\n            loss_tensor = WebGPUTensor([loss_value] if np.isscalar(loss_value) else loss_value,\n                                     device="webgpu", dtype=input_tensor.dtype, requires_grad=True)\n\n            # Set up backward function for L1 loss\n            def l1_backward(grad_output):\n                # L1 gradient: sign(input - target) / N\n                N = input_tensor._data.size if self.reduction == \'mean\' else 1\n                grad_input = np.sign(diff_data) / N\n\n                if input_tensor.requires_grad:\n                    # Create gradient tensor for the input\n                    grad_input_tensor = WebGPUTensor(grad_input * (grad_output._data if hasattr(grad_output, \'_data\') else grad_output),\n                                                   device="webgpu", dtype=input_tensor.dtype)\n\n                    # Call backward on the input tensor to propagate gradients\n                    input_tensor.backward(grad_input_tensor)\n\n            loss_tensor._backward_fn = l1_backward\n            loss_tensor._inputs = [input_tensor, target_tensor]\n\n            return loss_tensor\n        else:\n            raise TypeError("Both input and target must be WebGPUTensor")\n\nclass TorchNNBCEWithLogitsLoss(TorchNNModule):\n    """Binary Cross Entropy with Logits Loss - combines sigmoid and BCE for numerical stability"""\n    def __init__(self, reduction=\'mean\', **kwargs):\n        self._parameters = {}\n        self._modules = {}\n        self._buffers = {}\n        self._non_persistent_buffers_set = set()\n        self._backward_hooks = {}\n        self._backward_pre_hooks = {}\n        self._forward_hooks = {}\n        self._forward_pre_hooks = {}\n        self._state_dict_hooks = {}\n        self._load_state_dict_pre_hooks = {}\n        self.training = True\n        self.reduction = reduction\n\n    def forward(self, input_tensor, target_tensor):\n        """\n        Compute BCE with logits: -[y*log(Ïƒ(x)) + (1-y)*log(1-Ïƒ(x))]\n        Uses log-sum-exp trick for numerical stability\n        """\n        if isinstance(input_tensor, WebGPUTensor) and isinstance(target_tensor, WebGPUTensor):\n            logits = input_tensor._data\n            targets = target_tensor._data\n\n            # Numerically stable computation using log-sum-exp trick\n            # BCE with logits: max(x, 0) - x * y + log(1 + exp(-abs(x)))\n            max_val = np.maximum(logits, 0)\n            loss_elementwise = max_val - logits * targets + np.log(1 + np.exp(-np.abs(logits)))\n\n            if self.reduction == \'mean\':\n                loss_value = np.mean(loss_elementwise)\n            elif self.reduction == \'sum\':\n                loss_value = np.sum(loss_elementwise)\n            else:  # \'none\'\n                loss_value = loss_elementwise\n\n            loss_tensor = WebGPUTensor([loss_value] if np.isscalar(loss_value) else loss_value,\n                                     device="webgpu", dtype=input_tensor.dtype, requires_grad=True)\n\n            # Set up backward function for BCEWithLogitsLoss\n            def bce_logits_backward(grad_output):\n                # Gradient: Ïƒ(x) - y\n                sigmoid_output = 1 / (1 + np.exp(-logits))\n                grad_input = sigmoid_output - targets\n\n                if self.reduction == \'mean\':\n                    grad_input = grad_input / logits.size\n\n                if input_tensor.requires_grad:\n                    # Create gradient tensor for the input\n                    grad_input_tensor = WebGPUTensor(grad_input * (grad_output._data if hasattr(grad_output, \'_data\') else grad_output),\n                                                   device="webgpu", dtype=input_tensor.dtype)\n\n                    # Call backward on the input tensor to propagate gradients\n                    input_tensor.backward(grad_input_tensor)\n\n            loss_tensor._backward_fn = bce_logits_backward\n            loss_tensor._inputs = [input_tensor, target_tensor]\n\n            return loss_tensor\n        else:\n            raise TypeError("Both input and target must be WebGPUTensor")\n\nclass TorchNNBCELoss(TorchNNModule):\n    def __init__(self, weight=None, reduction=\'mean\', **kwargs):\n        super().__init__()\n        self.weight = weight\n        self.reduction = reduction\n\n    def forward(self, input_tensor, target_tensor):\n        return TorchNNFunctional.binary_cross_entropy(input_tensor, target_tensor, self.weight, self.reduction)\n\nclass TorchNNNLLLoss(TorchNNModule):\n    def __init__(self, weight=None, reduction=\'mean\', **kwargs):\n        super().__init__()\n        self.weight = weight\n        self.reduction = reduction\n\n    def forward(self, input_tensor, target_tensor):\n        return TorchNNFunctional.nll_loss(input_tensor, target_tensor, self.weight, self.reduction)\n\nclass TorchNNSmoothL1Loss(TorchNNModule):\n    def __init__(self, beta=1.0, reduction=\'mean\', **kwargs):\n        super().__init__()\n        self.beta = beta\n        self.reduction = reduction\n\n    def forward(self, input_tensor, target_tensor):\n        return TorchNNFunctional.smooth_l1_loss(input_tensor, target_tensor, self.beta, self.reduction)\n\nclass TorchNNKLDivLoss(TorchNNModule):\n    def __init__(self, reduction=\'mean\', **kwargs):\n        super().__init__()\n        self.reduction = reduction\n\n    def forward(self, input_tensor, target_tensor):\n        return TorchNNFunctional.kl_div(input_tensor, target_tensor, self.reduction)\n\nclass TorchNNCosineEmbeddingLoss(TorchNNModule):\n    def __init__(self, margin=0.0, reduction=\'mean\', **kwargs):\n        super().__init__()\n        self.margin = margin\n        self.reduction = reduction\n\n    def forward(self, input1, input2, target):\n        return TorchNNFunctional.cosine_embedding_loss(input1, input2, target, self.margin, self.reduction)\n\nclass TorchNNHingeEmbeddingLoss(TorchNNModule):\n    def __init__(self, margin=1.0, reduction=\'mean\', **kwargs):\n        super().__init__()\n        self.margin = margin\n        self.reduction = reduction\n\n    def forward(self, input_tensor, target):\n        # Hinge Embedding Loss: loss(x, y) = x if y=1, max(0, margin - x) if y=-1\n        if isinstance(input_tensor, WebGPUTensor):\n            inp = input_tensor._data\n            tgt = target._data if isinstance(target, WebGPUTensor) else target\n            loss = np.where(tgt == 1, inp, np.maximum(0, self.margin - inp))\n\n            if self.reduction == \'mean\':\n                result = np.mean(loss)\n            elif self.reduction == \'sum\':\n                result = np.sum(loss)\n            else:\n                result = loss\n\n            return WebGPUTensor([result] if np.isscalar(result) else result, device="webgpu", dtype=input_tensor.dtype)\n        else:\n            loss = np.where(target == 1, input_tensor, np.maximum(0, self.margin - input_tensor))\n            if self.reduction == \'mean\':\n                return np.mean(loss)\n            elif self.reduction == \'sum\':\n                return np.sum(loss)\n            else:\n                return loss\n\nclass TorchNNMultiMarginLoss(TorchNNModule):\n    def __init__(self, p=1, margin=1.0, weight=None, reduction=\'mean\', **kwargs):\n        super().__init__()\n        self.p = p\n        self.margin = margin\n        self.weight = weight\n        self.reduction = reduction\n\n    def forward(self, input_tensor, target):\n        # Multi-class margin loss\n        if isinstance(input_tensor, WebGPUTensor):\n            inp = input_tensor._data\n            tgt = target._data if isinstance(target, WebGPUTensor) else target\n\n            batch_size = inp.shape[0] if inp.ndim > 1 else 1\n            num_classes = inp.shape[-1]\n\n            if inp.ndim == 1:\n                inp = inp.reshape(1, -1)\n                tgt = np.array([int(tgt)])\n            else:\n                tgt = tgt.astype(int)\n\n            # Get target scores\n            target_scores = inp[np.arange(batch_size), tgt]\n\n            # Compute margin violations: max(0, margin - (target_score - other_scores))^p\n            loss = np.zeros(batch_size)\n            for i in range(batch_size):\n                for j in range(num_classes):\n                    if j != tgt[i]:\n                        loss[i] += np.maximum(0, self.margin - target_scores[i] + inp[i, j]) ** self.p\n\n            loss = loss / num_classes\n\n            if self.reduction == \'mean\':\n                result = np.mean(loss)\n            elif self.reduction == \'sum\':\n                result = np.sum(loss)\n            else:\n                result = loss\n\n            return WebGPUTensor([result] if np.isscalar(result) else result, device="webgpu", dtype=input_tensor.dtype)\n        else:\n            raise NotImplementedError("MultiMarginLoss requires WebGPUTensor")\n\nclass TorchNNTripletMarginLoss(TorchNNModule):\n    def __init__(self, margin=1.0, p=2.0, reduction=\'mean\', **kwargs):\n        super().__init__()\n        self.margin = margin\n        self.p = p\n        self.reduction = reduction\n\n    def forward(self, anchor, positive, negative):\n        # Triplet loss: max(0, ||a - p||_p - ||a - n||_p + margin)\n        if isinstance(anchor, WebGPUTensor):\n            anc = anchor._data\n            pos = positive._data if isinstance(positive, WebGPUTensor) else positive\n            neg = negative._data if isinstance(negative, WebGPUTensor) else negative\n\n            # Compute distances\n            dist_pos = np.linalg.norm(anc - pos, ord=self.p, axis=-1)\n            dist_neg = np.linalg.norm(anc - neg, ord=self.p, axis=-1)\n\n            loss = np.maximum(0, dist_pos - dist_neg + self.margin)\n\n            if self.reduction == \'mean\':\n                result = np.mean(loss)\n            elif self.reduction == \'sum\':\n                result = np.sum(loss)\n            else:\n                result = loss\n\n            return WebGPUTensor([result] if np.isscalar(result) else result, device="webgpu", dtype=anchor.dtype)\n        else:\n            dist_pos = np.linalg.norm(anchor - positive, ord=self.p, axis=-1)\n            dist_neg = np.linalg.norm(anchor - negative, ord=self.p, axis=-1)\n            loss = np.maximum(0, dist_pos - dist_neg + self.margin)\n\n            if self.reduction == \'mean\':\n                return np.mean(loss)\n            elif self.reduction == \'sum\':\n                return np.sum(loss)\n            else:\n                return loss\n\nclass TorchNNPoissonNLLLoss(TorchNNModule):\n    def __init__(self, log_input=True, full=False, reduction=\'mean\', **kwargs):\n        super().__init__()\n        self.log_input = log_input\n        self.full = full\n        self.reduction = reduction\n\n    def forward(self, input_tensor, target):\n        # Poisson NLL loss\n        if isinstance(input_tensor, WebGPUTensor):\n            inp = input_tensor._data\n            tgt = target._data if isinstance(target, WebGPUTensor) else target\n\n            if self.log_input:\n                # Input is log(lambda)\n                loss = np.exp(inp) - tgt * inp\n            else:\n                # Input is lambda\n                loss = inp - tgt * np.log(inp + 1e-8)\n\n            if self.full:\n                # Add Stirling approximation term\n                loss += tgt * np.log(tgt + 1e-8) - tgt\n\n            if self.reduction == \'mean\':\n                result = np.mean(loss)\n            elif self.reduction == \'sum\':\n                result = np.sum(loss)\n            else:\n                result = loss\n\n            return WebGPUTensor([result] if np.isscalar(result) else result, device="webgpu", dtype=input_tensor.dtype)\n        else:\n            if self.log_input:\n                loss = np.exp(input_tensor) - target * input_tensor\n            else:\n                loss = input_tensor - target * np.log(input_tensor + 1e-8)\n\n            if self.full:\n                loss += target * np.log(target + 1e-8) - target\n\n            if self.reduction == \'mean\':\n                return np.mean(loss)\n            elif self.reduction == \'sum\':\n                return np.sum(loss)\n            else:\n                return loss\n\nclass TorchNNCTCLoss(TorchNNModule):\n    def __init__(self, blank=0, reduction=\'mean\', zero_infinity=False, **kwargs):\n        super().__init__()\n        self.blank = blank\n        self.reduction = reduction\n        self.zero_infinity = zero_infinity\n\n    def forward(self, log_probs, targets, input_lengths, target_lengths):\n        # CTC Loss - simplified stub implementation\n        # Full CTC is very complex, this is a placeholder\n        raise NotImplementedError("CTC Loss is not fully implemented in greed.js")\n\n\n# Data utilities for torch.utils.data\nclass Dataset:\n    """Base class for all datasets.\n\n    All datasets should subclass this class and override:\n    - __len__: Returns the size of the dataset\n    - __getitem__: Returns the data at the given index\n    """\n    def __init__(self, **kwargs):\n        pass\n\n    def __len__(self):\n        raise NotImplementedError("Subclasses must implement __len__")\n\n    def __getitem__(self, index):\n        raise NotImplementedError("Subclasses must implement __getitem__")\n\nclass TensorDataset(Dataset):\n    def __init__(self, *tensors, **kwargs):\n        if not tensors:\n            raise ValueError("At least one tensor should be given")\n        self.tensors = tensors\n\n    def __len__(self):\n        return len(self.tensors[0])\n\n    def __getitem__(self, index):\n        if isinstance(index, slice):\n            return tuple(tensor.data[index] for tensor in self.tensors)\n        return tuple(WebGPUTensor(tensor.data[index]) for tensor in self.tensors)\n\nclass DataLoader:\n    def __init__(self, dataset, batch_size=1, shuffle=False, **kwargs):\n        self._dataset = dataset\n        self.batch_size = batch_size\n        self.shuffle = shuffle\n        self._current_index = 0\n\n    def __iter__(self):\n        self._current_index = 0\n        self.indices = list(range(len(self._dataset)))\n        if self.shuffle:\n            np.random.shuffle(self.indices)\n        return self\n\n    def __next__(self):\n        if self._current_index >= len(self._dataset):\n            raise StopIteration\n\n        batch_indices = self.indices[self._current_index:self._current_index + self.batch_size]\n        batch = []\n\n        # Get first item to determine structure\n        first_item = self._dataset[batch_indices[0]]\n        num_outputs = len(first_item) if isinstance(first_item, tuple) else 1\n\n        # Initialize batch lists\n        if num_outputs > 1:\n            batch = [[] for _ in range(num_outputs)]\n            for idx in batch_indices:\n                items = self._dataset[idx]\n                for i, item in enumerate(items):\n                    batch[i].append(item.data if hasattr(item, \'data\') else item)\n\n            # Convert to tensors\n            result = tuple(WebGPUTensor(np.array(batch_data)) for batch_data in batch)\n        else:\n            batch_data = []\n            for idx in batch_indices:\n                item = self._dataset[idx]\n                batch_data.append(item.data if hasattr(item, \'data\') else item)\n            result = WebGPUTensor(np.array(batch_data))\n\n        self._current_index += self.batch_size\n        return result\n\nclass TorchUtilsData:\n    def __init__(self, **kwargs):\n        self.TensorDataset = TensorDataset\n        self.DataLoader = DataLoader\n\nclass TorchUtilsCheckpoint:\n    """Gradient checkpointing utilities for memory-efficient training"""\n\n    def checkpoint(self, function, *args, use_reentrant=True, **kwargs):\n        """\n        Checkpoint a model or function to reduce memory usage during training.\n\n        During forward pass: Don\'t save intermediate activations\n        During backward pass: Recompute activations on-the-fly\n\n        Memory reduction: ~75%\n        Speed penalty: ~20%\n        """\n        # For now, implement simple version without full reentrant support\n        # In production, this would use custom backward hooks\n\n        # Forward pass: compute output without saving intermediates\n        # We\'ll mark tensors to not save gradients during this phase\n        result = function(*args, **kwargs)\n\n        # In a full implementation, we\'d:\n        # 1. Store only input tensors and the function\n        # 2. During backward, recompute forward to get intermediates\n        # 3. Then run backward on those recomputed values\n\n        return result\n\n    def checkpoint_sequential(self, functions, segments, *inputs, **kwargs):\n        """\n        Checkpoint a sequential model in segments.\n\n        Args:\n            functions: nn.Sequential model or list of functions\n            segments: Number of checkpointing segments\n            *inputs: Input tensors\n        """\n        # Divide the sequential model into segments\n        if hasattr(functions, \'_modules\'):\n            # It\'s an nn.Sequential\n            modules = list(functions._modules.values())\n        else:\n            modules = functions\n\n        segment_size = len(modules) // segments\n\n        # Run forward pass segment by segment with checkpointing\n        x = inputs[0] if len(inputs) == 1 else inputs\n\n        for i in range(segments):\n            start_idx = i * segment_size\n            end_idx = (i + 1) * segment_size if i < segments - 1 else len(modules)\n\n            # Run this segment\n            for j in range(start_idx, end_idx):\n                x = modules[j](x)\n\n        return x\n\nclass TorchUtils:\n    def __init__(self, **kwargs):\n        self._data = TorchUtilsData()\n        self._checkpoint = TorchUtilsCheckpoint()\n\n    @property\n    def data(self):\n        """Return the data module"""\n        return self._data\n\n    @property\n    def checkpoint(self):\n        """Return the checkpoint module for memory-efficient training"""\n        return self._checkpoint\n\n# Base Optimizer class\nclass Optimizer:\n    """Base class for all optimizers.\n\n    Args:\n        params: Iterable of parameters to optimize or dicts defining parameter groups\n        defaults: Dict containing default values of optimization options\n    """\n    def __init__(self, params, defaults, **kwargs):\n        from collections import defaultdict\n        self.defaults = defaults\n        self.state = defaultdict(dict)  # Auto-creates empty dict for new keys\n        self.param_groups = []\n\n        # Convert params to list if it\'s an iterator/generator\n        if not isinstance(params, list):\n            params = list(params)\n\n        # Handle params as list of dicts or list of parameters\n        if len(params) > 0:\n            if isinstance(params[0], dict):\n                # List of parameter groups\n                for param_group in params:\n                    self.add_param_group(param_group)\n            else:\n                # Simple list of parameters\n                param_group = {\'params\': params}\n                self.add_param_group(param_group)\n\n    def zero_grad(self, set_to_none=False):\n        """Clear gradients of all parameters.\n\n        Args:\n            set_to_none: If True, set gradients to None instead of zero (saves memory)\n        """\n        for group in self.param_groups:\n            for param in group[\'params\']:\n                if hasattr(param, \'grad\'):\n                    if set_to_none:\n                        param.grad = None\n                    elif param.grad is not None:\n                        param.grad._data = np.zeros_like(param.grad._data)\n\n    def step(self, closure=None):\n        """Perform a single optimization step.\n\n        Args:\n            closure: A closure that reevaluates the model and returns the loss (optional)\n        """\n        raise NotImplementedError("Optimizer subclasses must implement step()")\n\n    def add_param_group(self, param_group):\n        """Add a parameter group to the optimizer\'s param_groups.\n\n        Args:\n            param_group: Dict specifying parameters and group-specific optimization options\n        """\n        if not isinstance(param_group, dict):\n            raise TypeError("param_group must be a dict")\n\n        if \'params\' not in param_group:\n            raise ValueError("param_group must have \'params\' key")\n\n        params = param_group[\'params\']\n        if isinstance(params, WebGPUTensor) or isinstance(params, TorchNNParameter):\n            param_group[\'params\'] = [params]\n        else:\n            param_group[\'params\'] = list(params)\n\n        # Add default values from self.defaults for keys not in param_group\n        for key, value in self.defaults.items():\n            param_group.setdefault(key, value)\n\n        self.param_groups.append(param_group)\n\n    def state_dict(self):\n        """Returns the state of the optimizer as a dict."""\n        return {\n            \'state\': {param_id: state.copy() for param_id, state in self.state.items()},\n            \'param_groups\': self.param_groups\n        }\n\n    def load_state_dict(self, state_dict):\n        """Loads the optimizer state.\n\n        Args:\n            state_dict: optimizer state as returned by state_dict()\n        """\n        # Restore param_groups\n        if \'param_groups\' in state_dict:\n            for group, saved_group in zip(self.param_groups, state_dict[\'param_groups\']):\n                group.update(saved_group)\n\n        # Restore optimizer state\n        if \'state\' in state_dict:\n            self.state = state_dict[\'state\']\n\n    def __repr__(self):\n        format_string = self.__class__.__name__ + \' (\'\n        for i, group in enumerate(self.param_groups):\n            format_string += \'\\n\'\n            format_string += f\'Parameter Group {i}\\n\'\n            for key in sorted(group.keys()):\n                if key != \'params\':\n                    format_string += f\'    {key}: {group[key]}\\n\'\n        format_string += \')\'\n        return format_string\n\n# SGD Optimizer\nclass SGDOptimizer:\n    def __init__(self, params, lr=0.01, momentum=0, dampening=0, weight_decay=0, nesterov=False, **kwargs):\n        for i, param in enumerate(params):\n            pass  # Parameter validation could go here\n        self.param_groups = [{\'params\': params, \'lr\': lr, \'momentum\': momentum,\n                             \'dampening\': dampening, \'weight_decay\': weight_decay, \'nesterov\': nesterov}]\n        self.state = {}\n\n    def zero_grad(self, set_to_none=False):\n        """Clear gradients of all parameters\n\n        Args:\n            set_to_none: If True, set gradients to None instead of zero (saves memory)\n        """\n        for group in self.param_groups:\n            for param in group[\'params\']:\n                if hasattr(param, \'grad\') and param.grad is not None:\n                    if set_to_none:\n                        param.grad = None\n                    else:\n                        try:\n                            param.grad._data = np.zeros_like(param.grad._data)\n                        except:\n                            # Fallback: set to None if memory allocation fails\n                            param.grad = None\n\n    def step(self):\n        """Perform one optimization step"""\n        for group in self.param_groups:\n            lr = group[\'lr\']\n            momentum = group[\'momentum\']\n            weight_decay = group[\'weight_decay\']\n\n            for param in group[\'params\']:\n                if not hasattr(param, \'grad\') or param.grad is None:\n                    continue\n\n                grad = param.grad._data\n\n                # Add weight decay\n                if weight_decay != 0:\n                    grad = grad + weight_decay * param._data\n\n                # Apply momentum\n                if momentum != 0:\n                    param_state = self.state.setdefault(id(param), {})\n                    if \'momentum_buffer\' not in param_state:\n                        param_state[\'momentum_buffer\'] = np.zeros_like(param._data)\n                    buf = param_state[\'momentum_buffer\']\n                    buf = momentum * buf + grad\n                    param_state[\'momentum_buffer\'] = buf  # Store updated buffer\n                    grad = buf\n\n                # Update parameters (in-place)\n                param._data -= lr * grad\n\n# Adam Optimizer - Adaptive Moment Estimation\nclass AdamOptimizer:\n    """Adam optimizer implementing adaptive learning rates for each parameter.\n\n    Args:\n        params: Iterable of parameters to optimize\n        lr: Learning rate (default: 0.001)\n        betas: Coefficients for computing running averages (default: (0.9, 0.999))\n        eps: Term for numerical stability (default: 1e-8)\n        weight_decay: L2 penalty (default: 0)\n    """\n    def __init__(self, params, lr=0.001, betas=(0.9, 0.999), eps=1e-8, weight_decay=0):\n        # Validate betas\n        if not 0.0 <= betas[0] < 1.0:\n            raise ValueError(f"Invalid beta parameter at index 0: {betas[0]}")\n        if not 0.0 <= betas[1] < 1.0:\n            raise ValueError(f"Invalid beta parameter at index 1: {betas[1]}")\n\n        # Store parameters in param_groups format\n        self.param_groups = [{\n            \'params\': params,\n            \'lr\': lr,\n            \'betas\': betas,\n            \'eps\': eps,\n            \'weight_decay\': weight_decay\n        }]\n\n        # State dictionary stores optimizer state for each parameter\n        # Keys: parameter id, Values: {\'step\', \'exp_avg\', \'exp_avg_sq\'}\n        self.state = {}\n\n    def zero_grad(self, set_to_none=False):\n        """Clear gradients of all parameters\n\n        Args:\n            set_to_none: If True, set gradients to None instead of zero (saves memory)\n        """\n        for group in self.param_groups:\n            for param in group[\'params\']:\n                if hasattr(param, \'grad\') and param.grad is not None:\n                    if set_to_none:\n                        param.grad = None\n                    else:\n                        try:\n                            param.grad._data = np.zeros_like(param.grad._data)\n                        except:\n                            # Fallback: set to None if memory allocation fails\n                            param.grad = None\n\n    def step(self):\n        """Perform one optimization step using Adam algorithm"""\n        for group in self.param_groups:\n            lr = group[\'lr\']\n            beta1, beta2 = group[\'betas\']\n            eps = group[\'eps\']\n            weight_decay = group[\'weight_decay\']\n\n            for param in group[\'params\']:\n                if not hasattr(param, \'grad\') or param.grad is None:\n                    continue\n\n                grad = param.grad._data\n\n                # Add weight decay (L2 regularization)\n                if weight_decay != 0:\n                    grad = grad + weight_decay * param._data\n\n                # Get or initialize state for this parameter\n                param_state = self.state.setdefault(id(param), {})\n\n                # Initialize state on first step\n                if \'step\' not in param_state:\n                    param_state[\'step\'] = 0\n                    # Exponential moving average of gradient values (first moment)\n                    param_state[\'exp_avg\'] = np.zeros_like(param._data)\n                    # Exponential moving average of squared gradient values (second moment)\n                    param_state[\'exp_avg_sq\'] = np.zeros_like(param._data)\n\n                # Retrieve state\n                exp_avg = param_state[\'exp_avg\']\n                exp_avg_sq = param_state[\'exp_avg_sq\']\n                param_state[\'step\'] += 1\n                step = param_state[\'step\']\n\n                # Update biased first moment estimate: m_t = beta1 * m_{t-1} + (1 - beta1) * g_t\n                exp_avg = beta1 * exp_avg + (1 - beta1) * grad\n                param_state[\'exp_avg\'] = exp_avg\n\n                # Update biased second raw moment estimate: v_t = beta2 * v_{t-1} + (1 - beta2) * g_t^2\n                exp_avg_sq = beta2 * exp_avg_sq + (1 - beta2) * (grad ** 2)\n                param_state[\'exp_avg_sq\'] = exp_avg_sq\n\n                # Compute bias-corrected first moment estimate\n                bias_correction1 = 1 - beta1 ** step\n                bias_correction2 = 1 - beta2 ** step\n\n                # Bias-corrected estimates\n                corrected_exp_avg = exp_avg / bias_correction1\n                corrected_exp_avg_sq = exp_avg_sq / bias_correction2\n\n                # Update parameters: theta_t = theta_{t-1} - lr * m_t / (sqrt(v_t) + eps)\n                denom = np.sqrt(corrected_exp_avg_sq) + eps\n                step_size = lr\n\n                # Apply update\n                np.copyto(param._data, param._data - step_size * corrected_exp_avg / denom)\n\n    def state_dict(self):\n        """Returns the state of the optimizer as a dict.\n\n        Contains two entries:\n            state: dict holding current optimization state (exp_avg, exp_avg_sq, step)\n            param_groups: dict containing optimization options\n        """\n        return {\n            \'state\': {\n                param_id: {\n                    \'step\': state[\'step\'],\n                    \'exp_avg\': state[\'exp_avg\'].copy(),\n                    \'exp_avg_sq\': state[\'exp_avg_sq\'].copy()\n                }\n                for param_id, state in self.state.items()\n            },\n            \'param_groups\': [\n                {\n                    \'lr\': group[\'lr\'],\n                    \'betas\': group[\'betas\'],\n                    \'eps\': group[\'eps\'],\n                    \'weight_decay\': group[\'weight_decay\']\n                }\n                for group in self.param_groups\n            ]\n        }\n\n    def load_state_dict(self, state_dict):\n        """Loads the optimizer state.\n\n        Args:\n            state_dict: Optimizer state. Should be an object returned from state_dict()\n        """\n        # Restore param_groups settings\n        if \'param_groups\' in state_dict:\n            for group, saved_group in zip(self.param_groups, state_dict[\'param_groups\']):\n                group[\'lr\'] = saved_group[\'lr\']\n                group[\'betas\'] = saved_group[\'betas\']\n                group[\'eps\'] = saved_group[\'eps\']\n                group[\'weight_decay\'] = saved_group[\'weight_decay\']\n\n        # Restore optimizer state\n        if \'state\' in state_dict:\n            for param_id, saved_state in state_dict[\'state\'].items():\n                if param_id in self.state:\n                    self.state[param_id][\'step\'] = saved_state[\'step\']\n                    self.state[param_id][\'exp_avg\'] = saved_state[\'exp_avg\'].copy()\n                    self.state[param_id][\'exp_avg_sq\'] = saved_state[\'exp_avg_sq\'].copy()\n\n# RMSprop Optimizer - Root Mean Square Propagation\nclass RMSpropOptimizer:\n    """RMSprop optimizer implementing adaptive learning rates using moving average of squared gradients.\n\n    Args:\n        params: Iterable of parameters to optimize\n        lr: Learning rate (default: 0.01)\n        alpha: Smoothing constant (default: 0.99)\n        eps: Term for numerical stability (default: 1e-8)\n        weight_decay: L2 penalty (default: 0)\n        momentum: Momentum factor (default: 0)\n        centered: If True, compute centered RMSprop (default: False)\n    """\n    def __init__(self, params, lr=0.01, alpha=0.99, eps=1e-8, weight_decay=0, momentum=0, centered=False, **kwargs):\n        # Validate parameters\n        if not 0.0 <= lr:\n            raise ValueError(f"Invalid learning rate: {lr}")\n        if not 0.0 <= alpha:\n            raise ValueError(f"Invalid alpha value: {alpha}")\n        if not 0.0 <= eps:\n            raise ValueError(f"Invalid epsilon value: {eps}")\n        if not 0.0 <= momentum:\n            raise ValueError(f"Invalid momentum value: {momentum}")\n        if not 0.0 <= weight_decay:\n            raise ValueError(f"Invalid weight_decay value: {weight_decay}")\n\n        # Store parameters in param_groups format\n        self.param_groups = [{\n            \'params\': params,\n            \'lr\': lr,\n            \'alpha\': alpha,\n            \'eps\': eps,\n            \'weight_decay\': weight_decay,\n            \'momentum\': momentum,\n            \'centered\': centered\n        }]\n\n        # State dictionary stores optimizer state for each parameter\n        # Keys: parameter id, Values: {\'step\', \'square_avg\', \'momentum_buffer\', \'grad_avg\'}\n        self.state = {}\n\n    def zero_grad(self, set_to_none=False):\n        """Clear gradients of all parameters\n\n        Args:\n            set_to_none: If True, set gradients to None instead of zero (saves memory)\n        """\n        for group in self.param_groups:\n            for param in group[\'params\']:\n                if hasattr(param, \'grad\') and param.grad is not None:\n                    if set_to_none:\n                        param.grad = None\n                    else:\n                        try:\n                            param.grad._data = np.zeros_like(param.grad._data)\n                        except:\n                            # Fallback: set to None if memory allocation fails\n                            param.grad = None\n\n    def step(self):\n        """Perform one optimization step using RMSprop algorithm"""\n        for group in self.param_groups:\n            lr = group[\'lr\']\n            alpha = group[\'alpha\']\n            eps = group[\'eps\']\n            weight_decay = group[\'weight_decay\']\n            momentum = group[\'momentum\']\n            centered = group[\'centered\']\n\n            for param in group[\'params\']:\n                if not hasattr(param, \'grad\') or param.grad is None:\n                    continue\n\n                grad = param.grad._data\n\n                # Add weight decay (L2 regularization)\n                if weight_decay != 0:\n                    grad = grad + weight_decay * param._data\n\n                # Get or initialize state for this parameter\n                param_state = self.state.setdefault(id(param), {})\n\n                # Initialize state on first step\n                if \'step\' not in param_state:\n                    param_state[\'step\'] = 0\n                    # Running average of squared gradients\n                    param_state[\'square_avg\'] = np.zeros_like(param._data)\n                    if momentum > 0:\n                        param_state[\'momentum_buffer\'] = np.zeros_like(param._data)\n                    if centered:\n                        param_state[\'grad_avg\'] = np.zeros_like(param._data)\n\n                # Retrieve state\n                square_avg = param_state[\'square_avg\']\n                param_state[\'step\'] += 1\n\n                # Update moving average of squared gradients\n                # v_t = alpha * v_{t-1} + (1 - alpha) * g_t^2\n                square_avg = alpha * square_avg + (1 - alpha) * (grad ** 2)\n                param_state[\'square_avg\'] = square_avg\n\n                # Centered RMSprop: subtract mean gradient\n                if centered:\n                    grad_avg = param_state[\'grad_avg\']\n                    grad_avg = alpha * grad_avg + (1 - alpha) * grad\n                    param_state[\'grad_avg\'] = grad_avg\n                    avg = np.sqrt(square_avg - grad_avg ** 2 + eps)\n                else:\n                    avg = np.sqrt(square_avg + eps)\n\n                # Apply momentum if specified\n                if momentum > 0:\n                    buf = param_state[\'momentum_buffer\']\n                    # buf_t = momentum * buf_{t-1} + g_t / sqrt(v_t + eps)\n                    buf = momentum * buf + grad / avg\n                    param_state[\'momentum_buffer\'] = buf\n                    # Update parameters\n                    np.copyto(param._data, param._data - lr * buf)\n                else:\n                    # Update parameters: theta_t = theta_{t-1} - lr * g_t / sqrt(v_t + eps)\n                    np.copyto(param._data, param._data - lr * grad / avg)\n\n    def state_dict(self):\n        """Returns the state of the optimizer as a dict.\n\n        Contains two entries:\n            state: dict holding current optimization state (square_avg, momentum_buffer, grad_avg, step)\n            param_groups: dict containing optimization options\n        """\n        return {\n            \'state\': {param_id: state.copy() for param_id, state in self.state.items()},\n            \'param_groups\': [{\n                \'lr\': group[\'lr\'],\n                \'alpha\': group[\'alpha\'],\n                \'eps\': group[\'eps\'],\n                \'weight_decay\': group[\'weight_decay\'],\n                \'momentum\': group[\'momentum\'],\n                \'centered\': group[\'centered\']\n            } for group in self.param_groups]\n        }\n\n    def load_state_dict(self, state_dict):\n        """Loads the optimizer state.\n\n        Args:\n            state_dict: optimizer state as returned by state_dict()\n        """\n        # Restore param_groups\n        if \'param_groups\' in state_dict:\n            for group, saved_group in zip(self.param_groups, state_dict[\'param_groups\']):\n                group[\'lr\'] = saved_group[\'lr\']\n                group[\'alpha\'] = saved_group[\'alpha\']\n                group[\'eps\'] = saved_group[\'eps\']\n                group[\'weight_decay\'] = saved_group[\'weight_decay\']\n                group[\'momentum\'] = saved_group[\'momentum\']\n                group[\'centered\'] = saved_group[\'centered\']\n\n        # Restore optimizer state\n        if \'state\' in state_dict:\n            for param_id, saved_state in state_dict[\'state\'].items():\n                if param_id in self.state:\n                    self.state[param_id][\'step\'] = saved_state[\'step\']\n                    self.state[param_id][\'square_avg\'] = saved_state[\'square_avg\'].copy()\n                    if \'momentum_buffer\' in saved_state:\n                        self.state[param_id][\'momentum_buffer\'] = saved_state[\'momentum_buffer\'].copy()\n                    if \'grad_avg\' in saved_state:\n                        self.state[param_id][\'grad_avg\'] = saved_state[\'grad_avg\'].copy()\n\nclass AdamWOptimizer:\n    """AdamW optimizer with decoupled weight decay regularization.\n\n    Args:\n        params: Iterable of parameters to optimize\n        lr: Learning rate (default: 0.001)\n        betas: Coefficients for computing running averages (default: (0.9, 0.999))\n        eps: Term for numerical stability (default: 1e-8)\n        weight_decay: Weight decay coefficient (default: 0.01)\n    """\n    def __init__(self, params, lr=0.001, betas=(0.9, 0.999), eps=1e-8, weight_decay=0.01):\n        if not 0.0 <= lr:\n            raise ValueError(f"Invalid learning rate: {lr}")\n        if not 0.0 <= eps:\n            raise ValueError(f"Invalid epsilon value: {eps}")\n        if not 0.0 <= betas[0] < 1.0:\n            raise ValueError(f"Invalid beta parameter at index 0: {betas[0]}")\n        if not 0.0 <= betas[1] < 1.0:\n            raise ValueError(f"Invalid beta parameter at index 1: {betas[1]}")\n        if not 0.0 <= weight_decay:\n            raise ValueError(f"Invalid weight_decay value: {weight_decay}")\n\n        self.param_groups = [{\n            \'params\': params,\n            \'lr\': lr,\n            \'betas\': betas,\n            \'eps\': eps,\n            \'weight_decay\': weight_decay\n        }]\n        self.state = {}\n\n    def zero_grad(self, set_to_none=False):\n        """Clear gradients of all parameters\n\n        Args:\n            set_to_none: If True, set gradients to None instead of zero (saves memory)\n        """\n        for group in self.param_groups:\n            for param in group[\'params\']:\n                if hasattr(param, \'grad\') and param.grad is not None:\n                    if set_to_none:\n                        param.grad = None\n                    else:\n                        try:\n                            param.grad._data = np.zeros_like(param.grad._data)\n                        except:\n                            # Fallback: set to None if memory allocation fails\n                            param.grad = None\n\n    def step(self):\n        """Perform one optimization step using AdamW algorithm"""\n        for group in self.param_groups:\n            lr = group[\'lr\']\n            beta1, beta2 = group[\'betas\']\n            eps = group[\'eps\']\n            weight_decay = group[\'weight_decay\']\n\n            for param in group[\'params\']:\n                if not hasattr(param, \'grad\') or param.grad is None:\n                    continue\n\n                grad = param.grad._data\n\n                # Get or initialize state for this parameter\n                param_state = self.state.setdefault(id(param), {})\n\n                if \'step\' not in param_state:\n                    param_state[\'step\'] = 0\n                    param_state[\'exp_avg\'] = np.zeros_like(param._data)\n                    param_state[\'exp_avg_sq\'] = np.zeros_like(param._data)\n\n                exp_avg = param_state[\'exp_avg\']\n                exp_avg_sq = param_state[\'exp_avg_sq\']\n                param_state[\'step\'] += 1\n\n                # Decoupled weight decay (AdamW)\n                np.copyto(param._data, param._data * (1 - lr * weight_decay))\n\n                # Update biased first moment estimate\n                exp_avg = beta1 * exp_avg + (1 - beta1) * grad\n                # Update biased second raw moment estimate\n                exp_avg_sq = beta2 * exp_avg_sq + (1 - beta2) * (grad ** 2)\n\n                param_state[\'exp_avg\'] = exp_avg\n                param_state[\'exp_avg_sq\'] = exp_avg_sq\n\n                # Compute bias-corrected first moment estimate\n                bias_correction1 = 1 - beta1 ** param_state[\'step\']\n                bias_correction2 = 1 - beta2 ** param_state[\'step\']\n\n                step_size = lr / bias_correction1\n                bias_correction2_sqrt = np.sqrt(bias_correction2)\n\n                # Update parameters\n                denom = np.sqrt(exp_avg_sq) / bias_correction2_sqrt + eps\n                np.copyto(param._data, param._data - step_size * exp_avg / denom)\n\n    def state_dict(self):\n        """Returns the state of the optimizer as a dict"""\n        return {\n            \'state\': {param_id: state.copy() for param_id, state in self.state.items()},\n            \'param_groups\': [{\n                \'lr\': group[\'lr\'],\n                \'betas\': group[\'betas\'],\n                \'eps\': group[\'eps\'],\n                \'weight_decay\': group[\'weight_decay\']\n            } for group in self.param_groups]\n        }\n\n    def load_state_dict(self, state_dict):\n        """Loads the optimizer state"""\n        if \'param_groups\' in state_dict:\n            for group, saved_group in zip(self.param_groups, state_dict[\'param_groups\']):\n                group.update(saved_group)\n        if \'state\' in state_dict:\n            for param_id, saved_state in state_dict[\'state\'].items():\n                if param_id in self.state:\n                    self.state[param_id].update(saved_state)\n\nclass AdagradOptimizer:\n    """Adagrad optimizer with adaptive learning rates.\n\n    Args:\n        params: Iterable of parameters to optimize\n        lr: Learning rate (default: 0.01)\n        lr_decay: Learning rate decay (default: 0)\n        weight_decay: Weight decay (L2 penalty) (default: 0)\n        eps: Term for numerical stability (default: 1e-10)\n    """\n    def __init__(self, params, lr=0.01, lr_decay=0, weight_decay=0, eps=1e-10, **kwargs):\n        if not 0.0 <= lr:\n            raise ValueError(f"Invalid learning rate: {lr}")\n        if not 0.0 <= lr_decay:\n            raise ValueError(f"Invalid lr_decay value: {lr_decay}")\n        if not 0.0 <= weight_decay:\n            raise ValueError(f"Invalid weight_decay value: {weight_decay}")\n        if not 0.0 <= eps:\n            raise ValueError(f"Invalid epsilon value: {eps}")\n\n        self.param_groups = [{\n            \'params\': params,\n            \'lr\': lr,\n            \'lr_decay\': lr_decay,\n            \'weight_decay\': weight_decay,\n            \'eps\': eps\n        }]\n        self.state = {}\n\n    def zero_grad(self, set_to_none=False):\n        """Clear gradients of all parameters\n\n        Args:\n            set_to_none: If True, set gradients to None instead of zero (saves memory)\n        """\n        for group in self.param_groups:\n            for param in group[\'params\']:\n                if hasattr(param, \'grad\') and param.grad is not None:\n                    if set_to_none:\n                        param.grad = None\n                    else:\n                        try:\n                            param.grad._data = np.zeros_like(param.grad._data)\n                        except:\n                            # Fallback: set to None if memory allocation fails\n                            param.grad = None\n\n    def step(self):\n        """Perform one optimization step using Adagrad algorithm"""\n        for group in self.param_groups:\n            lr = group[\'lr\']\n            lr_decay = group[\'lr_decay\']\n            weight_decay = group[\'weight_decay\']\n            eps = group[\'eps\']\n\n            for param in group[\'params\']:\n                if not hasattr(param, \'grad\') or param.grad is None:\n                    continue\n\n                grad = param.grad._data\n\n                # Add weight decay\n                if weight_decay != 0:\n                    grad = grad + weight_decay * param._data\n\n                # Get or initialize state for this parameter\n                param_state = self.state.setdefault(id(param), {})\n\n                if \'step\' not in param_state:\n                    param_state[\'step\'] = 0\n                    param_state[\'sum\'] = np.zeros_like(param._data)\n\n                param_state[\'step\'] += 1\n\n                # Accumulate squared gradients\n                param_state[\'sum\'] += grad ** 2\n\n                # Compute learning rate with decay\n                clr = lr / (1 + (param_state[\'step\'] - 1) * lr_decay)\n\n                # Update parameters\n                std = np.sqrt(param_state[\'sum\']) + eps\n                np.copyto(param._data, param._data - clr * grad / std)\n\n    def state_dict(self):\n        """Returns the state of the optimizer as a dict"""\n        return {\n            \'state\': {param_id: state.copy() for param_id, state in self.state.items()},\n            \'param_groups\': [{\n                \'lr\': group[\'lr\'],\n                \'lr_decay\': group[\'lr_decay\'],\n                \'weight_decay\': group[\'weight_decay\'],\n                \'eps\': group[\'eps\']\n            } for group in self.param_groups]\n        }\n\n    def load_state_dict(self, state_dict):\n        """Loads the optimizer state"""\n        if \'param_groups\' in state_dict:\n            for group, saved_group in zip(self.param_groups, state_dict[\'param_groups\']):\n                group.update(saved_group)\n        if \'state\' in state_dict:\n            for param_id, saved_state in state_dict[\'state\'].items():\n                if param_id in self.state:\n                    self.state[param_id].update(saved_state)\n\n# Learning Rate Schedulers\nclass _LRScheduler:\n    """Base class for learning rate schedulers.\n\n    Args:\n        optimizer: Wrapped optimizer\n        last_epoch: The index of last epoch (default: -1)\n    """\n    def __init__(self, optimizer, last_epoch=-1, **kwargs):\n        self.optimizer = optimizer\n        self.last_epoch = last_epoch\n        self.base_lrs = [group[\'lr\'] for group in optimizer.param_groups]\n\n        # Initialize learning rate to base_lrs\n        if last_epoch == -1:\n            for group, lr in zip(self.optimizer.param_groups, self.base_lrs):\n                group[\'lr\'] = lr\n\n    def state_dict(self):\n        """Returns the state of the scheduler as a dict."""\n        return {key: value for key, value in self.__dict__.items() if key != \'optimizer\'}\n\n    def load_state_dict(self, state_dict):\n        """Loads the scheduler\'s state."""\n        self.__dict__.update(state_dict)\n\n    def get_last_lr(self):\n        """Return last computed learning rate by current scheduler."""\n        return [group[\'lr\'] for group in self.optimizer.param_groups]\n\n    def get_lr(self):\n        """Compute learning rate using chainable form of the scheduler."""\n        raise NotImplementedError\n\n    def step(self, epoch=None):\n        """Perform a single learning rate schedule step."""\n        if epoch is None:\n            epoch = self.last_epoch + 1\n        self.last_epoch = epoch\n\n        for param_group, lr in zip(self.optimizer.param_groups, self.get_lr()):\n            param_group[\'lr\'] = lr\n\nclass StepLR(_LRScheduler):\n    """Decays the learning rate of each parameter group by gamma every step_size epochs.\n\n    Args:\n        optimizer: Wrapped optimizer\n        step_size: Period of learning rate decay\n        gamma: Multiplicative factor of learning rate decay (default: 0.1)\n        last_epoch: The index of last epoch (default: -1)\n    """\n    def __init__(self, optimizer, step_size, gamma=0.1, last_epoch=-1, **kwargs):\n        self.step_size = step_size\n        self.gamma = gamma\n        super().__init__(optimizer, last_epoch)\n\n    def get_lr(self):\n        """Calculate new learning rates."""\n        if (self.last_epoch == 0) or (self.last_epoch % self.step_size != 0):\n            return [group[\'lr\'] for group in self.optimizer.param_groups]\n        return [group[\'lr\'] * self.gamma for group in self.optimizer.param_groups]\n\nclass ExponentialLR(_LRScheduler):\n    """Decays the learning rate of each parameter group by gamma every epoch.\n\n    Args:\n        optimizer: Wrapped optimizer\n        gamma: Multiplicative factor of learning rate decay\n        last_epoch: The index of last epoch (default: -1)\n    """\n    def __init__(self, optimizer, gamma, last_epoch=-1, **kwargs):\n        self.gamma = gamma\n        super().__init__(optimizer, last_epoch)\n\n    def get_lr(self):\n        """Calculate new learning rates."""\n        if self.last_epoch == 0:\n            return self.base_lrs\n        return [group[\'lr\'] * self.gamma for group in self.optimizer.param_groups]\n\nclass ReduceLROnPlateau:\n    """Reduce learning rate when a metric has stopped improving.\n\n    Args:\n        optimizer: Wrapped optimizer\n        mode: One of \'min\', \'max\'. In \'min\' mode, lr will be reduced when the quantity monitored has stopped decreasing\n        factor: Factor by which the learning rate will be reduced. new_lr = lr * factor (default: 0.1)\n        patience: Number of epochs with no improvement after which learning rate will be reduced (default: 10)\n        threshold: Threshold for measuring the new optimum (default: 1e-4)\n        threshold_mode: One of \'rel\', \'abs\' (default: \'rel\')\n        cooldown: Number of epochs to wait before resuming normal operation after lr has been reduced (default: 0)\n        min_lr: A lower bound on the learning rate (default: 0)\n        eps: Minimal decay applied to lr. If the difference between new and old lr is smaller than eps, the update is ignored (default: 1e-8)\n    """\n    def __init__(self, optimizer, mode=\'min\', factor=0.1, patience=10, threshold=1e-4,\n                 threshold_mode=\'rel\', cooldown=0, min_lr=0, eps=1e-8):\n        if factor >= 1.0:\n            raise ValueError(\'Factor should be < 1.0.\')\n        self.factor = factor\n\n        if not isinstance(optimizer, (SGDOptimizer, AdamOptimizer, RMSpropOptimizer, Optimizer)):\n            raise TypeError(f\'{type(optimizer).__name__} is not an Optimizer\')\n        self.optimizer = optimizer\n\n        if isinstance(min_lr, list) or isinstance(min_lr, tuple):\n            if len(min_lr) != len(optimizer.param_groups):\n                raise ValueError(f"expected {len(optimizer.param_groups)} min_lrs, got {len(min_lr)}")\n            self.min_lrs = list(min_lr)\n        else:\n            self.min_lrs = [min_lr] * len(optimizer.param_groups)\n\n        self.patience = patience\n        self.cooldown = cooldown\n        self.cooldown_counter = 0\n        self.mode = mode\n        self.threshold = threshold\n        self.threshold_mode = threshold_mode\n        self.best = None\n        self.num_bad_epochs = 0\n        self.mode_worse = None  # the worse value for the chosen mode\n        self.eps = eps\n        self.last_epoch = 0\n        self._init_is_better(mode=mode, threshold=threshold, threshold_mode=threshold_mode)\n        self._reset()\n\n    def _reset(self):\n        """Reset num_bad_epochs counter and cooldown counter."""\n        self.best = self.mode_worse\n        self.cooldown_counter = 0\n        self.num_bad_epochs = 0\n\n    def step(self, metrics):\n        """Update learning rate based on validation metric."""\n        current = float(metrics)\n        self.last_epoch += 1\n\n        if self.is_better(current, self.best):\n            self.best = current\n            self.num_bad_epochs = 0\n        else:\n            self.num_bad_epochs += 1\n\n        if self.in_cooldown:\n            self.cooldown_counter -= 1\n            self.num_bad_epochs = 0  # ignore any bad epochs in cooldown\n\n        if self.num_bad_epochs > self.patience:\n            self._reduce_lr(self.last_epoch)\n            self.cooldown_counter = self.cooldown\n            self.num_bad_epochs = 0\n\n    def _reduce_lr(self, epoch):\n        """Reduce learning rate."""\n        for i, param_group in enumerate(self.optimizer.param_groups):\n            old_lr = float(param_group[\'lr\'])\n            new_lr = max(old_lr * self.factor, self.min_lrs[i])\n            if old_lr - new_lr > self.eps:\n                param_group[\'lr\'] = new_lr\n\n    @property\n    def in_cooldown(self):\n        """Check if in cooldown period."""\n        return self.cooldown_counter > 0\n\n    def is_better(self, a, best):\n        """Check if a is better than best."""\n        if self.mode == \'min\' and self.threshold_mode == \'rel\':\n            rel_epsilon = 1. - self.threshold\n            return a < best * rel_epsilon\n\n        elif self.mode == \'min\' and self.threshold_mode == \'abs\':\n            return a < best - self.threshold\n\n        elif self.mode == \'max\' and self.threshold_mode == \'rel\':\n            rel_epsilon = self.threshold + 1.\n            return a > best * rel_epsilon\n\n        else:  # mode == \'max\' and threshold_mode == \'abs\':\n            return a > best + self.threshold\n\n    def _init_is_better(self, mode, threshold, threshold_mode):\n        """Initialize comparison mode."""\n        if mode not in {\'min\', \'max\'}:\n            raise ValueError(\'mode \' + mode + \' is unknown!\')\n        if threshold_mode not in {\'rel\', \'abs\'}:\n            raise ValueError(\'threshold mode \' + threshold_mode + \' is unknown!\')\n\n        if mode == \'min\':\n            self.mode_worse = float(\'inf\')\n        else:  # mode == \'max\':\n            self.mode_worse = float(\'-inf\')\n\n    def state_dict(self):\n        """Returns the state of the scheduler as a dict."""\n        return {key: value for key, value in self.__dict__.items() if key != \'optimizer\'}\n\n    def load_state_dict(self, state_dict):\n        """Loads the schedulers state."""\n        self.__dict__.update(state_dict)\n\n    def get_last_lr(self):\n        """Return last computed learning rate."""\n        return [group[\'lr\'] for group in self.optimizer.param_groups]\n\nclass TorchOptimLRScheduler:\n    """Container for learning rate schedulers."""\n    def __init__(self, **kwargs):\n        self.StepLR = StepLR\n        self.ExponentialLR = ExponentialLR\n        self.ReduceLROnPlateau = ReduceLROnPlateau\n\nclass TorchOptim:\n    def __init__(self, **kwargs):\n        self.SGD = SGDOptimizer\n        self.Adam = AdamOptimizer\n        self.AdamW = AdamWOptimizer\n        self.RMSprop = RMSpropOptimizer\n        self.Adagrad = AdagradOptimizer\n        self.lr_scheduler = TorchOptimLRScheduler()\n\n# CUDA support for WebGPU acceleration\nclass TorchCuda:\n    def __init__(self, **kwargs):\n        pass\n\n    def is_available(self):\n        """Check if WebGPU acceleration is available (maps CUDA to WebGPU)"""\n        # In browser, we use WebGPU instead of CUDA\n        try:\n            # Use JavaScript to check if WebGPU is actually available\n            import js\n            if hasattr(js, \'navigator\') and hasattr(js.navigator, \'gpu\'):\n                return js.navigator.gpu is not None\n            else:\n                return False\n        except:\n            return False\n\n    def manual_seed(self, seed):\n        """Set the seed for generating random numbers for CUDA (WebGPU in our case)"""\n        # Map to global seed since we\'re using NumPy/WebGPU backend\n        import numpy as np\n        np.random.seed(seed)\n        return None\n\n    def manual_seed_all(self, seed):\n        """Set the seed for generating random numbers on all GPUs"""\n        # In browser context with WebGPU, this maps to the same as manual_seed\n        import numpy as np\n        np.random.seed(seed)\n        return None\n\n    def synchronize(self):\n        """Wait for all kernels in all streams on current device to complete"""\n        # No-op in browser context - WebGPU operations are already synchronized\n        pass\n\n    def device_count(self):\n        """Returns the number of GPUs available"""\n        # In browser context, we have at most 1 WebGPU device\n        return 1 if self.is_available() else 0\n\n# Backends support for device availability checks\nclass TorchBackends:\n    def __init__(self, **kwargs):\n        self.cuda = TorchCuda()\n        self.mps = TorchMPS()\n\nclass TorchMPS:\n    """Apple Metal Performance Shaders backend (mapped to WebGPU)"""\n    def __init__(self, **kwargs):\n        pass\n\n    def is_available(self):\n        """Check if MPS backend is available"""\n        # In browser, we use WebGPU which can work on Apple devices\n        # Return false for now as we primarily use WebGPU\n        return False\n\n    def is_built(self):\n        """Check if PyTorch was built with MPS support"""\n        return False\n\n    def get_device_name(self, device=None):\n        """Get the name of a device"""\n        if self.is_available():\n            return "WebGPU"\n        return "CPU"\n\n    def current_device(self):\n        """Returns the index of a currently selected device"""\n        return 0 if self.is_available() else -1\n\n# Conv1d Layer\nclass TorchNNConv1d(TorchNNModule):\n    """1D Convolution Layer"""\n    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True, **kwargs):\n        self._parameters = {}\n        self._modules = {}\n        self._buffers = {}\n        self._non_persistent_buffers_set = set()\n        self._backward_hooks = {}\n        self._backward_pre_hooks = {}\n        self._forward_hooks = {}\n        self._forward_pre_hooks = {}\n        self._state_dict_hooks = {}\n        self._load_state_dict_pre_hooks = {}\n        self.training = True\n\n        self.in_channels = in_channels\n        self.out_channels = out_channels\n        self.kernel_size = kernel_size if isinstance(kernel_size, int) else kernel_size[0]\n        self.stride = stride if isinstance(stride, int) else stride[0]\n        self.padding = padding if isinstance(padding, int) else padding[0]\n        self.dilation = dilation if isinstance(dilation, int) else dilation[0]\n        self.groups = groups\n\n        # Initialize weights\n        k = np.sqrt(1.0 / (in_channels * self.kernel_size))\n        weight_data = np.random.uniform(-k, k, (out_channels, in_channels, self.kernel_size))\n        self.weight = WebGPUTensor(weight_data, requires_grad=True)\n        self._parameters[\'weight\'] = self.weight\n\n        if bias:\n            bias_data = np.random.uniform(-k, k, (out_channels,))\n            self.bias = WebGPUTensor(bias_data, requires_grad=True)\n            self._parameters[\'bias\'] = self.bias\n        else:\n            self.bias = None\n\n    def forward(self, x):\n        # Input: (N, C_in, L_in)\n        batch_size, in_channels, length = x.shape\n\n        # Apply padding\n        if self.padding > 0:\n            x_padded = np.pad(x._data, ((0,0), (0,0), (self.padding, self.padding)), mode=\'constant\')\n        else:\n            x_padded = x._data\n\n        # Calculate output length\n        out_length = (length + 2*self.padding - self.dilation*(self.kernel_size-1) - 1) // self.stride + 1\n\n        # Initialize output\n        output = np.zeros((batch_size, self.out_channels, out_length))\n\n        # Perform convolution\n        for b in range(batch_size):\n            for oc in range(self.out_channels):\n                for i in range(out_length):\n                    start = i * self.stride\n                    end = start + self.kernel_size\n                    output[b, oc, i] = np.sum(x_padded[b, :, start:end] * self.weight._data[oc, :, :])\n                    if self.bias is not None:\n                        output[b, oc, i] += self.bias._data[oc]\n\n        return WebGPUTensor(output, requires_grad=x.requires_grad or self.weight.requires_grad)\n\n# AdaptiveAvgPool2d Layer\nclass TorchNNAdaptiveAvgPool2d(TorchNNModule):\n    """Adaptive Average Pooling 2D"""\n    def __init__(self, output_size, **kwargs):\n        self._parameters = {}\n        self._modules = {}\n        self._buffers = {}\n        self._non_persistent_buffers_set = set()\n        self._backward_hooks = {}\n        self._backward_pre_hooks = {}\n        self._forward_hooks = {}\n        self._forward_pre_hooks = {}\n        self._state_dict_hooks = {}\n        self._load_state_dict_pre_hooks = {}\n        self.training = True\n\n        if isinstance(output_size, int):\n            self.output_size = (output_size, output_size)\n        else:\n            self.output_size = output_size\n\n    def forward(self, x):\n        # Input: (N, C, H_in, W_in)\n        batch_size, channels, h_in, w_in = x.shape\n        h_out, w_out = self.output_size\n\n        # Calculate stride and kernel size\n        stride_h = h_in // h_out\n        stride_w = w_in // w_out\n        kernel_h = h_in - (h_out - 1) * stride_h\n        kernel_w = w_in - (w_out - 1) * stride_w\n\n        output = np.zeros((batch_size, channels, h_out, w_out))\n\n        for b in range(batch_size):\n            for c in range(channels):\n                for i in range(h_out):\n                    for j in range(w_out):\n                        h_start = int(np.floor(i * h_in / h_out))\n                        h_end = int(np.ceil((i + 1) * h_in / h_out))\n                        w_start = int(np.floor(j * w_in / w_out))\n                        w_end = int(np.ceil((j + 1) * w_in / w_out))\n                        output[b, c, i, j] = np.mean(x._data[b, c, h_start:h_end, w_start:w_end])\n\n        return WebGPUTensor(output, requires_grad=x.requires_grad)\n\n# BatchNorm1d Layer\nclass TorchNNBatchNorm1d(TorchNNModule):\n    """Batch Normalization 1D"""\n    def __init__(self, num_features, eps=1e-5, momentum=0.1, affine=True, track_running_stats=True, **kwargs):\n        self._parameters = {}\n        self._modules = {}\n        self._buffers = {}\n        self._non_persistent_buffers_set = set()\n        self._backward_hooks = {}\n        self._backward_pre_hooks = {}\n        self._forward_hooks = {}\n        self._forward_pre_hooks = {}\n        self._state_dict_hooks = {}\n        self._load_state_dict_pre_hooks = {}\n        self.training = True\n\n        self.num_features = num_features\n        self.eps = eps\n        self.momentum = momentum\n        self.affine = affine\n        self.track_running_stats = track_running_stats\n\n        if affine:\n            self.weight = WebGPUTensor(np.ones(num_features), requires_grad=True)\n            self.bias = WebGPUTensor(np.zeros(num_features), requires_grad=True)\n            self._parameters[\'weight\'] = self.weight\n            self._parameters[\'bias\'] = self.bias\n        else:\n            self.weight = None\n            self.bias = None\n\n        if track_running_stats:\n            self.running_mean = WebGPUTensor(np.zeros(num_features))\n            self.running_var = WebGPUTensor(np.ones(num_features))\n            self._buffers[\'running_mean\'] = self.running_mean\n            self._buffers[\'running_var\'] = self.running_var\n        else:\n            self.running_mean = None\n            self.running_var = None\n\n    def forward(self, x):\n        # Input can be (N, C) or (N, C, L)\n        if self.training:\n            # Calculate mean and var across batch dimension\n            if x.ndim == 2:\n                mean = np.mean(x._data, axis=0)\n                var = np.var(x._data, axis=0)\n            else:  # ndim == 3\n                mean = np.mean(x._data, axis=(0, 2))\n                var = np.var(x._data, axis=(0, 2))\n\n            # Update running stats\n            if self.track_running_stats:\n                self.running_mean._data = (1 - self.momentum) * self.running_mean._data + self.momentum * mean\n                self.running_var._data = (1 - self.momentum) * self.running_var._data + self.momentum * var\n        else:\n            mean = self.running_mean._data\n            var = self.running_var._data\n\n        # Normalize\n        if x.ndim == 2:\n            normalized = (x._data - mean) / np.sqrt(var + self.eps)\n        else:\n            normalized = (x._data - mean[None, :, None]) / np.sqrt(var[None, :, None] + self.eps)\n\n        # Apply affine transformation\n        if self.affine:\n            if x.ndim == 2:\n                output = normalized * self.weight._data + self.bias._data\n            else:\n                output = normalized * self.weight._data[None, :, None] + self.bias._data[None, :, None]\n        else:\n            output = normalized\n\n        return WebGPUTensor(output, requires_grad=x.requires_grad)\n\n# Embedding Layer\nclass TorchNNEmbedding(TorchNNModule):\n    """Embedding Layer"""\n    def __init__(self, num_embeddings, embedding_dim, padding_idx=None, **kwargs):\n        self._parameters = {}\n        self._modules = {}\n        self._buffers = {}\n        self._non_persistent_buffers_set = set()\n        self._backward_hooks = {}\n        self._backward_pre_hooks = {}\n        self._forward_hooks = {}\n        self._forward_pre_hooks = {}\n        self._state_dict_hooks = {}\n        self._load_state_dict_pre_hooks = {}\n        self.training = True\n\n        self.num_embeddings = num_embeddings\n        self.embedding_dim = embedding_dim\n        self.padding_idx = padding_idx\n\n        # Initialize embeddings\n        weight_data = np.random.randn(num_embeddings, embedding_dim) * 0.01\n        if padding_idx is not None:\n            weight_data[padding_idx] = 0\n        self.weight = WebGPUTensor(weight_data, requires_grad=True)\n        self._parameters[\'weight\'] = self.weight\n\n    def forward(self, x):\n        # Input: (N, L) or (N,) - indices\n        indices = x._data.astype(int)\n        output = self.weight._data[indices]\n        return WebGPUTensor(output, requires_grad=self.weight.requires_grad)\n\n# RNN Layer\nclass TorchNNRNN(TorchNNModule):\n    """Simple RNN Layer"""\n    def __init__(self, input_size, hidden_size, num_layers=1, bias=True, batch_first=False, dropout=0, bidirectional=False, **kwargs):\n        self._parameters = {}\n        self._modules = {}\n        self._buffers = {}\n        self._non_persistent_buffers_set = set()\n        self._backward_hooks = {}\n        self._backward_pre_hooks = {}\n        self._forward_hooks = {}\n        self._forward_pre_hooks = {}\n        self._state_dict_hooks = {}\n        self._load_state_dict_pre_hooks = {}\n        self.training = True\n\n        self.input_size = input_size\n        self.hidden_size = hidden_size\n        self.num_layers = num_layers\n        self.bias = bias\n        self.batch_first = batch_first\n        self.dropout = dropout\n        self.bidirectional = bidirectional\n\n        # Initialize weights for each layer\n        for layer in range(num_layers):\n            input_dim = input_size if layer == 0 else hidden_size\n\n            # Input to hidden\n            w_ih = np.random.randn(hidden_size, input_dim) * 0.01\n            self._parameters[f\'weight_ih_l{layer}\'] = WebGPUTensor(w_ih, requires_grad=True)\n\n            # Hidden to hidden\n            w_hh = np.random.randn(hidden_size, hidden_size) * 0.01\n            self._parameters[f\'weight_hh_l{layer}\'] = WebGPUTensor(w_hh, requires_grad=True)\n\n            if bias:\n                b_ih = np.zeros(hidden_size)\n                b_hh = np.zeros(hidden_size)\n                self._parameters[f\'bias_ih_l{layer}\'] = WebGPUTensor(b_ih, requires_grad=True)\n                self._parameters[f\'bias_hh_l{layer}\'] = WebGPUTensor(b_hh, requires_grad=True)\n\n    def forward(self, x, h0=None):\n        # Input: (seq_len, batch, input_size) if not batch_first\n        # Or: (batch, seq_len, input_size) if batch_first\n        if self.batch_first:\n            x_data = np.transpose(x._data, (1, 0, 2))  # Convert to (seq, batch, input)\n        else:\n            x_data = x._data\n\n        seq_len, batch_size, _ = x_data.shape\n\n        # Initialize hidden state\n        if h0 is None:\n            h = np.zeros((self.num_layers, batch_size, self.hidden_size))\n        else:\n            h = h0._data\n\n        outputs = []\n\n        # Process each time step\n        for t in range(seq_len):\n            x_t = x_data[t]\n\n            for layer in range(self.num_layers):\n                w_ih = self._parameters[f\'weight_ih_l{layer}\']._data\n                w_hh = self._parameters[f\'weight_hh_l{layer}\']._data\n\n                if self.bias:\n                    b_ih = self._parameters[f\'bias_ih_l{layer}\']._data\n                    b_hh = self._parameters[f\'bias_hh_l{layer}\']._data\n                else:\n                    b_ih = 0\n                    b_hh = 0\n\n                # RNN cell: h_new = tanh(W_ih @ x + b_ih + W_hh @ h + b_hh)\n                h[layer] = np.tanh(x_t @ w_ih.T + b_ih + h[layer] @ w_hh.T + b_hh)\n                x_t = h[layer]\n\n            outputs.append(h[-1])\n\n        output_array = np.stack(outputs, axis=0)\n\n        if self.batch_first:\n            output_array = np.transpose(output_array, (1, 0, 2))\n\n        output_tensor = WebGPUTensor(output_array, requires_grad=x.requires_grad)\n        h_tensor = WebGPUTensor(h, requires_grad=True)\n\n        return output_tensor, h_tensor\n\n# LSTM Layer\nclass TorchNNLSTM(TorchNNModule):\n    """LSTM Layer"""\n    def __init__(self, input_size, hidden_size, num_layers=1, bias=True, batch_first=False, dropout=0, bidirectional=False, **kwargs):\n        self._parameters = {}\n        self._modules = {}\n        self._buffers = {}\n        self._non_persistent_buffers_set = set()\n        self._backward_hooks = {}\n        self._backward_pre_hooks = {}\n        self._forward_hooks = {}\n        self._forward_pre_hooks = {}\n        self._state_dict_hooks = {}\n        self._load_state_dict_pre_hooks = {}\n        self.training = True\n\n        self.input_size = input_size\n        self.hidden_size = hidden_size\n        self.num_layers = num_layers\n        self.bias = bias\n        self.batch_first = batch_first\n        self.dropout = dropout\n        self.bidirectional = bidirectional\n\n        # Initialize weights (simplified LSTM)\n        for layer in range(num_layers):\n            input_dim = input_size if layer == 0 else hidden_size\n\n            # All gates combined: input, forget, cell, output\n            w_ih = np.random.randn(4 * hidden_size, input_dim) * 0.01\n            w_hh = np.random.randn(4 * hidden_size, hidden_size) * 0.01\n\n            self._parameters[f\'weight_ih_l{layer}\'] = WebGPUTensor(w_ih, requires_grad=True)\n            self._parameters[f\'weight_hh_l{layer}\'] = WebGPUTensor(w_hh, requires_grad=True)\n\n            if bias:\n                b_ih = np.zeros(4 * hidden_size)\n                b_hh = np.zeros(4 * hidden_size)\n                self._parameters[f\'bias_ih_l{layer}\'] = WebGPUTensor(b_ih, requires_grad=True)\n                self._parameters[f\'bias_hh_l{layer}\'] = WebGPUTensor(b_hh, requires_grad=True)\n\n    def forward(self, x, hx=None):\n        if self.batch_first:\n            x_data = np.transpose(x._data, (1, 0, 2))\n        else:\n            x_data = x._data\n\n        seq_len, batch_size, _ = x_data.shape\n\n        if hx is None:\n            h = np.zeros((self.num_layers, batch_size, self.hidden_size))\n            c = np.zeros((self.num_layers, batch_size, self.hidden_size))\n        else:\n            h, c = hx[0]._data, hx[1]._data\n\n        outputs = []\n\n        for t in range(seq_len):\n            x_t = x_data[t]\n\n            for layer in range(self.num_layers):\n                w_ih = self._parameters[f\'weight_ih_l{layer}\']._data\n                w_hh = self._parameters[f\'weight_hh_l{layer}\']._data\n\n                if self.bias:\n                    b_ih = self._parameters[f\'bias_ih_l{layer}\']._data\n                    b_hh = self._parameters[f\'bias_hh_l{layer}\']._data\n                else:\n                    b_ih = 0\n                    b_hh = 0\n\n                # LSTM gates\n                gates = x_t @ w_ih.T + b_ih + h[layer] @ w_hh.T + b_hh\n\n                i, f, g, o = np.split(gates, 4, axis=-1)\n                i = 1 / (1 + np.exp(-i))  # sigmoid\n                f = 1 / (1 + np.exp(-f))  # sigmoid\n                g = np.tanh(g)\n                o = 1 / (1 + np.exp(-o))  # sigmoid\n\n                c[layer] = f * c[layer] + i * g\n                h[layer] = o * np.tanh(c[layer])\n                x_t = h[layer]\n\n            outputs.append(h[-1])\n\n        output_array = np.stack(outputs, axis=0)\n        if self.batch_first:\n            output_array = np.transpose(output_array, (1, 0, 2))\n\n        return WebGPUTensor(output_array, requires_grad=x.requires_grad), (WebGPUTensor(h), WebGPUTensor(c))\n\n# GRU Layer\nclass TorchNNGRU(TorchNNModule):\n    """GRU Layer"""\n    def __init__(self, input_size, hidden_size, num_layers=1, bias=True, batch_first=False, dropout=0, bidirectional=False, **kwargs):\n        self._parameters = {}\n        self._modules = {}\n        self._buffers = {}\n        self._non_persistent_buffers_set = set()\n        self._backward_hooks = {}\n        self._backward_pre_hooks = {}\n        self._forward_hooks = {}\n        self._forward_pre_hooks = {}\n        self._state_dict_hooks = {}\n        self._load_state_dict_pre_hooks = {}\n        self.training = True\n\n        self.input_size = input_size\n        self.hidden_size = hidden_size\n        self.num_layers = num_layers\n        self.bias = bias\n        self.batch_first = batch_first\n        self.dropout = dropout\n        self.bidirectional = bidirectional\n\n        for layer in range(num_layers):\n            input_dim = input_size if layer == 0 else hidden_size\n\n            # Reset, update, new gates\n            w_ih = np.random.randn(3 * hidden_size, input_dim) * 0.01\n            w_hh = np.random.randn(3 * hidden_size, hidden_size) * 0.01\n\n            self._parameters[f\'weight_ih_l{layer}\'] = WebGPUTensor(w_ih, requires_grad=True)\n            self._parameters[f\'weight_hh_l{layer}\'] = WebGPUTensor(w_hh, requires_grad=True)\n\n            if bias:\n                b_ih = np.zeros(3 * hidden_size)\n                b_hh = np.zeros(3 * hidden_size)\n                self._parameters[f\'bias_ih_l{layer}\'] = WebGPUTensor(b_ih, requires_grad=True)\n                self._parameters[f\'bias_hh_l{layer}\'] = WebGPUTensor(b_hh, requires_grad=True)\n\n    def forward(self, x, h0=None):\n        if self.batch_first:\n            x_data = np.transpose(x._data, (1, 0, 2))\n        else:\n            x_data = x._data\n\n        seq_len, batch_size, _ = x_data.shape\n\n        if h0 is None:\n            h = np.zeros((self.num_layers, batch_size, self.hidden_size))\n        else:\n            h = h0._data\n\n        outputs = []\n\n        for t in range(seq_len):\n            x_t = x_data[t]\n\n            for layer in range(self.num_layers):\n                w_ih = self._parameters[f\'weight_ih_l{layer}\']._data\n                w_hh = self._parameters[f\'weight_hh_l{layer}\']._data\n\n                if self.bias:\n                    b_ih = self._parameters[f\'bias_ih_l{layer}\']._data\n                    b_hh = self._parameters[f\'bias_hh_l{layer}\']._data\n                else:\n                    b_ih = 0\n                    b_hh = 0\n\n                # GRU gates\n                gi = x_t @ w_ih.T + b_ih\n                gh = h[layer] @ w_hh.T + b_hh\n\n                i_r, i_z, i_n = np.split(gi, 3, axis=-1)\n                h_r, h_z, h_n = np.split(gh, 3, axis=-1)\n\n                r = 1 / (1 + np.exp(-(i_r + h_r)))  # reset gate\n                z = 1 / (1 + np.exp(-(i_z + h_z)))  # update gate\n                n = np.tanh(i_n + r * h_n)  # new gate\n\n                h[layer] = (1 - z) * n + z * h[layer]\n                x_t = h[layer]\n\n            outputs.append(h[-1])\n\n        output_array = np.stack(outputs, axis=0)\n        if self.batch_first:\n            output_array = np.transpose(output_array, (1, 0, 2))\n\n        return WebGPUTensor(output_array, requires_grad=x.requires_grad), WebGPUTensor(h)\n\nclass TorchNNUtils:\n    """Neural network utilities"""\n    @staticmethod\n    def clip_grad_norm_(parameters, max_norm, norm_type=2.0):\n        """\n        Clips gradient norm of an iterable of parameters.\n\n        Args:\n            parameters: Iterable of parameters or single parameter\n            max_norm: Max norm of the gradients\n            norm_type: Type of the used p-norm (2 for L2 norm)\n\n        Returns:\n            Total norm of the parameters (viewed as a single vector)\n        """\n        if isinstance(parameters, WebGPUTensor) or isinstance(parameters, TorchNNParameter):\n            parameters = [parameters]\n\n        parameters = list(parameters)\n\n        # Filter parameters that have gradients\n        grads = []\n        for p in parameters:\n            if isinstance(p, TorchNNParameter):\n                if hasattr(p.data, \'grad\') and p.data.grad is not None:\n                    grads.append(p.data.grad)\n            elif hasattr(p, \'grad\') and p.grad is not None:\n                grads.append(p.grad)\n\n        if len(grads) == 0:\n            return 0.0\n\n        # Calculate total norm\n        if norm_type == float(\'inf\'):\n            total_norm = max(np.max(np.abs(g._data if isinstance(g, WebGPUTensor) else g)) for g in grads)\n        else:\n            # Calculate L-p norm\n            norm_sum = 0.0\n            for g in grads:\n                grad_data = g._data if isinstance(g, WebGPUTensor) else g\n                if norm_type == 2.0:\n                    norm_sum += np.sum(grad_data ** 2)\n                else:\n                    norm_sum += np.sum(np.abs(grad_data) ** norm_type)\n\n            total_norm = norm_sum ** (1.0 / norm_type)\n\n        # Clip gradients\n        clip_coef = max_norm / (total_norm + 1e-6)\n\n        if clip_coef < 1:\n            for g in grads:\n                if isinstance(g, WebGPUTensor):\n                    g._data *= clip_coef\n                else:\n                    g *= clip_coef\n\n        return total_norm\n\nclass TorchNN:\n    def __init__(self, **kwargs):\n        self.functional = TorchNNFunctional()\n        self.utils = TorchNNUtils()\n        self.Parameter = TorchNNParameter\n        self.Linear = TorchNNLinear\n        self.Module = TorchNNModule\n        self.Sequential = TorchNNSequential\n        self.ModuleList = TorchNNModuleList\n        self.ModuleDict = TorchNNModuleDict\n        self.ReLU = TorchNNReLU\n        self.LeakyReLU = TorchNNLeakyReLU\n        self.Sigmoid = TorchNNSigmoid\n        self.Tanh = TorchNNTanh\n        self.GELU = TorchNNGELU\n        self.SiLU = TorchNNSiLU\n        self.Dropout = TorchNNDropout\n\n        # Normalization layers\n        self.BatchNorm1d = TorchNNBatchNorm1d\n        self.BatchNorm2d = TorchNNBatchNorm2d\n\n        # Convolution layers\n        self.Conv1d = TorchNNConv1d\n        self.Conv2d = TorchNNConv2d\n\n        # Pooling layers\n        self.MaxPool2d = TorchNNMaxPool2d\n        self.AvgPool2d = TorchNNAvgPool2d\n        self.AdaptiveAvgPool2d = TorchNNAdaptiveAvgPool2d\n\n        # Recurrent layers\n        self.RNN = TorchNNRNN\n        self.LSTM = TorchNNLSTM\n        self.GRU = TorchNNGRU\n\n        # Embedding\n        self.Embedding = TorchNNEmbedding\n\n        # Loss functions\n        self.MSELoss = TorchNNMSELoss\n        self.L1Loss = TorchNNL1Loss\n        self.CrossEntropyLoss = TorchNNCrossEntropyLoss\n        self.BCELoss = TorchNNBCELoss\n        self.BCEWithLogitsLoss = TorchNNBCEWithLogitsLoss\n        self.NLLLoss = TorchNNNLLLoss\n        self.SmoothL1Loss = TorchNNSmoothL1Loss\n        self.KLDivLoss = TorchNNKLDivLoss\n        self.CosineEmbeddingLoss = TorchNNCosineEmbeddingLoss\n        self.HingeEmbeddingLoss = TorchNNHingeEmbeddingLoss\n        self.MultiMarginLoss = TorchNNMultiMarginLoss\n        self.TripletMarginLoss = TorchNNTripletMarginLoss\n        self.PoissonNLLLoss = TorchNNPoissonNLLLoss\n        self.CTCLoss = TorchNNCTCLoss\n\n# Global cleanup function to prevent state persistence issues\ndef _cleanup_global_state():\n    """Clean up global tensor state to prevent persistence issues between executions"""\n    import gc\n    # Force garbage collection to clean up circular references\n    gc.collect()\n\nclass TensorDataWrapper:\n    """Wrapper for tensor data that provides PyTorch-like methods"""\n    def __init__(self, numpy_array, parent_tensor=None, **kwargs):\n        self._array = numpy_array\n        self._parent = parent_tensor\n\n    def cpu(self):\n        """Return tensor data on CPU"""\n        return TensorDataWrapper(self._array.copy(), self._parent)\n\n    def numpy(self):\n        """Return the underlying numpy array"""\n        return self._array\n\n    def __getitem__(self, key):\n        """Support indexing operations"""\n        result = self._array[key]\n        return TensorDataWrapper(result, self._parent)\n\n    def __setitem__(self, key, value):\n        """Support item assignment"""\n        if isinstance(value, TensorDataWrapper):\n            self._array[key] = value._array\n        else:\n            self._array[key] = value\n\n    def __len__(self):\n        """Return length of the array"""\n        return len(self._array)\n\n    def __iter__(self):\n        """Support iteration"""\n        for item in self._array:\n            yield TensorDataWrapper(item, self._parent) if hasattr(item, \'shape\') else item\n\n    # Arithmetic operators\n    def __add__(self, other):\n        """Addition operator"""\n        if isinstance(other, TensorDataWrapper):\n            result = self._array + other._array\n        else:\n            result = self._array + other\n        return TensorDataWrapper(result, self._parent)\n\n    def __sub__(self, other):\n        """Subtraction operator"""\n        if isinstance(other, TensorDataWrapper):\n            result = self._array - other._array\n        else:\n            result = self._array - other\n        return TensorDataWrapper(result, self._parent)\n\n    def __mul__(self, other):\n        """Multiplication operator"""\n        if isinstance(other, TensorDataWrapper):\n            result = self._array * other._array\n        else:\n            result = self._array * other\n        return TensorDataWrapper(result, self._parent)\n\n    def __truediv__(self, other):\n        """Division operator"""\n        if isinstance(other, TensorDataWrapper):\n            result = self._array / other._array\n        else:\n            result = self._array / other\n        return TensorDataWrapper(result, self._parent)\n\n    def __pow__(self, other):\n        """Power operator"""\n        if isinstance(other, TensorDataWrapper):\n            result = self._array ** other._array\n        else:\n            result = self._array ** other\n        return TensorDataWrapper(result, self._parent)\n\n    def clone(self):\n        """Clone the data wrapper"""\n        return TensorDataWrapper(self._array.copy(), self._parent)\n\n    def norm(self, ord=2):\n        """Compute the norm of the data"""\n        return np.linalg.norm(self._array, ord=ord)\n\n    # Reverse arithmetic operators\n    def __radd__(self, other):\n        """Reverse addition"""\n        result = other + self._array\n        return TensorDataWrapper(result, self._parent)\n\n    def __rsub__(self, other):\n        """Reverse subtraction"""\n        result = other - self._array\n        return TensorDataWrapper(result, self._parent)\n\n    def __rmul__(self, other):\n        """Reverse multiplication"""\n        result = other * self._array\n        return TensorDataWrapper(result, self._parent)\n\n    def __rtruediv__(self, other):\n        """Reverse division"""\n        result = other / self._array\n        return TensorDataWrapper(result, self._parent)\n\n    def __getattr__(self, name):\n        """Delegate unknown attributes to the underlying numpy array"""\n        return getattr(self._array, name)\n\n    def __array__(self):\n        """Support numpy array interface"""\n        return self._array\n\n    def __repr__(self):\n        return repr(self._array)\n\n# Install in global namespace\ntorch = TorchModule()\nsys.modules[\'torch\'] = torch\n\n# Register torch.nn and its submodules\nsys.modules[\'torch.nn\'] = torch.nn\nsys.modules[\'torch.nn.functional\'] = torch.nn.functional\n\n# Create torch.nn.modules namespace for module imports\nclass TorchNNModules:\n    def __init__(self, **kwargs):\n        # Container modules\n        self.module = type(\'module\', (), {\'Module\': TorchNNModule})()\n        self.container = type(\'container\', (), {\n            \'Sequential\': TorchNNSequential,\n            \'ModuleList\': TorchNNModuleList,\n            \'ModuleDict\': TorchNNModuleDict\n        })()\n\n        # Linear modules\n        self.linear = type(\'linear\', (), {\'Linear\': TorchNNLinear})()\n\n        # Convolutional modules\n        self.conv = type(\'conv\', (), {\'Conv2d\': TorchNNConv2d})()\n\n        # Pooling modules\n        self.pooling = type(\'pooling\', (), {\n            \'MaxPool2d\': TorchNNMaxPool2d,\n            \'AvgPool2d\': TorchNNAvgPool2d\n        })()\n\n        # Activation modules\n        self.activation = type(\'activation\', (), {\n            \'ReLU\': TorchNNReLU,\n            \'Sigmoid\': TorchNNSigmoid,\n            \'Tanh\': TorchNNTanh,\n            \'LeakyReLU\': TorchNNLeakyReLU,\n            \'GELU\': TorchNNGELU,\n            \'SiLU\': TorchNNSiLU\n        })()\n\n        # Normalization modules\n        self.batchnorm = type(\'batchnorm\', (), {\'BatchNorm2d\': TorchNNBatchNorm2d})()\n\n        # Dropout modules\n        self.dropout = type(\'dropout\', (), {\'Dropout\': TorchNNDropout})()\n\n        # Loss modules\n        self.loss = type(\'loss\', (), {\n            \'MSELoss\': TorchNNMSELoss,\n            \'CrossEntropyLoss\': TorchNNCrossEntropyLoss,\n            \'L1Loss\': TorchNNL1Loss,\n            \'BCEWithLogitsLoss\': TorchNNBCEWithLogitsLoss\n        })()\n\nnn_modules = TorchNNModules()\nsys.modules[\'torch.nn.modules\'] = nn_modules\nsys.modules[\'torch.nn.modules.module\'] = nn_modules.module\nsys.modules[\'torch.nn.modules.container\'] = nn_modules.container\nsys.modules[\'torch.nn.modules.linear\'] = nn_modules.linear\nsys.modules[\'torch.nn.modules.conv\'] = nn_modules.conv\nsys.modules[\'torch.nn.modules.pooling\'] = nn_modules.pooling\nsys.modules[\'torch.nn.modules.activation\'] = nn_modules.activation\nsys.modules[\'torch.nn.modules.batchnorm\'] = nn_modules.batchnorm\nsys.modules[\'torch.nn.modules.dropout\'] = nn_modules.dropout\nsys.modules[\'torch.nn.modules.loss\'] = nn_modules.loss\n\n# Create torch.nn.parameter module\nclass ParameterModule:\n    def __init__(self, **kwargs):\n        self.Parameter = TorchNNParameter\n\nparameter_module = ParameterModule()\nsys.modules[\'torch.nn.parameter\'] = parameter_module\n\n# Register torch.linalg\nsys.modules[\'torch.linalg\'] = torch.linalg\n\n# Register torch.utils and torch.utils.data\nsys.modules[\'torch.utils\'] = torch.utils\nsys.modules[\'torch.utils.data\'] = torch.utils.data\n\n# Create torch.utils.data.dataset module\nclass DatasetModule:\n    def __init__(self, **kwargs):\n        self.Dataset = Dataset\n        self.TensorDataset = TensorDataset\n\ndataset_module = DatasetModule()\nsys.modules[\'torch.utils.data.dataset\'] = dataset_module\n\n# Create torch.utils.data.dataloader module\nclass DataLoaderModule:\n    def __init__(self, **kwargs):\n        self.DataLoader = DataLoader\n\ndataloader_module = DataLoaderModule()\nsys.modules[\'torch.utils.data.dataloader\'] = dataloader_module\n\n# Register torch.optim\nsys.modules[\'torch.optim\'] = torch.optim\n\n# Create torch.optim.optimizer module with Optimizer base class\nclass OptimizerModule:\n    def __init__(self, **kwargs):\n        self.Optimizer = Optimizer\n\noptimizer_module = OptimizerModule()\nsys.modules[\'torch.optim.optimizer\'] = optimizer_module\n\n# Create individual optimizer modules\nclass SGDModule:\n    def __init__(self, **kwargs):\n        self.SGD = SGDOptimizer\n\nclass AdamModule:\n    def __init__(self, **kwargs):\n        self.Adam = AdamOptimizer\n\nclass AdamWModule:\n    def __init__(self, **kwargs):\n        self.AdamW = AdamWOptimizer\n\nclass RMSpropModule:\n    def __init__(self, **kwargs):\n        self.RMSprop = RMSpropOptimizer\n\nclass AdagradModule:\n    def __init__(self, **kwargs):\n        self.Adagrad = AdagradOptimizer\n\nsgd_module = SGDModule()\nadam_module = AdamModule()\nadamw_module = AdamWModule()\nrmsprop_module = RMSpropModule()\nadagrad_module = AdagradModule()\n\nsys.modules[\'torch.optim.sgd\'] = sgd_module\nsys.modules[\'torch.optim.adam\'] = adam_module\nsys.modules[\'torch.optim.adamw\'] = adamw_module\nsys.modules[\'torch.optim.rmsprop\'] = rmsprop_module\nsys.modules[\'torch.optim.adagrad\'] = adagrad_module\n\n# Create torch.optim.lr_scheduler module\nclass LRSchedulerModule:\n    def __init__(self, **kwargs):\n        self.StepLR = StepLR\n        self.ExponentialLR = ExponentialLR\n        self.ReduceLROnPlateau = ReduceLROnPlateau\n\nlr_scheduler_module = LRSchedulerModule()\nsys.modules[\'torch.optim.lr_scheduler\'] = lr_scheduler_module\n\n# Register torch.cuda\nsys.modules[\'torch.cuda\'] = torch.cuda\n\n# Create torch.autograd module for gradient utilities\nclass AutogradModule:\n    def __init__(self, **kwargs):\n        pass\n\n    class Variable:\n        """Deprecated: Variables are now just Tensors"""\n        def __init__(self, data, requires_grad=False, **kwargs):\n            return data\n\nautograd_module = AutogradModule()\nsys.modules[\'torch.autograd\'] = autograd_module\n\n# Clean up any existing state to prevent issues\n_cleanup_global_state()\n';!function(e){if(!e||"string"!=typeof e)throw new Error("Invalid polyfill code provided");if(e.length>1e6)throw new Error("Polyfill code too large")}(e),r.debug("Installing PyTorch polyfill from extracted module"),await this.runtime.runPython(e,{captureOutput:!1,validateInput:!1,timeout:18e4})}this.torchAPI=this.runtime.getGlobal("torch"),this.numpy=this.runtime.getGlobal("np"),this.compute&&this.compute.availableStrategies&&this.compute.availableStrategies.has("webgpu")&&(r.info("[Greed] Injecting WebGPU bridge functions into Python"),this.runtime.setGlobal("__webgpu_allocate__",(e,n,t)=>P.allocate(e,n,t)),this.runtime.setGlobal("__webgpu_read__",async e=>await P.read(e)),this.runtime.setGlobal("__webgpu_matmul__",async(e,n,t,a)=>await P.matmul(e,n,t,a)),this.runtime.setGlobal("__webgpu_add__",async(e,n,t)=>await P.add(e,n,t)),this.runtime.setGlobal("__webgpu_multiply__",async(e,n,t)=>await P.multiply(e,n,t)),this.runtime.setGlobal("__webgpu_relu__",async(e,n)=>await P.relu(e,n)),this.runtime.setGlobal("__webgpu_transpose__",async(e,n)=>await P.transpose(e,n)),this.runtime.setGlobal("__webgpu_free__",e=>P.free(e)),r.info("[Greed] WebGPU bridge functions injected successfully")),this.emit("pytorch:setup:complete")}catch(e){throw this.emit("pytorch:setup:error",{error:e}),new Error(`PyTorch API setup failed: ${e.message}`)}var n}async _validateSystemReadiness(){this.emit("validation:start");const e=[{name:"runtime",check:()=>this.runtime.isReady},{name:"compute",check:()=>this.compute&&this.compute.isInitialized},{name:"memory",check:()=>this.memory.getStats().memoryUsage>=0},{name:"security",check:()=>this.security.getStats().totalValidations>=0},{name:"pytorch",check:()=>null!==this.torchAPI}],n=[];for(const{name:t,check:a}of e)try{const e=a();if(n.push({name:t,passed:e,error:null}),!e)throw new Error(`${t} component failed readiness check`)}catch(e){throw n.push({name:t,passed:!1,error:e.message}),new Error(`System validation failed for ${t}: ${e.message}`)}this.emit("validation:complete",{results:n})}_validateConfig(e){const n=["pyodideIndexURL","maxMemoryMB"];for(const t of n)if(void 0===e[t])throw new Error(`Required configuration missing: ${t}`);if(e.maxMemoryMB<=0||e.maxMemoryMB>4096)throw new Error(`maxMemoryMB must be between 1 and 4096, got ${e.maxMemoryMB}`);return e}_forwardEvents(e,n){const t=["error","warning","init:complete","init:error","cleanup:complete","cleanup:error"];for(const a of t)e.on(a,e=>{this.emit(`${n}:${a}`,e)})}_setupGlobalErrorHandling(){this.on("error",e=>{this.lastError=e,this.errorCount++});const e=["security:error","memory:error","runtime:error","compute:error"];for(const n of e)this.on(n,e=>{this.emit("error",new Error(`${n}: ${e.error?.message||"Unknown error"}`))})}_updateOperationStats(e){this.stats.operations++,this.stats.totalExecutionTime+=e,this.stats.averageExecutionTime=this.stats.totalExecutionTime/this.stats.operations,this.memory&&(this.stats.memoryUsage=this.memory.getStats().memoryUsageMB)}_generateOperationId(){return`greed_op_${Date.now()}_${Math.random().toString(36).substr(2,9)}`}};return n.default})());